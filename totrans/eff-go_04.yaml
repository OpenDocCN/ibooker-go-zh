- en: Chapter 4\. How Go Uses the CPU Resource (or Two)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章\. 如何使用 CPU 资源（或两个）
- en: 'One of the most useful abstractions we can make is to treat properties of our
    hardware and infrastructure systems as resources. CPU, memory, data storage, and
    the network are similar to resources in the natural world: they are finite, they
    are physical objects in the real world, and they must be distributed and shared
    between various key players in the ecosystem.'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们可以做出的最有用的抽象之一是将硬件和基础设施系统的属性视为资源。CPU、内存、数据存储和网络类似于自然界中的资源：它们是有限的，是现实世界中的物理对象，并且必须在生态系统的各个关键参与者之间分配和共享。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Susan J. Fowler, [*Production-Ready Microservices*](https://oreil.ly/8xO1v)
    (O’Reilly, 2016)
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Susan J. Fowler，《*可生产的微服务*》（[O’Reilly, 2016](https://oreil.ly/8xO1v)）
- en: As you learned in [“Behind Performance”](ch01.html#ch-eff-s-performance), software
    efficiency depends on how our program uses the hardware resources. If the same
    functionality uses fewer resources, our efficiency increases and the requirements
    and net cost of running such a program decrease. For example, if we use less CPU
    time (CPU “resource”) or fewer resources with slower access time (e.g., disk),
    we usually reduce the latency of our software.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在 [“性能背后”](ch01.html#ch-eff-s-performance) 中所学到的，软件效率取决于我们的程序如何使用硬件资源。如果相同的功能使用更少的资源，我们的效率就会提高，并且运行这样的程序的需求和净成本会降低。例如，如果我们使用更少的
    CPU 时间（CPU “资源”）或具有较慢访问时间的更少资源（例如磁盘），通常可以减少软件的延迟。
- en: This might sound simple, but in modern computers, these resources interact with
    each other in a complex, nontrivial way. Furthermore, more than one process is
    using these resources, so our program does not use them directly. Instead, these
    resources are managed for us by an operating system. If that wasn’t complex enough,
    especially in cloud environments, we often “virtualize” the hardware further so
    it can be shared across many individual systems in an isolated way. That means
    there are methods for “hosts” to give access to part of a single CPU or disk to
    a “guest” operating system that thinks it’s all the hardware that exists. In the
    end, operating systems and virtualization mechanisms create layers between our
    program and the actual physical devices that store or compute our data.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来可能很简单，但在现代计算机中，这些资源以复杂且非平凡的方式相互交互。此外，多个进程使用这些资源，因此我们的程序并不直接使用它们。相反，操作系统为我们管理这些资源。如果这还不够复杂，特别是在云环境中，我们经常进一步“虚拟化”硬件，以便可以以隔离的方式跨许多个体系统共享它们。这意味着“主机”有方法将部分单个
    CPU 或磁盘访问授予“客户”操作系统，后者认为这是所有存在的硬件。最终，操作系统和虚拟化机制在我们的程序与实际存储或计算我们数据的物理设备之间创建了层次。
- en: To understand how to write efficient code or improve our program’s efficiency
    effectively, we have to learn the characteristics, purpose, and limits of the
    typical computer resources like CPU, different types of storage, and network.
    There is no shortcut here. Furthermore, we can’t ignore understanding how these
    physical components are managed by the operating system and typical virtualization
    layers.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解如何编写高效的代码或有效提升程序的效率，我们必须深入了解典型计算机资源如 CPU、不同类型存储和网络的特性、目的和限制。这里没有捷径。此外，我们不能忽视操作系统和典型虚拟化层如何管理这些物理组件。
- en: In this chapter, we will examine our program execution from the point of view
    of the CPU. We will discuss how Go uses CPUs for single and multiple core tasking.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将从 CPU 的角度来审视我们的程序执行。我们将讨论 Go 如何在单个和多核任务中使用 CPU。
- en: We won’t discuss all types of computer architectures with all mechanisms of
    all existing operating systems, as this would be impossible to fit in one book,
    never mind one chapter. So instead, this chapter will focus on a typical x86-64
    CPU architecture with Intel or AMD, ARM CPUs, and the modern Linux operating system.
    This should get you started and give you a jumping-off point if you ever run your
    program on other, unique types of hardware or operating systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会讨论所有类型的计算机架构以及所有现有操作系统的所有机制，因为这在一本书中是不可能完成的，更不用说一章了。因此，本章将专注于典型的 x86-64
    CPU 架构，包括 Intel 或 AMD、ARM CPU 和现代 Linux 操作系统。这应该让您开始，并为您提供一个跳板，如果您曾经在其他独特类型的硬件或操作系统上运行您的程序。
- en: We will start with exploring CPU in a modern computer architecture to understand
    how modern computers are designed, mainly focusing on the CPU, or processor. Then
    I will introduce the Assembly language, which will help us understand how the
    CPU core executes instructions. After that, we will dig into the Go compiler to
    build awareness of what happens when we do a `go build`. Furthermore, we will
    jump into the CPU and memory wall problem, showing you why modern CPU hardware
    is complex. This problem directly impacts writing efficient code on these ultracritical
    paths. Finally, we will enter the realm of multitasking by explaining how the
    operating system scheduler tries to distribute thousands of executing programs
    on outnumbered CPU cores and how the Go runtime scheduler leverages that to implement
    an efficient concurrency framework for us to use. We will finish with the summary
    on when to use concurrency.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从探索现代计算机架构中的 CPU 开始，以理解现代计算机是如何设计的，主要关注 CPU 或处理器。然后我将介绍汇编语言，这将帮助我们理解 CPU
    核心执行指令的方式。之后，我们将深入了解 Go 编译器，以增进我们对进行`go build`时发生的事情的认识。此外，我们将深入讨论 CPU 和内存墙问题，展示现代
    CPU 硬件为何如此复杂。这个问题直接影响在这些超关键路径上编写高效代码。最后，我们将进入多任务处理的领域，解释操作系统调度程序如何尝试在数量不足的 CPU
    核心上分发数千个执行程序，以及 Go 运行时调度程序如何利用这一点为我们实现高效的并发框架。我们将以何时使用并发的总结结束。
- en: Mechanical Sympathy
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机械同情心
- en: Initially, this chapter might get overwhelming, especially if you are new to
    low-level programming. Yet, awareness of what is happening will help us understand
    the optimizations, so focus on understanding high-level patterns and characteristics
    of each resource (e.g., how the Go scheduler works). We don’t need to know how
    to write machine code manually or how to, blindfolded, manufacture the computer.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，这一章节可能会让人感到不知所措，特别是对低级编程新手来说。然而，了解正在发生的事情将有助于我们理解优化，因此要专注于理解每个资源的高级模式和特性（例如
    Go 调度器的工作原理）。我们不需要知道如何手动编写机器码，或者如何盲目地制造计算机。
- en: Instead, let’s treat this with curiosity about how things work under the computer
    case in general. In other words, we need to have [mechanical sympathy](https://oreil.ly/Co2IM).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，让我们对计算机箱底下的事情如何运作充满好奇。换句话说，我们需要对[机械同情心](https://oreil.ly/Co2IM)抱有好奇心。
- en: To understand how the CPU architecture works, we need to explain how modern
    computers operate. So let’s dive into that in the next section.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解 CPU 架构的工作原理，我们需要解释现代计算机的运行方式。因此，让我们在下一节深入探讨这个问题。
- en: CPU in a Modern Computer Architecture
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现代计算机架构中的 CPU
- en: All we do while programming in Go is construct a set of statements that tells
    the computer what to do, step-by-step. Given predefined language constructs like
    variables, loops, control mechanisms, arithmetic, and I/O operations, we can implement
    any algorithms that interact with data stored in different mediums. This is why
    Go, like many other popular programming languages, can be called imperative—as
    developers, we have to describe how the program will operate. This is also how
    hardware is designed nowadays—it is imperative too. It waits for program instructions,
    optional input data, and the desired place for output.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Go 编程中，我们所做的一切就是构建一组语句，告诉计算机逐步执行什么操作。借助预定义的语言结构，如变量、循环、控制机制、算术和 I/O 操作，我们可以实现与存储在不同介质中的数据交互的任何算法。这也是为什么像
    Go 这样的流行编程语言被称为命令式语言——作为开发人员，我们必须描述程序的操作方式。现代硬件的设计也是如此——这也是命令式的。它等待程序指令、可选的输入数据以及所需的输出位置。
- en: Programming wasn’t always so simple. Before general-purpose machines, engineers
    had to design fixed program hardware to achieve requested functionality, e.g.,
    a desk calculator. Adding a feature, fixing a bug, or optimizing required changing
    the circuits and manufacturing new devices. Probably not the easiest time to be
    a “programmer”!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 编程并不总是如此简单。在通用目的机器出现之前，工程师们必须设计固定程序硬件以实现请求的功能，例如台式计算器。添加功能、修复错误或优化都需要改变电路并制造新设备。可能不是成为“程序员”的最轻松时期！
- en: Fortunately, around the 1950s, a few inventors worldwide figured out the opportunity
    for the universal machine that could be programmed using a set of predefined instructions
    stored in memory. One of the first people to document this idea was a great mathematician,
    John von Neumann, and his team.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，大约在1950年代，世界各地的一些发明家发现了一种可以使用存储在内存中的一组预定义指令来编程的通用机器的机会。最早记录这一想法的之一是伟大的数学家约翰·冯·诺伊曼及其团队。
- en: It is evident that the machine must be capable of storing in some manner not
    only the digital information needed in a given computation ..., the intermediate
    results of the computation (which may be wanted for varying lengths of time),
    but also the instructions which govern the actual routine to be performed on the
    numerical data. ... For an all-purpose machine, it must be possible to instruct
    the device to carry out whatsoever computation that can be formulated in numerical
    terms.
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 显然，设备必须能够以某种方式存储不仅计算中所需的数字信息，... 还有计算的中间结果（可能需要存储不同长度的时间），以及控制实际计算例程的指令。...
    对于通用机器，必须能够指示设备执行以数字形式表达的任何计算。
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Arthur W. Burks, Herman H. Goldstine, and John von Neumann, *Preliminary Discussion
    of the Logical Design of an Electronic Computing Instrument* (Institute for Advanced
    Study, 1946)
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Arthur W. Burks、Herman H. Goldstine 和 John von Neumann，《电子计算仪器逻辑设计初步讨论》（高级研究院，1946年）
- en: What’s noteworthy is that most modern general-purpose computers (e.g., PCs,
    laptops, and servers) are based on John von Neumann’s design. This assumes that
    program instructions can be stored and fetched similar to storing and reading
    program data (instruction input and output). We fetch both the instruction to
    be performed (e.g., `add`) and data (e.g., addition operands) by reading bytes
    from a certain memory address in the main memory (or caches). While it doesn’t
    sound like a novel idea now, it established how general-purpose machines work.
    We call this Von Neumann computer architecture, and you can see its modern, evolved
    variation in [Figure 4-1](#img-uma).^([1](ch04.html#idm45606836099536))
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，大多数现代通用计算机（如PC、笔记本电脑和服务器）基于John von Neumann的设计。这假设程序指令可以像存储和读取程序数据（指令输入和输出）一样被存储和提取。我们通过从主存储器（或高速缓存）中的特定内存地址读取字节来获取要执行的指令（例如`add`）和数据（例如加法操作数）。虽然现在听起来并不像一个新颖的想法，但它确立了通用机器的工作方式。我们称之为冯·诺依曼计算机体系结构，你可以在[图
    4-1](#img-uma)中看到其现代演变的变体。^([1](ch04.html#idm45606836099536))
- en: '![efgo 0401](assets/efgo_0401.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0401](assets/efgo_0401.png)'
- en: Figure 4-1\. High-level computer architecture with a single multicore CPU and
    uniform memory access (UMA)
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1\. 带有单个多核 CPU 和统一内存访问（UMA）的高级计算机架构
- en: At the heart of modern architecture, we see a CPU consisting of multiple cores
    (four to six physical cores are the norm in the 2020s PCs). Each core can execute
    desired instructions with certain data saved in random-access memory (RAM) or
    any other memory layers like registers or L-caches (discussed later).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代架构的核心，我们看到一个CPU由多个核心组成（2020年代PC中四到六个物理核心是常见的）。每个核心可以执行带有存储在随机访问内存（RAM）或任何其他存储器层中的特定数据的所需指令。
- en: The RAM explained in [Chapter 5](ch05.html#ch-hardware2) performs the duty of
    the main, fast, volatile memory that can store our data and program code as long
    as the computer is powered. In addition, the memory controller makes sure RAM
    is supplied with a constant power flow to keep the information on RAM chips. Last,
    the CPU can interact with various external or internal input/output (I/O) devices.
    From a high-level view, an I/O device means anything that accepts sending or receiving
    a stream of bytes, for example, mouse, keyboard, speaker, monitor, HDD or SSD
    disk, network interface, GPU, and thousands more.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 5 章](ch05.html#ch-hardware2)中解释的RAM承担了主要、快速、易失性内存的职责，它可以在计算机通电的同时存储我们的数据和程序代码。此外，内存控制器确保RAM得到持续的电源供应，以保持RAM芯片上的信息。最后，CPU可以与各种外部或内部输入/输出（I/O）设备进行交互。从高层次来看，I/O设备指的是接受发送或接收字节流的任何内容，例如鼠标、键盘、扬声器、显示器、HDD或SSD磁盘、网络接口、GPU等等，数量众多。
- en: Roughly speaking, CPU, RAM, and popular I/O devices like disks and network interfaces
    are the essential parts of computer architecture. This is what we use as “resources”
    in our RAERs mentioned in [“Efficiency Requirements Should Be Formalized”](ch03.html#ch-conq-req-formal)
    and what we are usually optimizing for in our software development.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 大致来说，CPU、RAM 和流行的I/O设备（如磁盘和网络接口）是计算机架构的基本组成部分。这是我们在《“效率要求应该被形式化”》中提到的RAERs中使用的“资源”，也是我们在软件开发中通常进行优化的对象。
- en: 'In this chapter, we will focus on the brain of our general-purpose machines—the
    CPU. When should we care about CPU resources? Typically, from an efficiency standpoint,
    we should start looking at our Go process CPU resource usage when either of the
    following occurs:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将关注我们通用计算机的大脑——CPU。我们何时应该关注 CPU 资源？从效率的角度来看，当以下情况之一发生时，我们应该开始关注我们 Go
    进程的 CPU 资源使用情况：
- en: Our machine can’t do other tasks because our process uses all the available
    CPU resource computing capacity.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的机器无法执行其他任务，因为我们的进程使用了所有可用的 CPU 资源计算能力。
- en: Our process runs unexpectedly slow, while we see higher CPU consumption.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的进程运行得出乎意料地慢，而我们却看到更高的 CPU 消耗。
- en: There are many techniques to troubleshoot these symptoms, but we must first
    understand the CPU’s internal working and program execution basics. This is the
    key to efficient Go programming. Furthermore, it explains the numerous optimization
    techniques that might surprise us initially. For example, do you know why in Go
    (and other languages), we should avoid using linked lists like structures if we
    plan to iterate over them a lot, despite their theoretical advantages like quick
    insertion and deletion?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多技术可以排除这些症状，但我们必须首先了解 CPU 的内部工作原理和程序执行基础。这是进行高效 Go 编程的关键。此外，它解释了最初可能让我们惊讶的许多优化技术。例如，你知道为什么在
    Go（和其他语言中），如果我们计划经常迭代它们，我们应该避免使用类似链表的结构，尽管它们在理论上有快速插入和删除的优势吗？
- en: Before we learn why, we must understand how the CPU core executes our programs.
    Surprisingly, I found that the best way to explain this is by learning how the
    Assembly language works. Trust me on this; it might be easier than you think!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们了解为什么之前，我们必须理解 CPU 核心如何执行我们的程序。令人惊讶的是，我发现通过学习汇编语言工作的方式来解释这一点是最好的。相信我，这可能比你想象的要容易！
- en: Assembly
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 汇编语言
- en: The CPU core, indirectly, can execute programs we write. For example, consider
    the simple Go code in [Example 4-1](#code-sum).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 核心间接地可以执行我们编写的程序。例如，考虑在 [Example 4-1](#code-sum) 中的简单 Go 代码。
- en: Example 4-1\. Simple function that reads numbers from a file and returns the
    total sum
  id: totrans-34
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-1\. 从文件中读取数字并返回总和的简单函数
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO1-1)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO1-1)'
- en: The main arithmetic operation in this function adds a parsed number from the
    file into a `ret` integer variable representing the total sum.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数中的主要算术操作将从文件中解析的数字添加到表示总和的整数变量 `ret` 中。
- en: While such language is far from, let’s say, spoken English, unfortunately, it
    is still too complex and incomprehensible for the CPU. It is not “machine-readable”
    code. Thankfully every programming language has a dedicated tool called a compiler^([2](ch04.html#idm45606835882864))
    that (among other things discussed in [“Understanding Go Compiler”](#ch-hw-compilation))
    translates our higher-level code to machine code. You might be familiar with a
    `go build` command that invokes a default Go compiler.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种语言远非口语英语，不幸的是，对于 CPU 来说，它仍然太复杂和难以理解。这不是“机器可读”的代码。幸运的是，每种编程语言都有一个专门的工具称为编译器^([2](ch04.html#idm45606835882864))，它（除了其他讨论在[“理解
    Go 编译器”](#ch-hw-compilation)中的内容）将我们的高级代码转换为机器代码。你可能熟悉`go build`命令，它调用默认的 Go 编译器。
- en: The machine code is a sequence of instructions written in binary format (famous
    zeros and ones). In principle, each instruction is represented by a number (`opcode`)
    followed by optional operands in the form of a constant value or address in the
    main memory. We can also refer to a few CPU core registers, which are tiny “slots”
    directly on the CPU chip that can be used to store intermediate results. For example,
    on AMD64 CPU, we have sixteen 64-bit general-purpose registers referred to as
    RAX, RBX, RDX, RBP, RSI, RDI, RSP, and R8-R15.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 机器码是用二进制格式编写的指令序列（著名的零和一）。原则上，每条指令由一个数字（`opcode`）表示，后面是形式为常量值或主存中地址的可选操作数。我们还可以引用几个
    CPU 核心寄存器，这些寄存器是直接安装在 CPU 芯片上的小“槽”，用于存储中间结果。例如，在 AMD64 CPU 上，我们有十六个 64 位通用寄存器，分别称为
    RAX、RBX、RDX、RBP、RSI、RDI、RSP，以及 R8-R15。
- en: While translating to machine code, the compiler often adds additional code like
    extra memory safety bound checks. It automatically changes our code for known
    efficiency patterns for a given architecture. Sometimes this might not be what
    we expect. This is why inspecting the resulting machine code when troubleshooting
    some efficiency problems is sometimes useful. Another advanced example of humans
    needing to read machine code is when we need to reverse engineer programs without
    source code.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在转换为机器代码时，编译器通常会添加额外的代码，例如额外的内存安全边界检查。它会根据已知的效率模式自动更改我们的代码以适应特定的体系结构。有时这可能并不是我们期望的。这就是为什么在解决某些效率问题时检查结果的机器代码有时很有用。人们需要阅读机器代码的另一个高级示例是在没有源代码的情况下对程序进行逆向工程。
- en: Unfortunately, machine code is impossible to read for humans unless you are
    a genius. However, there is a great tool we can use in such situations. We can
    compile [Example 4-1](#code-sum) code to [Assembly language](https://oreil.ly/3xZAs)
    instead of machine code. We can also disassemble the compiled machine code to
    Assembly. The Assembly language represents the lowest code level that can be practically
    read and (in theory) written by human developers. It also represents well what
    will be interpreted by the CPU when converted to machine code.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，机器代码对人类来说是不可能阅读的，除非你是天才。然而，在这种情况下，我们可以使用一个很棒的工具。我们可以将[示例 4-1](#code-sum)
    的代码编译成[汇编语言](https://oreil.ly/3xZAs) 而不是机器代码。我们也可以将编译后的机器代码反汇编为汇编语言。汇编语言代表可以由人类开发者实际阅读（在理论上可以编写）的最低代码级别。它也很好地代表了当转换为机器代码时CPU将执行的内容。
- en: 'It is worth mentioning that we can disassemble compiled code into various Assembly
    dialects. For example:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，我们可以将编译后的代码反汇编成各种汇编方言。例如：
- en: To [Intel syntax](https://oreil.ly/alpt4) using the standard Linux tool [`objdump
    -d -M intel <binary>`](https://oreil.ly/kZO3j)
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换为[Intel语法](https://oreil.ly/alpt4)，使用标准的Linux工具[`objdump -d -M intel <binary>`](https://oreil.ly/kZO3j)
- en: To [AT&T syntax](https://oreil.ly/k6bKs) using the similar command [`objdump
    -d -M att <binary>`](https://oreil.ly/cmAW9)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换为[AT&T语法](https://oreil.ly/k6bKs)，使用类似的命令[`objdump -d -M att <binary>`](https://oreil.ly/cmAW9)
- en: To [Go “pseudo” assembly language](https://oreil.ly/lT07J) using Go tooling
    [`go tool objdump -s <binary>`](https://oreil.ly/5I9t2)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换为[Go“伪”汇编语言](https://oreil.ly/lT07J)，使用Go工具[`go tool objdump -s <binary>`](https://oreil.ly/5I9t2)
- en: All three of these dialects are used in the various tools, and their syntax
    varies. To have an easier time, always ensure what syntax your disassembly tool
    uses. The Go Assembly is a dialect that tries to be as portable as possible, so
    it might not exactly represent the machine code. Yet it is usually consistent
    and close enough for our purposes. It can show all compilation optimization discussed
    in [“Understanding Go Compiler”](#ch-hw-compilation). This is why Go Assembly
    is what we will use throughout this book.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这三种方言都在各种工具中使用，并且它们的语法各不相同。为了更容易理解，请始终确认您的反汇编工具使用的语法。Go汇编语言是一种尝试尽可能通用的方言，因此可能并不完全代表机器代码。然而，它通常是一致的并且足够接近我们的目的。它可以显示[《理解Go编译器》](#ch-hw-compilation)中讨论的所有编译优化。这就是为什么本书将始终使用Go汇编语言的原因。
- en: Do I Need to Understand Assembly?
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我需要理解汇编语言吗？
- en: You don’t need to know how to program in Assembly to write efficient Go code.
    Yet a rough understanding of Assembly and the decompilation process are essential
    tools that can often reveal hidden, lower-level computation waste. Practically
    speaking, it’s useful primarily for advanced optimizations when we have already
    applied all of the more straightforward optimizations. Assembly is also beneficial
    for understanding the changes the compiler applies to our code when translating
    to machine code. Sometimes these might surprise us! Finally, it also tells us
    how the CPU works.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您不需要知道如何在汇编语言中编程来编写高效的Go代码。然而，对汇编语言和反汇编过程的粗略理解是揭示隐藏的低级计算浪费的重要工具。实际上，当我们已经应用了所有更简单的优化时，它通常对于高级优化是有用的。汇编语言还有助于理解编译器在将我们的代码转换为机器代码时应用的变化。有时这些变化可能会让我们感到意外！最后，它还告诉我们CPU是如何工作的。
- en: In [Example 4-2](#code-sum-asm) we can see a tiny, disassembled part of the
    compiled [Example 4-1](#code-sum) (using `go tool objsdump -s`) that represents
    `ret += num` statement.^([3](ch04.html#idm45606835843408))
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 4-2](#code-sum-asm) 中，我们可以看到编译后的[示例 4-1](#code-sum) 的一个小片段（使用`go tool objsdump
    -s`）表示`ret += num`语句。^([3](ch04.html#idm45606835843408))
- en: Example 4-2\. Addition part of code in Go Assembly language decompiled from
    the compiled [Example 4-1](#code-sum)
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-2\. 从编译后的[示例 4-1](#code-sum) 中反编译出来的Go汇编语言中的代码部分
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO2-1)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO2-1)'
- en: The first line represents a [quadword (64 bit) MOV instruction](https://oreil.ly/SDE5R)
    that tells the CPU to copy the 64-bit value from memory under the address stored
    in register `SP` plus 80 bytes and put that into the `SI` register.^([4](ch04.html#idm45606835798912))
    The compiler decided that `SI` will store the initial value of the return argument
    in our function, so the `ret` integer variable for the `ret+=num` operation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行代表一个[四字节（64位）MOV指令](https://oreil.ly/SDE5R)，告诉CPU从存储在寄存器`SP`地址加上80字节的内存中复制64位值，并将其放入`SI`寄存器中。^([4](ch04.html#idm45606835798912))
    编译器决定`SI`将存储返回参数在我们函数中的初始值，所以`ret`整数变量用于`ret+=num`操作。
- en: '[![2](assets/2.png)](#co_how_go_uses_the_cpu_resource__or_two__CO2-2)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_how_go_uses_the_cpu_resource__or_two__CO2-2)'
- en: As a second instruction, we tell the CPU to add a quadword value from the `AX`
    register to the `SI` register. The compiler used the `AX` register to store the
    `num` integer variable, which we parsed from the `string` in previous instructions
    (outside of this snippet).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第二条指令，我们告诉CPU将来自`AX`寄存器的四字节值添加到`SI`寄存器中。编译器使用`AX`寄存器来存储`num`整数变量，该变量是我们从之前指令（不在本段内）解析的字符串。
- en: The preceding example shows `MOVQ` and `ADDQ` instructions. To make things more
    complex, each distinct CPU implementation allows a different set of instructions,
    with different memory addressing, etc. The industry created the [Instruction Set
    Architecture (ISA)](https://oreil.ly/eTzST) to specify a strict, portable interface
    between software and hardware. Thanks to the ISA, we can compile our program,
    for example, to machine code compatible with the ISA for x86 architecture and
    run it on any x86 CPU.^([5](ch04.html#idm45606835763760)) The ISA defines data
    types, registers, main memory management, fixed set of instructions, unique identification,
    input/output model, etc. There are various [ISAs](https://oreil.ly/TLxJn) for
    different types of CPUs. For example, both 32-bit and 64-bit Intel and AMD processors
    use x86 ISA, and ARM uses its ARM ISA (for example, new [Apple M chips use ARMv8.6-A](https://oreil.ly/NZqT1)).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的示例展示了`MOVQ`和`ADDQ`指令。为了使事情更加复杂，每个不同的CPU实现允许不同的指令集，具有不同的内存寻址等。行业创建了[指令集架构（ISA）](https://oreil.ly/eTzST)来指定软件和硬件之间严格的、可移植的接口。由于ISA，我们可以将我们的程序编译为与x86架构的ISA兼容的机器码，并在任何x86
    CPU上运行。^([5](ch04.html#idm45606835763760)) ISA定义了数据类型、寄存器、主存储器管理、固定指令集、唯一标识、输入/输出模型等。不同类型的CPU有不同的[ISA](https://oreil.ly/TLxJn)。例如，32位和64位的Intel和AMD处理器都使用x86
    ISA，而ARM则使用其ARM ISA（例如，新的[Apple M芯片使用ARMv8.6-A](https://oreil.ly/NZqT1)）。
- en: As far as Go developers are concerned, the ISA defines a set of instructions
    and registers our compiled machine code can use. To produce a portable program,
    a compiler can transform our Go code into machine code compatible with a specific
    ISA (architecture) and the type of the desired operating system. In the next section,
    let’s look at how the default Go compiler works. On the way, we will uncover mechanisms
    to help the Go compiler produce efficient and fast machine code.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 就Go开发者而言，ISA定义了一组指令和寄存器，我们编译的机器码可以使用。为了生成可移植的程序，编译器可以将我们的Go代码转换为与特定ISA（架构）和所需操作系统类型兼容的机器码。在下一节中，让我们看看默认的Go编译器是如何工作的。在此过程中，我们将揭示帮助Go编译器生成高效快速机器码的机制。
- en: Understanding Go Compiler
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Go编译器
- en: The topic of building effective compilers can fill a few books. In this book,
    however, we will try to understand the Go compiler basics that we, as Go developers
    interested in efficient code, have to be aware of. Generally, many things are
    involved in executing the Go code we write on the typical operating system, not
    only compilation. First, we need to compile it using a compiler, and then we have
    to use a linker to link different object files together, including potentially
    shared libraries. These compile and link procedures, often called *building*,
    produce the executable (“binary”) that the operating system can execute. During
    the initial start, called *loading*, other shared libraries can be dynamically
    loaded too (e.g., Go plug-ins).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 关于构建有效编译器的话题可以填写几本书。然而，在本书中，我们将试图理解作为对高效代码感兴趣的 Go 开发人员必须了解的 Go 编译器基础知识。通常，我们在典型操作系统上执行的
    Go 代码涉及许多内容，不仅仅是编译。首先，我们需要使用编译器编译它，然后我们必须使用链接器将不同的目标文件链接在一起，包括可能的共享库。这些编译和链接过程通常称为*构建*，它们生成操作系统可以执行的可执行文件（“二进制文件”）。在初始启动时，称为*加载*，还可以动态加载其他共享库（例如
    Go 插件）。
- en: There are many code-building methods for Go code, designed for different target
    environments. For example, [Tiny Go](https://oreil.ly/c2C5E) is optimized to produce
    binaries for microcontrollers, [gopherjs](https://oreil.ly/D83Jq) produces JavaScript
    for in-browser execution, and [android](https://oreil.ly/83Wm1) produces programs
    executable on Android operating systems. However, this book will focus on the
    default and most popular Go compiler and linking mechanism available in the `go
    build` command. The compiler itself is written in Go (initially in C). The rough
    documentation and source code can be found [here](https://oreil.ly/qcrLt).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多针对不同目标环境设计的 Go 代码构建方法。例如，[Tiny Go](https://oreil.ly/c2C5E) 优化生成微控制器的二进制文件，[gopherjs](https://oreil.ly/D83Jq)
    生成用于浏览器执行的 JavaScript，而 [android](https://oreil.ly/83Wm1) 则生成可在 Android 操作系统上执行的程序。但是，本书将重点放在
    `go build` 命令中默认和最流行的 Go 编译器和链接机制上。编译器本身是用 Go 编写的（最初是用 C 编写的）。可以在[这里](https://oreil.ly/qcrLt)找到粗略的文档和源代码。
- en: The `go build` can build our code into many different outputs. We can build
    executables that require system libraries to be dynamically linked on startup.
    We can build shared libraries or even C-compatible shared libraries. Yet the most
    common and recommended way of using Go is to build executables with all dependencies
    statically linked in. It offers a much better experience where invocation of our
    binary does not need any system dependency of a specific version in a certain
    directory. It is a default build mode for code with a starting `main` function
    that can also be explicitly invoked using `go build -buildmode=exe`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`go build` 可以将我们的代码构建成许多不同的输出。我们可以构建需要在启动时动态链接系统库的可执行文件。我们可以构建共享库，甚至是兼容 C 的共享库。然而，使用
    Go 的最常见和推荐的方式是构建将所有依赖项静态链接的可执行文件。它提供了更好的体验，其中我们的二进制文件的调用不需要特定目录中特定版本的系统依赖项。对于具有起始
    `main` 函数的代码，默认构建模式也可以通过 `go build -buildmode=exe` 明确调用。'
- en: The `go build` command invokes both compilation and linking. While the linking
    phase also performs certain optimizations and checks, the compiler probably performs
    the most complex duty. The Go compiler focuses on a single package at once. It
    compiles package source code into the native code that the target architecture
    and operating systems support. On top of that, it validates, optimizes that code,
    and prepares important metadata for debugging purposes. We need to “collaborate”
    with the compiler (and operating system and hardware) to write efficient Go and
    not work against it.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`go build` 命令既调用编译又调用链接。虽然链接阶段也执行某些优化和检查，但编译器可能执行最复杂的任务。Go 编译器一次只专注于一个包。它将包的源代码编译为目标架构和操作系统支持的本机代码。此外，它还验证、优化该代码，并为调试目的准备重要的元数据。我们需要与编译器（以及操作系统和硬件）“合作”，以编写高效的
    Go 代码，而不是反其道而行之。'
- en: I tell everyone, if you’re not sure how to do something, ask the question around
    what is the most idiomatic way to do this in Go. Because many of those answers
    are already tuned to being sympathetic with the operating system of the hardware.
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我告诉每个人，如果不确定如何做某事，请问问在 Go 中最惯用的方式是什么。因为许多答案已经调整为与硬件的操作系统相容。
- en: ''
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Bill Kennedy, [“Bill Kennedy on Mechanical Sympathy”](https://oreil.ly/X3XzI)
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Bill Kennedy，《机械同情心上的比尔·肯尼迪》。
- en: To make things more interesting, `go build` also offers a special cross-compilation
    mode if you want to compile a mix of Go code that uses functions implemented in
    C, C++, or even Fortran! This is possible if you enable a mode called [`cgo`](https://oreil.ly/Xjh9U),
    which uses a mix of C (or C++) compiler and Go compiler. Unfortunately, `cgo`
    [is not recommended](https://oreil.ly/QojX3), and it should be avoided if possible.
    It makes the build process slow, the performance of passing data between C and
    Go is questionable, and non-`cgo` compilation is already powerful enough to cross-compile
    binaries for different architectures and operating systems. Luckily, most of the
    libraries are either pure Go or are using pieces of Assembly that can be included
    in the Go binary without `cgo`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使事情更有趣，`go build` 还提供了一个特殊的交叉编译模式，如果您想要编译使用 C、C++ 或甚至 Fortran 实现的函数混合的 Go
    代码！如果您启用了一个称为 [`cgo`](https://oreil.ly/Xjh9U) 的模式，这是可能的。不幸的是，`cgo` [不建议使用](https://oreil.ly/QojX3)，应尽量避免使用它。它会使构建过程变慢，C
    和 Go 之间传递数据的性能值得怀疑，并且非 `cgo` 编译已经足够强大，可以为不同架构和操作系统交叉编译二进制文件。幸运的是，大多数库要么是纯 Go 的，要么是使用可以包含在
    Go 二进制文件中的汇编代码片段，而无需 `cgo`。
- en: To understand the impact of the compiler on our code, see the stages the Go
    compiler performs in [Figure 4-2](#img-hw-comp). While `go build` includes such
    compilation, we can trigger just the compilation (without linking) alone using
    `go tool compile`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解编译器对我们的代码的影响，可以看看 Go 编译器在 [Figure 4-2](#img-hw-comp) 中执行的阶段。虽然 `go build`
    包括这样的编译，但我们可以仅使用 `go tool compile` 触发单独的编译（不链接）。
- en: '![efgo 0402](assets/efgo_0402.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0402](assets/efgo_0402.png)'
- en: Figure 4-2\. Stages performed by the Go compiler on each Go package
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. Go 编译器对每个 Go 包执行的阶段
- en: 'As mentioned previously, the whole process resides around the packages you
    use in your Go program. Each package is compiled in separation, allowing parallel
    compilation and separation of concerns. The compilation flow presented in [Figure 4-2](#img-hw-comp)
    works as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，整个过程围绕您在 Go 程序中使用的包展开。每个包都在单独编译，允许并行编译和关注点分离。图 4-2 中展示的编译流程如下：
- en: The Go source code is first tokenized and parsed. The syntax is checked. The
    syntax tree references files and file positions to produce meaningful error and
    debugging information.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Go 源代码首先被标记化和解析。语法被检查。语法树引用文件和文件位置，以产生有意义的错误和调试信息。
- en: An abstract syntax tree (AST) is built. Such a tree notion is a common abstraction
    that allows developers to create algorithms that easily transform or check parsed
    statements. While in AST form, code is initially type-checked. Declared but not
    used items are detected.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建抽象语法树（AST）。这样的树是一种常见的抽象，允许开发人员创建能够轻松转换或检查解析语句的算法。在 AST 形式中，代码首先进行类型检查。检测出声明但未使用的项。
- en: The first pass of optimization is performed. For example, the initial dead code
    is eliminated, so the binary size can be smaller and less code needs to be compiled.
    Then, escape analysis (mentioned in [“Go Memory Management”](ch05.html#ch-hw-go-mem))
    is performed to decide which variables can be placed on the stack and which have
    to be allocated on the heap. On top of that, in this stage, function inlining
    occurs for simple and small functions.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先执行优化的第一遍。例如，初始的死代码被消除，因此二进制大小可以更小，编译的代码量也更少。接着进行逃逸分析（见 [“Go 内存管理”](ch05.html#ch-hw-go-mem)），以决定哪些变量可以放在堆栈上，哪些必须分配到堆上。此外，在这个阶段，对于简单和小型函数，还会进行函数内联。
- en: Function Inlining
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数内联
- en: Functions^([6](ch04.html#idm45606835723216)) in programming language allow us
    to create abstractions, hide complexities, and reduce repeated code. Yet the cost
    of calling execution is nonzero. For example, [a function with a single argument
    call needs ~10 extra CPU instructions](https://oreil.ly/4OPbI).^([7](ch04.html#idm45606835721776))
    So, while the cost is fixed and typically at the level of nanoseconds, it can
    matter if we have thousands of these calls in the hot path and the function body
    is small enough that this execution call matters.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编程语言中的函数^([6](ch04.html#idm45606835723216)) 允许我们创建抽象，隐藏复杂性，并减少重复代码。然而，调用执行的成本不为零。例如，[具有单个参数调用的函数需要额外的约
    10 条 CPU 指令](https://oreil.ly/4OPbI)^([7](ch04.html#idm45606835721776))。因此，虽然成本固定且通常在纳秒级别，但如果我们在热路径中有数千个这样的调用，并且函数体足够小，这个执行调用可能会有影响。
- en: There are also other benefits of inlining. For example, the compiler can apply
    other optimizations more effectively in code with fewer functions and does not
    need to use heap or large stack memory (with copy) to pass arguments between function
    scopes. Heap and stack are explained in [“Go Memory Management”](ch05.html#ch-hw-go-mem).
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 内联还有其他好处。例如，编译器可以更有效地在代码中应用其他优化，尤其是在函数更少的情况下，并且不需要在函数作用域之间传递参数时使用堆或大型栈内存（通过复制）。堆和栈的解释请参见[“Go内存管理”](ch05.html#ch-hw-go-mem)。
- en: The compiler automatically substitutes some function calls with the exact copy
    of its body. This is called *inlining* or [*inline expansion*](https://oreil.ly/JGde3).
    The logic is quite smart. For instance, from Go 1.9, the compiler can [inline
    both leaf and mid-stack functions](https://oreil.ly/CX2v0).
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编译器会自动用其正文的精确副本替换某些函数调用。这称为*内联*或[*内联扩展*](https://oreil.ly/JGde3)。其逻辑非常智能。例如，从Go
    1.9开始，编译器可以[内联叶和中栈函数](https://oreil.ly/CX2v0)。
- en: Manual Inlining Is Rarely Needed
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 很少需要手动内联
- en: It is tempting for beginner engineers to micro-optimize by manually inlining
    some of their functions. However, while developers had to do it in the early days
    of programming, this functionality is a fundamental duty of the compiler, which
    usually knows better when and how to inline a function. Use that fact by focusing
    on your code readability and maintainability first regarding the choice of functions.
    Inline manually only as a last resort, and always measure.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于初学者工程师来说，通过手动内联一些函数进行微优化是很诱人的。然而，尽管在编程的早期阶段开发人员必须这样做，但这种功能通常是编译器的基本职责，它通常更了解何时以及如何内联函数。利用这一事实，首先关注代码的可读性和可维护性，只在最后的情况下手动内联，并始终进行测量。
- en: After early optimizations on the AST, the tree is converted to the Static Single
    Assignment (SSA) form. This low-level, more explicit representation makes it easier
    to perform further optimization passes using a set of rules. For example, with
    the help of the SSA, the compiler can easily find places of unnecessary variable
    assignments.^([8](ch04.html#idm45606835712848))
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在对AST进行了早期优化之后，树被转换为静态单赋值（SSA）形式。这种底层更明确的表示形式使得使用一组规则进行进一步优化更加容易。例如，借助SSA的帮助，编译器可以轻松地找到不必要的变量赋值位置。^([8](ch04.html#idm45606835712848))
- en: The compiler applies further machine-independent optimization rules. So, for
    example, statements like `y := 0*x` will be simplified to `y :=0`. The complete
    list of rules is [enormous](https://oreil.ly/QTljA) and only confirms how complex
    this space is. Furthermore, some code pieces can be replaced by an [intrinsic
    function](https://oreil.ly/FMjT0)—heavily optimized equivalent code (e.g., in
    raw Assembly).
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译器应用进一步的机器无关优化规则。例如，语句如`y := 0*x`将简化为`y := 0`。完整的规则列表是[巨大的](https://oreil.ly/QTljA)，并且只能确认这个领域有多复杂。此外，一些代码片段可以由[内置函数](https://oreil.ly/FMjT0)替换——这是经过高度优化的等效代码（例如原始汇编）。
- en: Based on `GOARCH` and `GOOS` environment variables, the compiler invokes the
    `genssa` function that converts SSA to the machine code for the desired architecture
    (ISA) and operating system.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据`GOARCH`和`GOOS`环境变量，编译器调用`genssa`函数将SSA转换为所需架构（ISA）和操作系统的机器码。
- en: Further ISA- and operating system–specific optimizations are applied.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进一步的ISA和操作系统特定优化被应用。
- en: Package machine code that is not dead is built into a single object file (with
    the *.o* suffix) and debug information.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 未死的包机器码被构建为单个对象文件（带有*.o*后缀）和调试信息。
- en: The final “object file” is compressed into a `tar` file called a Go *archive*,
    usually with *.a* file suffix.^([9](ch04.html#idm45606835698096)) Such archive
    files for each package can be used by Go linker (or other linkers) to combine
    all into a single executable, commonly called a *binary file*. Depending on the
    operating system, such a file follows a certain format, telling the system how
    to execute and use it. Typically for Linux, it will be an [Executable and Linkable
    Format](https://oreil.ly/jnicX) (ELF). On Windows, it might be [Portable Executable](https://oreil.ly/SdohW)
    (PE).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的“目标文件”被压缩为一个名为Go *archive*的`tar`文件，通常带有*.a*文件后缀。^([9](ch04.html#idm45606835698096))
    每个包的这种存档文件可以被Go链接器（或其他链接器）使用，以组合成一个单一的可执行文件，通常称为*二进制文件*。根据操作系统的不同，这样的文件遵循特定的格式，告诉系统如何执行和使用它。对于Linux来说，通常是[可执行和可链接格式](https://oreil.ly/jnicX)（ELF）。在Windows上，可能是[便携式可执行格式](https://oreil.ly/SdohW)（PE）。
- en: The machine code is not the only part of such a binary file. It also carries
    the program’s static data, like global variables and constants. The executable
    file also contains a lot of debugging information that can take a considerable
    amount of binary size, like a simple symbols table, basic type information (for
    reflection), and [PC-to-line mapping](https://oreil.ly/akAR2) (address of the
    instruction to the line in the source code where the command was). That extra
    information enables valuable debugging tools to link machine code to the source
    code. Many debugging tools use it, for example, [“Profiling in Go”](ch09.html#ch-obs-profiling)
    and the aforementioned `objdump` tool. For compatibility with debugging software
    like Delve or GDB, the DWARF table is also attached to the binary file.^([10](ch04.html#idm45606835689456))
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制文件中的机器代码并非唯一的部分。它还包含程序的静态数据，如全局变量和常量。可执行文件还包含大量调试信息，这些信息会占用相当大的二进制文件大小，例如简单的符号表、基本类型信息（用于反射）和
    [PC-to-line 映射](https://oreil.ly/akAR2)（指令地址对应源代码中的行）。这些额外信息能够帮助宝贵的调试工具将机器代码与源代码链接起来。例如，许多调试工具使用它，如
    [“Go 中的性能分析”](ch09.html#ch-obs-profiling) 和前述的 `objdump` 工具。为了与 Delve 或 GDB 等调试软件兼容，二进制文件还附加了
    DWARF 表。^([10](ch04.html#idm45606835689456))
- en: On top of the already long list of responsibilities, the Go compiler must perform
    extra steps to ensure Go [memory safety](https://oreil.ly/kkCRb). For instance,
    the compiler can often tell during compile time that some commands will use a
    memory space that is safe to use (contains an expected data structure and is reserved
    for our program). However, there are cases when this cannot be determined during
    compilation, so additional checks have to be done at runtime, e.g., extra bound
    checks or nil checks.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 除了已有的责任清单外，Go 编译器必须执行额外的步骤，以确保 Go [内存安全性](https://oreil.ly/kkCRb)。例如，编译器通常可以在编译时确定某些命令将使用一个安全的内存空间（包含预期的数据结构并为我们的程序保留），但有时在编译期间无法确定，因此需要在运行时执行额外的检查，例如额外的边界检查或空指针检查。
- en: We will discuss this in more detail in [“Go Memory Management”](ch05.html#ch-hw-go-mem),
    but for our conversation about CPU, we need to acknowledge that such checks can
    take our valuable CPU time. While the Go compiler tries to eliminate these checks
    when unnecessary (e.g., in the bound check elimination stage during SSA optimizations),
    there might be cases where we need to write code in a way that helps the compiler
    eliminate some checks.^([11](ch04.html#idm45606835684112))
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 [“Go 内存管理”](ch05.html#ch-hw-go-mem) 中更详细地讨论这个问题，但是在我们关于 CPU 的对话中，我们需要认识到这些检查会占用我们宝贵的
    CPU 时间。虽然 Go 编译器在不必要时会尽力消除这些检查（例如在 SSA 优化的边界检查消除阶段），但在某些情况下，我们可能需要以一种有助于编译器消除某些检查的方式编写代码。^([11](ch04.html#idm45606835684112))
- en: 'There are many different configuration options for the Go build process. The
    first large batch of options can be passed through `go build -ldflags="<flags>"`,
    which represents [linker command options](https://oreil.ly/g8dvv) (the `ld` prefix
    traditionally stands for [Linux linker](https://oreil.ly/uJEda)). For example:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Go 构建过程，有许多不同的配置选项。第一批大批选项可以通过 `go build -ldflags="<flags>"` 传递，这代表 [链接器命令选项](https://oreil.ly/g8dvv)（`ld`
    前缀传统上代表 [Linux 链接器](https://oreil.ly/uJEda)）。例如：
- en: We can omit the DWARF table, thus reducing the binary size using `-ldflags="-w"`
    (recommended for production build if you don’t use debuggers there).
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过 `-ldflags="-w"` 来省略 DWARF 表，从而减小二进制文件大小（如果您在生产环境中不使用调试器，则推荐使用此选项）。
- en: We can further reduce the size with `-ldflags= "-s -w"`, removing the DWARF
    and symbols tables with other debug information. I would not recommend the latter
    option, as non-DWARF elements allow important runtime routines, like gathering
    profiles.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似地，使用 `-ldflags= "-s -w"` 可以进一步减小二进制文件的大小，删除 DWARF 和其他调试信息中的符号表。我不建议使用后者选项，因为非
    DWARF 元素允许重要的运行时例程，例如收集配置文件。
- en: 'Similarly, `go build -gcflags="<flags>"` represents [Go compiler options](https://oreil.ly/rRtRs)
    (`gc` stands for `Go Compiler`; don’t confuse it with GC, which means garbage
    collection, as explained in [“Garbage Collection”](ch05.html#ch-hw-garbage)).
    For example:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，`go build -gcflags="<flags>"` 代表 [Go 编译器选项](https://oreil.ly/rRtRs)（`gc`
    代表 `Go Compiler`；不要与 GC 混淆，后者指的是垃圾回收，如 [“垃圾回收”](ch05.html#ch-hw-garbage) 中所述）。例如：
- en: '`-gcflags="-S"` prints Go Assembly from the source code.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-gcflags="-S"` 打印出 Go 汇编代码。'
- en: '`-gcflags="-N"` disables all compiler optimizations.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-gcflags="-N"` 禁用所有编译器优化。'
- en: '`-gcflags="-m=<number>` builds the code while printing the main optimization
    decisions, where the number represents the level of detail. See [Example 4-3](#code-comp-sum)
    for the automatic compiler optimizations made on our `Sum` function in [Example 4-1](#code-sum).'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-gcflags="-m=<number>` 在打印主要优化决策的同时构建代码，其中数字表示详细级别。参见[示例 4-3](#code-comp-sum)
    中我们在 [示例 4-1](#code-sum) 中的 `Sum` 函数上自动编译器优化。'
- en: Example 4-3\. Output of `go build -gcflags="-m=1" sum.go` on [Example 4-1](#code-sum)
    code
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-3\. `go build -gcflags="-m=1" sum.go` 在 [示例 4-1](#code-sum) 代码上的输出
- en: '[PRE2]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO3-1)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO3-1)'
- en: '`os.ReadFile` and `bytes.Split` are short enough, so the compiler can copy
    the whole body of the `Sum` function.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`os.ReadFile` 和 `bytes.Split` 足够简短，所以编译器可以复制 `Sum` 函数的整个主体。'
- en: '[![2](assets/2.png)](#co_how_go_uses_the_cpu_resource__or_two__CO3-3)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_how_go_uses_the_cpu_resource__or_two__CO3-3)'
- en: The `fileName` argument is “leaking,” meaning this function keeps its parameter
    alive after it returns (it can still be on stack, though).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`fileName` 参数“泄漏”，意味着这个函数在返回后仍然保持其参数活动状态（尽管可能仍在堆栈上）。'
- en: '[![3](assets/3.png)](#co_how_go_uses_the_cpu_resource__or_two__CO3-4)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_how_go_uses_the_cpu_resource__or_two__CO3-4)'
- en: Memory for `[]byte("\n")` will be allocated on the stack. Messages like this
    help debug escape analysis. Learn more about it [here](https://oreil.ly/zBCyO).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`[]byte("\n")` 的内存将分配在堆栈上。像这样的消息有助于调试逃逸分析。在这里了解更多信息：[链接](https://oreil.ly/zBCyO)。'
- en: '[![4](assets/4.png)](#co_how_go_uses_the_cpu_resource__or_two__CO3-5)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_how_go_uses_the_cpu_resource__or_two__CO3-5)'
- en: Memory for `string(line)` will be allocated in a more expensive heap.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`string(line)` 的内存将分配在更昂贵的堆中。'
- en: The compiler will print more details with an increased `-m` number. For example,
    `-m=3` will explain why certain decisions were made. This option is handy when
    we expect certain optimization (inlining or keeping variables on the stack) to
    occur, but we still see an overhead while benchmarking in our TFBO cycle ([“Efficiency-Aware
    Development Flow”](ch03.html#ch-conq-eff-flow)).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当增加 `-m` 数字时，编译器将打印更多详细信息。例如，`-m=3` 将解释为什么会做出某些决策。在我们预期某些优化（如内联或保持变量在堆栈上）发生时，但在我们的
    TFBO 周期（“效率感知开发流程”](ch03.html#ch-conq-eff-flow)）的基准测试中仍然看到开销时，此选项非常方便。
- en: The Go compiler implementation is highly tested and mature, but there are limitless
    ways of writing the same functionality. There might be edge cases when our implementation
    confuses the compiler, so it does not apply certain naive implementations. Benchmarking
    if there is a problem, profiling the code, and confirming with the `-m` option
    help. More detailed optimizations can also be printed using further options. For
    example, `-gcflags="-d=ssa/check_bce/debug=1"` prints all bound check elimination
    optimizations.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Go 编译器实现经过高度测试和成熟，但编写相同功能的方法有无数种。当我们的实现让编译器困惑时，可能不会应用某些天真的实现。通过性能基准测试是否存在问题，分析代码并确认
    `-m` 选项有助于解决问题。更详细的优化也可以使用进一步的选项打印出来。例如，`-gcflags="-d=ssa/check_bce/debug=1"`
    打印出所有边界检查消除优化。
- en: The Simpler the Code, the More Effective Compiler Optimizations Will Be
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码越简单，编译器的优化效果就会越好
- en: Too-clever code is hard to read and makes it difficult to maintain programmed
    functionality. But it also can confuse the compiler that tries to match patterns
    with their optimized equivalents. Using idiomatic code, keeping your functions
    and loops straightforward, increases the chances that the compiler applies the
    optimizations so you don’t need to!
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 太聪明的代码难以阅读，并使得维护编程功能变得困难。但它也会使得试图匹配优化等效的模式的编译器感到困惑。使用惯用代码，保持函数和循环简单直接，增加编译器应用优化的机会，这样你就不需要！
- en: Knowing compiler internals helps, especially when it comes to more advanced
    optimizations tricks, which among other things, help compilers optimize our code.
    Unfortunately, it also means our optimizations might be a bit fragile regarding
    portability between different compiler versions. The Go team reserves rights to
    change compiler implementation and flags since they are not part of any specification.
    This might mean that the way you wrote a function that allows automatic inline
    by the compiler might not trigger inline in the next version of the Go compiler.
    This is why it’s even more important to benchmark and closely observe the efficiency
    of your program when you switch to a different Go version.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉编译器内部特性是有帮助的，尤其是在涉及更高级优化技巧时，这些技巧帮助编译器优化我们的代码。不幸的是，这也意味着我们的优化在不同编译器版本之间可能有些脆弱性。Go
    团队保留更改编译器实现和标志的权利，因为它们不属于任何规范的一部分。这可能意味着你编写的一个允许编译器自动内联的函数，在下一个版本的 Go 编译器中可能不会触发内联。因此，当你切换到不同版本的
    Go 时，更加重要的是进行基准测试并密切观察程序的效率。
- en: To sum up, the compilation process has a crucial role in offloading programmers
    from pretty tedious work. Without compiler optimizations, we would need to write
    more code to get to the same efficiency level while sacrificing readability and
    portability. Instead, if you focus on making your code simple, you can trust that
    the Go compiler will do a good enough job. If you need to increase efficiency
    for a particular hot path, it might be beneficial to double-check if the compiler
    did what you expected. For example, it might be that the compiler did not match
    our code with common optimization; there is some extra memory safety check that
    the compiler could further eliminate or function that could be inlined but was
    not. In very extreme cases, there might be even a value to write a dedicated assembly
    code and import it from the Go code.^([12](ch04.html#idm45606835565472))
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，编译过程在解放程序员免于繁琐工作方面起着至关重要的作用。没有编译器优化，我们需要编写更多代码才能达到相同的效率水平，同时牺牲可读性和可移植性。相反，如果你专注于使你的代码简单化，你可以相信
    Go 编译器会做一个足够好的工作。如果你需要提高特定热路径的效率，最好再次确认编译器是否按预期进行了操作。例如，编译器可能没有将我们的代码与常见的优化匹配；可能有一些额外的内存安全检查编译器可以进一步消除，或者可能有可以内联但未被内联的函数。在极端情况下，可能需要编写专门的汇编代码，并从
    Go 代码中导入它。^([12](ch04.html#idm45606835565472))
- en: The Go building process constructs fully executable machine code from our Go
    source code. The operating system loads machine code to memory and writes the
    first instruction address to the program counter (PC) register when it needs to
    be executed. From there, the CPU core can compute each instruction one by one.
    At first glance, it might mean that the CPU has a relatively simple job to do.
    But unfortunately, a memory wall problem causes CPU makers to continuously work
    on additional hardware optimizations that change how these instructions are executed.
    Understanding these mechanisms will allow us to control the efficiency and speed
    of our Go programs even better. Let’s uncover this problem in the next section.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Go 的构建过程从我们的 Go 源代码中构建出完全可执行的机器码。当操作系统需要执行时，将机器码加载到内存中，并将第一条指令地址写入程序计数器（PC）寄存器。从那里开始，CPU
    核心可以逐条计算每条指令。乍一看，这可能意味着 CPU 的工作相对简单。但不幸的是，内存墙问题导致 CPU 制造商不断进行额外的硬件优化，改变这些指令执行的方式。理解这些机制将使我们更好地控制我们的
    Go 程序的效率和速度。让我们在下一节揭示这个问题。
- en: CPU and Memory Wall Problem
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CPU 和内存墙问题
- en: To understand the memory wall and its consequences, let’s dive briefly into
    CPU core internals. The details and implementation of the CPU core change over
    time for better efficiency (usually getting more complex), but the fundamentals
    stay the same. In principle, a Control Unit, shown in [Figure 4-1](#img-uma),
    manages reads from memory through various L-caches (from smallest and fastest),
    decodes program instructions, coordinates their execution in the Arithmetic Logic
    Unit (ALU), and handles interruptions.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解内存墙及其后果，让我们简要深入探讨 CPU 核心内部。CPU 核心的详细信息和实现随时间改变以获得更好的效率（通常变得更加复杂），但基本原理保持不变。原则上，控制单元（如
    [图 4-1](#img-uma) 所示）通过各种 L-cache（从最小且最快的开始）管理从内存中读取的操作，解码程序指令，协调它们在算术逻辑单元（ALU）中的执行，并处理中断。
- en: An important fact is that the CPU works in cycles. Most CPUs in one cycle can
    perform one instruction on one set of tiny data. This pattern is called the Single
    Instruction Single Data (SISD) in characteristics mentioned in [Flynn’s taxonomy](https://oreil.ly/oQu0M),
    and it’s the key aspect of the von Neumann architecture. Some CPUs also allow
    Single Instruction Multiple Data (SIMD)^([13](ch04.html#idm45606835552784)) processing
    with special instructions like SSE, which allows the same arithmetic operation
    on four floating numbers in one cycle. Unfortunately, these instructions are not
    straightforward to use in Go and are therefore quite rarely seen.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的事实是CPU按周期工作。大多数CPU在一个周期内可以对一组小数据执行一条指令。这种模式被称为冯·诺依曼结构的特征中提到的“单指令单数据（SISD）”，这是冯·诺依曼结构的关键方面。一些CPU还允许使用特殊指令如SSE进行“单指令多数据（SIMD）”处理，允许在一个周期内对四个浮点数进行相同的算术运算。不幸的是，这些指令在Go语言中使用起来并不直接，因此相当少见。
- en: Meanwhile, registers are the fastest local storage available to the CPU core.
    Because they are small circuits wired directly into the ALU, it takes only one
    CPU cycle to read their data. Unfortunately, there are also only a few of them
    (depending on the CPU, typically 16 for general use), and their size is usually
    not larger than 64 bits. This means they are used as short-time variables in our
    program lifetime. Some of the registers can be used for our machine code. Others
    are reserved for CPU use. For example, the [PC register](https://oreil.ly/TvHVd)
    holds the address of the next instruction that the CPU should fetch, decode, and
    execute.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，寄存器是CPU核心可用的最快本地存储。由于它们是直接连接到ALU的小电路，仅需一个CPU周期即可读取它们的数据。不幸的是，它们数量有限（取决于CPU，通常为16个用于一般用途），且其大小通常不超过64位。这意味着它们在程序生命周期中被用作短期变量。一些寄存器可以用于我们的机器码，而另一些则保留给CPU使用。例如，[PC寄存器](https://oreil.ly/TvHVd)保存着CPU应该获取、解码和执行的下一条指令的地址。
- en: Computation is all about the data. As we learned in [Chapter 1](ch01.html#ch-efficiency-matters),
    there is lots of data nowadays, scattered around different storage mediums—uncomparably
    more than what’s available to store in a single CPU register. Moreover, a single
    CPU cycle is faster than accessing data from the main memory (RAM)—on average,
    one hundred times faster, as we read from our rough napkin math of latencies in
    [Appendix A](app01.html#appendix-napkin-math) that we will use throughout this
    book. As discussed in the misconception [“Hardware Is Getting Faster and Cheaper”](ch01.html#ch-eff-s-hardware),
    technology allows us to create CPU cores with dynamic clock speed, yet the maximum
    is always around 4 GHz. Funny enough, the fact we can’t make faster CPU cores
    is not the most important problem since our CPU cores are already…​too fast! It’s
    a fact we cannot make faster memory, which causes the main efficiency issues in
    CPUs nowadays.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 计算完全围绕数据展开。正如我们在[第1章](ch01.html#ch-efficiency-matters)中学到的那样，如今有大量数据分散在不同的存储介质中——比可以存储在单个CPU寄存器中的数据量要多得多。此外，单个CPU周期比从主存储器（RAM）访问数据快——平均快100倍，这是我们在附录A中粗略的延迟数学计算中得出的结论，本书将沿用这些计算。正如我们在“硬件越来越快且便宜”的误解讨论中所述，技术使我们能够创建具有动态时钟速度的CPU核心，但其最大值始终约为4
    GHz。有趣的是，我们不能制造更快的CPU核心并不是最重要的问题，因为我们的CPU核心已经……太快了！事实上，我们无法制造更快的内存才是当前CPU主要效率问题的原因。
- en: We can execute something in the ballpark of 36 billion instructions every second.
    Unfortunately, most of that time is spent waiting for data. About 50% of the time
    in almost every application. In some applications upwards of 75% of the time is
    spent waiting for data rather than executing instructions. If this horrifies you,
    good. It should.
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们可以每秒执行大约360亿条指令。不幸的是，大部分时间都花在等待数据上。几乎每个应用程序中约50%的时间都在等待数据。在某些应用程序中，高达75%的时间都是在等待数据而不是执行指令。如果这让你感到恐惧，那就对了。确实应该如此。
- en: ''
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Chandler Carruth, [“Efficiency with Algorithms, Performance with Data Structures”](https://oreil.ly/I55mm)
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Chandler Carruth，《“算法效率，数据结构性能”》（https://oreil.ly/I55mm）
- en: The aforementioned problem is often referred to as a [“memory wall” problem](https://oreil.ly/l5zgk).
    As a result of this problem, we risk wasting dozens, if not hundreds, of CPU cycles
    per single instruction, since fetching that instruction and data (and then saving
    the results) takes ages.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 上述问题通常被称为[“内存墙问题”](https://oreil.ly/l5zgk)。由于这个问题，我们面临着浪费几十甚至几百个CPU周期来执行单条指令的风险，因为获取该指令和数据（然后保存结果）需要很长时间。
- en: This problem is so prominent that it has triggered recent discussions about
    [revisiting von Neumann’s architecture](https://oreil.ly/xqbNU) as machine learning
    (ML) workloads (e.g., neural networks) for artificial intelligence (AI) use become
    more popular. These workloads are especially affected by the memory wall problem
    because most of the time is spent performing complex matrix math calculations,
    which require traversing large amounts of memory.^([14](ch04.html#idm45606835540240))
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题如此突出，以至于最近有关于[重新审视冯·诺依曼体系结构](https://oreil.ly/xqbNU)的讨论。随着人工智能（AI）使用的机器学习（如神经网络）工作负载变得更加流行，这些工作负载特别受到内存墙问题的影响。因为大部分时间都花在执行复杂的矩阵数学计算上，这需要遍历大量内存。^([14](ch04.html#idm45606835540240))
- en: 'The memory wall problem effectively limits how fast our programs do their job.
    It also impacts the overall energy efficiency that matters for mobile applications.
    Nevertheless, it is the best common general-purpose hardware nowadays. Industry
    mitigated many of these problems by developing a few main CPU optimizations we
    will discuss below: the hierarchical cache system, pipelining, out-of-order execution,
    and hyperthreading. These directly impact our low-level Go code efficiency, especially
    in terms of how fast our program will be executed.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 内存墙问题有效地限制了我们的程序执行速度。它还影响移动应用程序的总体能效，这对于移动应用程序尤为重要。尽管如此，它是目前为止最佳的通用硬件。行业通过开发几个主要CPU优化措施来缓解这些问题，我们将在下面讨论：分层缓存系统、流水线处理、乱序执行和超线程。这些直接影响我们的低级Go代码效率，特别是程序执行速度方面。
- en: Hierachical Cache System
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分层缓存系统
- en: All modern CPUs include local, fast, small caches for often-used data. L1, L2,
    L3 (and sometimes L4) caches are on-chip static random-access memory (SRAM) circuits.
    SRAM uses different technology for storing data faster than our main memory RAM
    but is much more expensive to use and produce in large capacities (main memory
    is explained in [“Physical Memory”](ch05.html#ch-hw-memory-ph)). Therefore, L-caches
    are touched first when the CPU needs to fetch instruction or data for an instruction
    from the main memory (RAM). The way the CPU is using L-caches is presented in
    [Figure 4-3](#img-hw-lcaches).^([15](ch04.html#idm45606835530224)) In the example,
    we will use a simple CPU instruction `MOVQ`, explained in [Example 4-2](#code-sum-asm).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 所有现代CPU都包括用于常用数据的本地、快速、小型缓存。L1、L2、L3（有时还有L4）缓存是芯片上的静态随机访问存储器（SRAM）电路。SRAM使用不同的技术存储数据，比我们的主内存RAM更快，但在大容量下的使用和生产成本更高（主内存在[“物理内存”](ch05.html#ch-hw-memory-ph)中有解释）。因此，当CPU需要从主内存（RAM）获取指令或数据来执行指令时，首先接触L缓存。CPU使用L缓存的方式在[图4-3](#img-hw-lcaches)中展示。^([15](ch04.html#idm45606835530224))
    在示例中，我们将使用一个简单的CPU指令`MOVQ`，在[示例4-2](#code-sum-asm)中有解释。
- en: '![efgo 0403](assets/efgo_0403.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0403](assets/efgo_0403.png)'
- en: Figure 4-3\. The “look up” cache method performed by the CPU to read bytes from
    the main memory through L-caches
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-3. CPU执行的“查找”缓存方法来从主内存中读取字节，通过L缓存
- en: To copy 64 bits (`MOVQ` command) from a specific memory address to register
    `SI`, we must access the data that normally resides in the main memory. Since
    reading from RAM is slow, it uses L-caches to check for data first. The CPU will
    ask the L1 cache for these bytes on the first try. If the data is not there (cache
    miss), it visits a larger L2 cache, then the largest cache L3, then eventually
    main memory (RAM). In any of these misses, the CPU will try to fetch the complete
    “cache line” (typically 64 bytes, so eight times the size of the register), save
    it in all caches, and only use these specific bytes.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要从特定内存地址复制64位（`MOVQ`命令）到寄存器`SI`，我们必须访问通常驻留在主内存中的数据。由于从RAM读取速度较慢，它使用L缓存首先检查数据。CPU在第一次尝试时将向L1缓存请求这些字节。如果数据不在那里（缓存未命中），它会访问更大的L2缓存，然后是最大的L3缓存，最终是主内存（RAM）。在任何这些未命中情况下，CPU将尝试获取完整的“缓存行”（通常为64字节，因此是寄存器大小的8倍），保存在所有缓存中，并仅使用这些特定字节。
- en: Reading more bytes at once (cache line) is useful as it takes the same latency
    as reading a single byte (explained in [“Physical Memory”](ch05.html#ch-hw-memory-ph)).
    Statistically, it is also likely that the next operation needs bytes next to the
    previously accessed area. L-caches partially mitigate the memory latency problem
    and reduce the overall amount of data to be transferred, preserving memory bandwidth.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一次性读取更多字节（缓存行）在性能上非常有用，因为它的延迟与读取单个字节相同（在[“物理内存”](ch05.html#ch-hw-memory-ph)中解释）。从统计上讲，下一个操作可能需要访问之前访问区域的相邻字节。L缓存部分缓解了内存延迟问题，并减少了要传输的总数据量，保持了内存带宽。
- en: The first direct consequence of having L-caches in our CPUs is that the smaller
    and more aligned the data structure we define, the better the efficiency. Such
    a structure will have more chances to fit fully in lower-level caches and avoid
    expensive cache misses. The second result is that instructions on sequential data
    will be faster since cache lines typically contain multiple items stored next
    to each other.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的CPU中引入L缓存的第一个直接结果是，我们定义的数据结构越小且更对齐，效率就越高。这样的结构更有可能完全适应较低级别的缓存，并避免昂贵的缓存未命中。第二个结果是，对于顺序数据的指令将更快，因为缓存行通常包含相邻存储的多个项。
- en: Pipelining and Out-of-Order Execution
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流水线和乱序执行
- en: If the data were magically accessible in zero time, we would have a perfect
    situation where every CPU core cycle performs a meaningful instruction, executing
    instructions as fast as CPU core speed allows. Since this is not the case, modern
    CPUs try to keep every part of the CPU core busy using cascading pipelining. In
    principle, the CPU core can perform many stages required for instruction execution
    at once in one cycle. This means we can exploit Instruction-Level Parallelism
    (ILP) to execute, for example, five independent instructions in five CPU cycles,
    giving us that sweet average of one instruction per cycle (IPC).^([16](ch04.html#idm45606835511424))
    For example, in an [initial 5-stage pipeline system](https://oreil.ly/ccBg2) (modern
    CPUs have 14–24 stages!), a single CPU core computes 5 instructions at the same
    time within a cycle, as presented in [Figure 4-4](#img-hw-cpupipe).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据能够在零时间内魔法般地访问，那么我们将拥有每个CPU核心周期执行有意义指令的完美情况，以CPU核心速度允许的速度执行指令。由于这并非事实，现代CPU尝试通过级联流水线保持CPU核心的每个部分繁忙。原则上，CPU核心可以在一个周期内同时执行指令执行所需的多个阶段。这意味着我们可以利用指令级并行性（ILP）执行，例如，在五个CPU周期内执行五条独立指令，平均每个周期执行一条指令（IPC）[^16]。例如，在[初始的五阶段流水线系统](https://oreil.ly/ccBg2)（现代CPU具有14-24个阶段！），单个CPU核心可以在一个周期内同时计算5条指令，如图[4-4](#img-hw-cpupipe)所示。
- en: '![efgo 0404](assets/efgo_0404.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0404](assets/efgo_0404.png)'
- en: Figure 4-4\. Example five-stage pipeline
  id: totrans-134
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-4。示例五阶段流水线
- en: 'The classic five-stage pipeline consists of five operations:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的五阶段流水线包括五个操作：
- en: '`IF`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`IF`'
- en: Fetch the instruction to execute.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 获取要执行的指令。
- en: '`ID`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`ID`'
- en: Decode the instruction.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 解码指令。
- en: '`EX`'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`EX`'
- en: Start the execution of the instruction.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 执行指令。
- en: '`MEM`'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`MEM`'
- en: Fetch the operands for the execution.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 获取执行操作的操作数。
- en: '`WB`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`WB`'
- en: Write back the result of the operation (if any).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 返回操作结果（如果有）。
- en: To make it even more complex, as we discussed in the L-caches section, it is
    rarely the case that even the fetch of the data (e.g., the `MEM` stage) takes
    only one cycle. To mitigate this, the CPU core also employs [a technique called
    out-of-order execution](https://oreil.ly/ccBg2). In this method, the CPU attempts
    to schedule instructions in an order governed by the availability of the input
    data and execution unit (if possible) rather than by their original order in the
    program. For our purposes, it is enough to think about it as a complex, more dynamic
    pipeline that utilizes internal queues for more efficient CPU execution.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在L缓存部分讨论的那样，更复杂的是，即使是数据的获取（例如`MEM`阶段）也很少仅仅需要一个周期。为了缓解这一点，CPU核心还采用了一种称为[乱序执行](https://oreil.ly/ccBg2)的技术。在这种方法中，CPU试图按照输入数据和执行单元的可用性（如果可能）而不是按照程序中的原始顺序安排指令。对于我们的目的，把它看作是一个利用内部队列进行更有效CPU执行的复杂、更动态的流水线即可。
- en: The resulting pipelined and out-of-order CPU execution is complex, but the preceding
    simplified explanation should be all we need to understand two critical consequences
    for us as developers. The first, trivial one is that every switch of the instruction
    stream has a huge cost (e.g., in latency),^([17](ch04.html#idm45606835495520))
    because the pipeline has to reset and start from scratch, on top of the obvious
    cache trashing. We haven’t yet mentioned the operating system overhead that must
    be added on top. We often call this a *context switch*, which is inevitable in
    modern computers since the typical operating systems use preemptive task scheduling.
    In these systems, the execution flow of the single CPU core can be preempted many
    times a second, which might matter in extreme cases. We will discuss how to influence
    such behavior in [“Operating System Scheduler”](#ch-hw-os-scheduler).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 由此产生的流水线和乱序 CPU 执行是复杂的，但前述的简化解释应该足够我们理解作为开发人员的两个关键后果。第一个微不足道的后果是，每次指令流的切换都具有巨大的成本（例如，延迟方面），^([17](ch04.html#idm45606835495520))因为流水线必须重置并从头开始，再加上明显的缓存崩溃。我们还未提及必须添加的操作系统开销。我们经常称之为*上下文切换*，这在现代计算机中是不可避免的，因为典型操作系统使用抢占式任务调度。在这些系统中，单个
    CPU 核心的执行流可能每秒被抢占多次，这在极端情况下可能很重要。我们将讨论如何影响这种行为在[“操作系统调度器”](#ch-hw-os-scheduler)中。
- en: The second consequence is that the more predictive our code is, the better.
    This is because pipelining requires the CPU cores to perform complex *branch predictions*
    to find instructions that will be executed after the current one. If our code
    is full of branches like `if` statements, `switch` cases, or jump statements like
    `continue`, finding even two instructions to execute simultaneously might be impossible,
    simply because one instruction might decide on what instruction will be done next.
    This is called data dependency. Modern CPU core implementation goes even further
    by performing speculative execution. Since it does not know which instruction
    is next, it picks the most likely one and assumes that such a branch will be chosen.
    Unnecessary executions on the wrong branches are better than wasted CPU cycles
    doing nothing. Therefore, many branchless coding techniques have emerged, which
    help the CPU predict branches and might result in faster code. Some methods are
    applied automatically by the [Go compiler](https://oreil.ly/VqKzx), but sometimes,
    manual improvements have to be added.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个后果是我们的代码越具有预测性，效果越好。这是因为流水线需要 CPU 核心进行复杂的*分支预测*，以找到在当前指令之后执行的指令。如果我们的代码充满像
    `if` 语句、`switch` 语句或者像 `continue` 这样的跳转语句，那么甚至可能找不到两个可以同时执行的指令，因为一个指令可能决定接下来执行哪条指令。这被称为数据依赖性。现代
    CPU 核心的实现甚至进一步执行推测执行。因为它不知道下一条指令是什么，它选择最有可能的一条并假设将选择这样的分支。与浪费 CPU 周期无所作为相比，错误分支上的不必要执行更为可取。因此，出现了许多无分支编码技术，帮助
    CPU 预测分支并可能导致更快的代码执行。某些方法由[Go 编译器](https://oreil.ly/VqKzx)自动应用，但有时需要手动改进。
- en: Generally speaking, the simpler the code, with fewer nested conditionals and
    loops, the better for the branch predictor. This is why we often hear that the
    code that “leans to the left” is faster.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 通常来说，代码越简单，嵌套条件和循环越少，对于分支预测器越好。这就是为什么我们经常听说“向左倾斜”的代码更快。
- en: In my experience [I saw] repeatedly that code that wants to be fast, go to the
    left of the page. So if you [write] like a loop and the if, and the for and a
    switch, it’s not going to be fast. By the way, the Linux kernel, do you know what
    the coding standard is? Eight characters tab, 80 characters line width. You can’t
    write bad code in the Linux kernel. You can’t write slow code there. ... The moment
    you have too many ifs and decision points ... in your code, the efficiency is
    out of the window.
  id: totrans-150
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 依我看，一再看到想要快速的代码，都会向页面的左边去。所以如果你写像一个循环和 if、for 和 switch 这样的语句，那么它不会快。顺便说一下，Linux
    内核，你知道编码标准是什么吗？八个字符的制表符，80个字符的行宽。你不能在 Linux 内核中写糟糕的代码。你不能在那里写慢代码。……一旦你的代码中有太多的
    if 和决策点……效率就没了。
- en: ''
  id: totrans-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Andrei Alexandrescu, [“Speed Is Found in the Minds of People”](https://oreil.ly/6mERC)
  id: totrans-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Andrei Alexandrescu, [“人们思维中的速度”](https://oreil.ly/6mERC)
- en: The existence of branch predictors and speculative approaches in the CPU has
    another consequence. It causes contiguous memory data structures to perform much
    better in pipelined CPU architecture with L-caches.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 中分支预测器和推测性方法的存在有另一个后果。这导致在具有 L 缓存的流水线 CPU 架构中，连续内存数据结构的性能大大提高。
- en: Contiguous Memory Structure Matters
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连续内存结构的重要性
- en: Practically speaking, on modern CPUs, developers in most cases should prefer
    contiguous memory data structures like arrays instead of linked lists in their
    programs. This is because a typical linked-like list implementation (e.g., a tree)
    uses memory pointers to the next, past, child, or parent elements. This means
    that when iterating over such a structure, the CPU core can’t tell what data and
    what instruction we will do next until we visit the node and check that pointer.
    This effectively limits the speculation capabilities, causing inefficient CPU
    usage.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在现代CPU上，大多数情况下，开发者应该更倾向于使用连续的内存数据结构，比如数组，而不是链表。这是因为典型的链式结构实现（例如树）使用内存指针来指向下一个、过去的、子元素或父元素。这意味着当遍历这样的结构时，CPU核心在访问节点并检查该指针之前，无法预测接下来要执行的数据和指令。这有效地限制了推测能力，导致CPU使用效率低下。
- en: Hyper-Threading
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超线程
- en: Hyper-Threading is Intel’s proprietary name for the CPU optimization technique
    called [*simultaneous multithreading* (SMT)](https://oreil.ly/L5va6).^([18](ch04.html#idm45606835464576))
    Other CPU makers implement SMT too. This method allows a single CPU core to operate
    in a mode visible to programs and operating systems as two logical CPU cores.^([19](ch04.html#idm45606835463680))
    SMT prompts the operating system to schedule two threads onto the same physical
    CPU core. While a single physical core will never execute more than one instruction
    at a time, more instructions in the queue help make the CPU core busy during idle
    times. Given the memory access wait times, this can utilize a single CPU core
    more without impacting the latency of the process execution. In addition, extra
    registers in SMT enable CPUs to allow for faster context switches between multiple
    threads running on a single physical core.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 超线程是英特尔对CPU优化技术的专有名称，称为[*同时多线程* (SMT)](https://oreil.ly/L5va6).^([18](ch04.html#idm45606835464576))
    其他CPU制造商也实现了SMT。这种方法允许单个CPU核心以对程序和操作系统可见的方式运行为两个逻辑CPU核心。^([19](ch04.html#idm45606835463680))
    SMT促使操作系统在同一物理CPU核心上调度两个线程。虽然单个物理核心永远不会同时执行多个指令，但在队列中有更多指令有助于在空闲时使CPU核心忙碌。鉴于内存访问等待时间，这可以在不影响进程执行延迟的情况下更有效地利用单个CPU核心。此外，SMT中的额外寄存器使CPU能够更快地在单个物理核心上多个线程之间进行上下文切换。
- en: SMT has to be supported and integrated with the operating system. You should
    see twice as many cores as physical ones in your machine when enabled. To understand
    if your CPU supports Hyper-Threading, check the “thread(s) per core” information
    in the specifications. For example, using the `lscpu` Linux command in [Example 4-4](#code-lscpu),
    my CPU has two threads, meaning Hyper-Threading is available.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: SMT必须得到操作系统的支持和集成。当启用时，您应该在您的机器上看到比物理核心多两倍的核心。要了解您的CPU是否支持超线程，请查看规格中的“每核线程数”信息。例如，使用`lscpu`
    Linux命令在[示例 4-4](#code-lscpu)中，我的CPU有两个线程，这意味着超线程是可用的。
- en: Example 4-4\. Output of the `lscpu` command on my Linux laptop
  id: totrans-159
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-4\. 在我的Linux笔记本上执行`lscpu`命令的输出
- en: '[PRE3]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO4-1)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO4-1)'
- en: My CPU supports SMT, and it’s enabled on my Linux installation.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我的CPU支持SMT，并且在我的Linux安装中已启用。
- en: The SMT is usually enabled by default but can be turned to on demand on newer
    kernels. This poses one consequence when running our Go programs. We can usually
    choose if we should enable or disable this mechanism for our processes. But should
    we? In most cases, it is better to keep it enabled for our Go programs as it allows
    us to fully utilize physical cores when running multiple different tasks on a
    single computer. Yet, in some extreme cases, it might be worth dedicating full
    physical core to a single process to ensure the highest quality of service. Generally,
    a benchmark on each specific hardware should tell us.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，默认情况下启用SMT，但在新内核上可以根据需求进行调整。这在运行我们的Go程序时会有后果。通常，我们可以选择是否应该为我们的进程启用或禁用这种机制。但是，大多数情况下，最好保持启用状态，因为这使得我们可以在单台计算机上运行多个不同任务时充分利用物理核心。然而，在某些极端情况下，可能值得将整个物理核心专用于单个进程，以确保服务质量最高。一般来说，每个特定硬件的基准测试应该能告诉我们。
- en: To sum up, all the aforementioned CPU optimizations and the corresponding programming
    techniques utilizing that knowledge tend to be used only at the very end of the
    optimization cycle and only when we want to squeeze out the last dozen nanoseconds
    on the critical path.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，所有上述的 CPU 优化和相应的编程技术只在优化周期的最后阶段使用，并且只在我们想要在关键路径上挤出最后几十纳秒时使用。
- en: Three Principles of Writing CPU-Efficient Code on Critical Path
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写关键路径上 CPU 高效代码的三个原则
- en: 'The three basic rules that will yield CPU-friendly code are as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 会产生 CPU 友好代码的三条基本规则如下：
- en: Use algorithms that do less work.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用做更少工作的算法。
- en: Focus on writing low-complexity code that will be easier to optimize for the
    compiler and CPU branch predictors. Ideally, separate “hot” from “cold” code.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于编写低复杂度的代码，这样更容易为编译器和 CPU 分支预测器进行优化。理想情况下，将“热”代码与“冷”代码分开。
- en: Favor contiguous memory data structures when you plan to iterate or traverse
    over them a lot.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在计划经常迭代或遍历它们时，倾向于使用连续的内存数据结构。
- en: With this brief understanding of CPU hardware dynamics, let’s dive deeper into
    the essential software types that allow us to run thousands of programs simultaneously
    on shared hardware—schedulers.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对 CPU 硬件动态的简要了解，让我们深入探讨关键路径上运行成千上万程序的关键软件类型——调度器。
- en: Schedulers
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调度器
- en: Scheduling generally means allocating necessary, usually limited, resources
    for a certain process to finish. For example, assembling car parts must be tightly
    scheduled in a certain place at a certain time in a car factory to avoid downtime.
    We might also need to schedule a meeting among certain attendees with only certain
    time slots of the day free.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 调度通常意味着为某个进程分配必要的、通常是有限的资源以完成。例如，在汽车工厂中，组装汽车零部件必须在特定的地点和特定的时间紧密安排，以避免停机。我们还可能需要在某些时间段内安排会议参与者之间的会议。
- en: In modern computers or clusters of servers, we have thousands of programs that
    have to be running on shared resources like CPU, memory, network, disks, etc.
    That’s why the industry developed many types of scheduling software (commonly
    called *schedulers*) focused on allocating these programs to free resources on
    many levels.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代计算机或服务器集群中，我们有成千上万的程序需要在共享的资源如 CPU、内存、网络、磁盘等上运行。这就是为什么行业开发了许多类型的调度软件（通常称为*调度器*），专注于将这些程序分配给多个级别的空闲资源。
- en: In this section, we will discuss CPU scheduling. Starting from the bottom level,
    we have an operating system that schedules arbitrary programs on a limited number
    of physical CPUs. Operating system mechanisms should tell us how multiple programs
    running simultaneously can impact our CPU resources and, in effect, our own Go
    program execution latency. It will also help us understand how a developer can
    utilize multiple CPU cores simultaneously, in parallel or concurrently, to achieve
    faster execution.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论 CPU 调度。从底层开始，我们有一个操作系统，它在有限数量的物理 CPU 上调度任意程序。操作系统的机制应告诉我们同时运行多个程序如何影响我们的
    CPU 资源，以及如何影响我们自己的 Go 程序执行延迟。它还将帮助我们了解开发人员如何同时利用多个 CPU 内核，以并行或同时方式实现更快的执行。
- en: Operating System Scheduler
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作系统调度器
- en: As with compilers, there are many different operating systems (OSes), each with
    different task scheduling and resource management logic. While most of the systems
    operate on similar abstractions (e.g., threads, processes with priorities), we
    will focus on the Linux operating system in this book. Its core, called the kernel,
    has many important functionalities, like managing memory, devices, network access,
    security, and more. It also ensures program execution using a configurable component
    called a scheduler.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 与编译器一样，有许多不同的操作系统（OSes），每个都有不同的任务调度和资源管理逻辑。虽然大多数系统都在类似的抽象上操作（例如，带有优先级的线程、进程），但在本书中我们将专注于
    Linux 操作系统。它的核心称为内核，具有许多重要功能，如管理内存、设备、网络访问、安全性等。它还通过一个可配置的组件称为调度器来确保程序的执行。
- en: 'As a central part of resource management, the OS thread scheduler must maintain
    the following, simple, invariant: make sure that ready threads are scheduled on
    available cores.'
  id: totrans-177
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为资源管理的核心部分，操作系统线程调度器必须保持以下简单的不变性：确保准备好的线程在可用的核心上调度。
- en: ''
  id: totrans-178
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'J.P. Lozi et al., [“The Linux Scheduler: A Decade of Wasted Cores”](https://oreil.ly/bfiEW)'
  id: totrans-179
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: J.P. Lozi 等人的文章 [“Linux 调度器：十年浪费核心”](https://oreil.ly/bfiEW)
- en: The smallest scheduling unit for the Linux scheduler is called an [OS thread](https://oreil.ly/Lp2Sk).
    The thread (sometimes also referred to as a *task* or *lightweight process*) contains
    an independent set of machine code in the form of CPU instructions designed to
    run sequentially. While threads can maintain their execution state, stack, and
    register set, they cannot run out of context.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Linux 调度程序的最小调度单元称为[操作系统线程](https://oreil.ly/Lp2Sk)。线程（有时也称为*任务*或*轻量级进程*）包含独立的一组机器代码，以
    CPU 指令的形式顺序运行。虽然线程可以维护其执行状态、堆栈和寄存器集，但它们无法超出上下文运行。
- en: Each thread runs as a part of the process. The process represents a program
    in execution and can be identified by its Process Identification Number (PID).
    When we tell Linux OS to execute our compiled program, a new process is created
    (for example, when a [`fork`](https://oreil.ly/IPKYU) system call is used).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 每个线程作为进程的一部分运行。进程代表正在执行的程序，并可以通过其进程标识号（PID）进行识别。当我们告诉 Linux 操作系统执行我们编译的程序时，将创建一个新进程（例如使用[`fork`](https://oreil.ly/IPKYU)系统调用）。
- en: The process creation includes the assignment of a new PID, the creation of the
    initial thread with its machine code (our `func main()` in the Go code) and stack,
    files for standard outputs and input, and tons of other data (e.g., list of open
    file descriptors, statistics, limits, attributes, mounted items, groups, etc.).
    On top of that, a new memory address space is created, which has to be protected
    from other processes. All of that information is maintained under the dedicated
    directory */proc/`<PID>`* for the duration of the program execution.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 进程创建包括分配新的 PID、创建带有其机器代码的初始线程（例如 Go 代码中的`func main()`）和栈、标准输出和输入文件以及大量其他数据（例如打开文件描述符列表、统计数据、限制、属性、挂载项目、组等）。此外，还会创建新的内存地址空间，必须保护它免受其他进程的影响。所有这些信息在整个程序执行期间都在专用目录
    */proc/`<PID>`* 中维护。
- en: 'Threads can create new threads (e.g., using the [`clone`](https://oreil.ly/6qSg3)
    syscall) that will have independent machine code sequences but will share the
    same memory address space. Threads can also create new processes (e.g., using
    [`fork`](https://oreil.ly/idB06)) that will run in isolation and execute the desired
    program. Threads maintain their execution state: Running, Ready, and Blocked.
    Possible transformations of these states are presented in [Figure 4-5](#img-threads).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 线程可以创建新线程（例如使用[`clone`](https://oreil.ly/6qSg3)系统调用），这些线程将拥有独立的机器代码序列，但会共享同一内存地址空间。线程也可以创建新进程（例如使用[`fork`](https://oreil.ly/idB06)系统调用），这些进程将独立运行并执行所需程序。线程维护其执行状态：运行、准备和阻塞。这些状态的可能转换如图
    [4-5](#img-threads) 所示。
- en: 'Thread state tells the scheduler what the thread is doing at the moment:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 线程状态告诉调度程序线程当前正在做什么：
- en: Running
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 运行
- en: Thread is assigned to the CPU core and is doing its job.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 线程被分配到 CPU 核心并执行其工作。
- en: Blocked
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 阻塞
- en: Thread is waiting on some event that potentially takes longer than a context
    switch. For example, a thread reads from a network connection and is waiting for
    a packet or its turn on the mutex lock. This is an opportunity for the scheduler
    to step in and allow other threads to run.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 线程正在等待某个事件，该事件可能比上下文切换花费的时间更长。例如，线程从网络连接读取数据，正在等待数据包或者在互斥锁上的轮询。这是调度程序介入并允许其他线程运行的时机。
- en: Ready
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 准备
- en: Thread is ready for execution but is waiting for its turn.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 线程准备执行但正在等待轮到它。
- en: '![efgo 0405](assets/efgo_0405.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0405](assets/efgo_0405.png)'
- en: Figure 4-5\. Thread states as seen by the Linux OS scheduler
  id: totrans-192
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-5\. 线程状态在 Linux 操作系统调度程序中的显示
- en: As you might already notice, the Linux scheduler does a preemptive type of thread
    scheduling. Preemptive means the scheduler can freeze a thread execution at any
    time. In modern OS, we always have more threads to be executed than available
    CPU cores, so the scheduler must run multiple “ready” threads on a single CPU
    core. The thread is preempted every time it waits for an I/O request or other
    events. The thread can also tell the operating system to yield itself (e.g., using
    the [`sched_yield`](https://oreil.ly/QfnCs) syscall). When preempted, it enters
    a “blocked” state, and another thread can take its place in the meantime.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经注意到的那样，Linux 调度程序采用抢占式线程调度。抢占式意味着调度程序可以随时冻结线程的执行。在现代操作系统中，通常有多个线程等待执行，但可用的
    CPU 核心有限，因此调度程序必须在单个 CPU 核心上运行多个“准备好”的线程。每次线程等待 I/O 请求或其他事件时，线程被抢占。线程还可以告知操作系统放弃自己的执行（例如使用[`sched_yield`](https://oreil.ly/QfnCs)系统调用）。被抢占时，线程进入“阻塞”状态，其他线程可以顶替它暂时执行。
- en: The naive scheduling algorithm could wait for the thread to preempt itself.
    This would work great for I/O bound threads, which are often in the “Blocked”
    state—for example, interactive systems with graphical interfaces or lightweight
    web servers working with network calls. But what if the thread is CPU bound, which
    means it spends most of its time using only CPU and memory—for example, doing
    some computation-heavy jobs like linear search, multiplying matrixes, or brute-forcing
    a hashed password? In such cases, the CPU core could be busy on one task for minutes,
    which will starve all other threads in the system. For example, imagine not being
    able to type in your browser or resize a window for a minute—it would look like
    a long system freeze!
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 傻瓜调度算法可以等待线程抢占自身。这对于 I/O 绑定的线程非常有效，它们经常处于“阻塞”状态——例如，具有图形界面或与网络调用交互的轻量级 Web 服务器的交互系统。但如果线程是
    CPU 绑定的，这意味着它大部分时间只使用 CPU 和内存——例如，执行一些计算密集型的工作如线性搜索、矩阵乘法或暴力破解散列密码？在这种情况下，CPU 核心可能在一个任务上忙碌数分钟，这将使系统中所有其他线程饿死。例如，想象一下在浏览器中无法输入或调整窗口大小一分钟——看起来像是系统长时间冻结！
- en: 'This primary Linux scheduler implementation addresses that problem. It is called
    a Completely Fair Scheduler (CFS), and it assigns threads in short turns. Each
    thread is given a certain slice of the CPU time, typically something between 1
    ms and 20 ms, which creates the illusion that threads are running simultaneously.
    It especially helps desktop systems, which must be responsive to human interactions.
    There are a few other important consequences of that design:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这个主要的 Linux 调度器实现解决了这个问题。它被称为完全公平调度器（CFS），并且它为线程分配了短暂的轮换时间。每个线程被赋予一定的 CPU 时间片，通常在
    1 毫秒到 20 毫秒之间，这造成了线程同时运行的假象。这对必须对人类交互保持响应的桌面系统尤其有帮助。这种设计还有一些其他重要的后果：
- en: The more threads that want to be executed, the less time they will have in each
    turn. However, this can result in lower productive utilization of the CPU core,
    which starts to spend more time on expensive context switches.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要执行的线程越多，它们每次轮换的时间就越少。然而，这可能导致 CPU 核心的生产利用率降低，开始花费更多时间进行昂贵的上下文切换。
- en: On the overloaded machine, each thread has shorter turns on the CPU core and
    can also end up having fewer turns per second. While none of the threads is completely
    starved (blocked), their execution can significantly slow down.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在过载的机器上，每个线程在 CPU 核心上的轮换时间较短，也可能每秒的轮换次数较少。虽然没有线程完全饥饿（阻塞），它们的执行速度可能会显著减慢。
- en: CPU Overloading
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: CPU 过载
- en: Writing CPU-efficient code means our program wastes significantly fewer CPU
    cycles. Of course, this is always great, but the efficient implementation might
    be still doing its job very slowly if the CPU is overloaded.
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编写高效的 CPU 代码意味着我们的程序浪费的 CPU 周期显著减少。当然，这总是很好的，但是如果 CPU 过载，即使是高效的实现也可能表现得非常缓慢。
- en: An overloaded CPU or system means too many threads are competing for the available
    CPU cores. As a result, the machine might be overscheduled, or a process or two
    spawns too many threads to perform some heavy task (we call this situation a *noisy
    neighbor*). If an overloaded CPU situation occurs, checking the machine CPU utilization
    metric should show us CPU cores running at 100% capacity. Every thread will be
    executed slower in such a case, resulting in a frozen system, timeouts, and lack
    of responsiveness.
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CPU 过载或系统意味着太多的线程在竞争可用的 CPU 核心。因此，机器可能被超调度，或者一个或两个进程生成了太多的线程来执行某些重型任务（我们称这种情况为*嘈杂的邻居*）。如果出现
    CPU 过载情况，检查机器的 CPU 利用率指标应该显示 CPU 核心以 100% 的容量运行。在这种情况下，每个线程的执行都会变慢，导致系统冻结、超时和缺乏响应。
- en: It is hard to rely on pure program execution latency (sometimes referred to
    as *wall time* or *wall-clock time*) to estimate our program CPU efficiency. This
    is because modern OS schedulers are preemptive, and the program often waits for
    other I/O or synchronizations. As a result, it’s pretty hard to reliably check
    if, after a fix, our program utilizes the CPU better than the previous implementation.
    This is why the industry defined an important metric to gather how long our program’s
    process (all its threads) spent in the “Running” state on all CPU cores. We usually
    call it CPU time and we will discuss it in [“CPU Usage”](ch06.html#ch-obs-cpu-usage).
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依靠纯程序执行延迟（有时称为 *墙上时间* 或 *墙钟时间*）来估算我们程序的 CPU 效率是困难的。这是因为现代操作系统调度器是抢占式的，而程序通常会等待其他
    I/O 或同步操作。因此，要可靠地检查在修复后，我们的程序是否比以前的实现更有效地利用了 CPU，这是相当困难的。这就是为什么行业定义了一个重要的度量标准，用于收集我们程序进程（所有其线程）在所有
    CPU 核心上处于“运行”状态的时间。我们通常称之为 CPU 时间，并将在 [“CPU 使用率”](ch06.html#ch-obs-cpu-usage)
    中讨论。
- en: CPU Time on an Overloaded Machine
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在负载过重的机器上的 CPU 时间
- en: Measuring CPU time is a great way to check our program’s CPU efficiency. However,
    be careful when looking at the CPU time from some narrow window of process execution
    time. For example, lower CPU time might mean our process was not using much CPU
    during that moment, but it might also represent an overloaded CPU.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测量 CPU 时间是检查我们程序 CPU 效率的一种好方法。然而，在查看某个进程执行时间的狭窄窗口时要小心。例如，较低的 CPU 时间可能意味着我们的进程在那一时刻没有使用太多
    CPU，但它也可能表示 CPU 负载过重。
- en: Overall, sharing processes on the same system has its problems. That’s why in
    virtualized environments, we tend to reserve these resources. For example, we
    can limit CPU use of one process to 200 milliseconds of CPU time per second, so
    20% of one CPU core.
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 总体而言，在同一系统上共享进程存在问题。这就是为什么在虚拟化环境中，我们倾向于保留这些资源的原因。例如，我们可以将一个进程的 CPU 使用限制为每秒钟
    200 毫秒的 CPU 时间，这相当于一个 CPU 核心的 20%。
- en: The final consequence of the CFS design is that it is too fair to ensure dedicated
    CPU time for a single thread. The Linux scheduler has priorities, a user-configurable
    “niceness” flag, and different scheduling policies. Modern Linux OS even has a
    scheduling policy that uses a special real-time scheduler in place of CFS for
    threads that need to be executed in the first order.^([20](ch04.html#idm45606835364128))
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CFS 设计的最终后果是，它对于确保单个线程专用的 CPU 时间过于公平了。Linux 调度器具有优先级、用户可配置的“niceness”标志以及不同的调度策略。现代
    Linux 操作系统甚至有一种调度策略，用特殊的实时调度程序替代 CFS，以执行需要第一顺序执行的线程。^([20](ch04.html#idm45606835364128))
- en: Unfortunately, even with a real-time scheduler, a Linux system cannot ensure
    that higher-priority threads will have all the CPU time they need, as it will
    still try to ensure that low-priority threads are not starved. Furthermore, because
    both CFS and real-time counterparts are preemptive, they are not deterministic
    and predictive. As a result, any task with hard real-time requirements (e.g.,
    millisecond trading or airplane software) can’t be guaranteed enough execution
    time before its deadline. This is why some companies develop their own schedulers
    or systems for [strict real-time programs](https://oreil.ly/oVsCz) like [Zephyr
    OS](https://oreil.ly/hV7ym).
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不幸的是，即使有了实时调度程序，Linux 系统也不能确保高优先级线程将获得它们所需的所有 CPU 时间，因为它仍然会努力确保低优先级线程不会挨饿。此外，因为
    CFS 和实时对应物都是抢占式的，它们不是确定性和可预测性的。因此，在有严格实时要求的任务（例如毫秒级交易或飞机软件）之前，不能保证足够的执行时间。这就是为什么一些公司为
    [严格实时程序](https://oreil.ly/oVsCz) 开发了他们自己的调度程序或系统，如 [Zephyr OS](https://oreil.ly/hV7ym)。
- en: Despite the somewhat complex characteristics of the CFS scheduler, it remains
    the most popular thread orchestration system available in modern Linux systems.
    In 2016 the CFS was also overhauled for multicore machines and NUMA architectures,
    based on findings from [a famous research paper](https://oreil.ly/kUEiQ). As a
    result, threads are now smartly distributed across idle cores while ensuring migrations
    are not done too often and not among threads sharing the same resources.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 CFS 调度器具有一定复杂的特性，它仍然是现代 Linux 系统中最流行的线程编排系统。2016 年，CFS 还针对多核机器和 NUMA 架构进行了全面升级，基于
    [一篇著名的研究论文](https://oreil.ly/kUEiQ) 的发现。因此，现在线程可以智能地分布在空闲核心上，同时确保迁移不会太频繁，也不会在共享相同资源的线程之间进行。
- en: With a basic understanding of the OS scheduler, let’s dive into why the Go scheduler
    exists and how it enables developers to program multiple tasks to run concurrently
    on single or multiple CPU cores.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在对操作系统调度程序有基本了解之后，让我们深入探讨为何Go调度程序的存在以及它如何使开发人员能够在单个或多个CPU核心上并发运行多个任务。
- en: Go Runtime Scheduler
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Go运行时调度器
- en: The Go concurrency framework is built on the premise that it’s hard for a single
    flow of CPU instructions (e.g., function) to utilize all CPU cycles due to the
    I/O-bound nature of the typical workflow. While OS thread abstraction mitigates
    this by multiplexing threads into a set of CPU cores, the Go language brings another
    layer—a *goroutine*—that multiplexes functions on top of a set of threads. The
    [idea for goroutines](https://oreil.ly/TClXu) is similar to [coroutines](https://oreil.ly/t7oXZ),
    but since it is not the same (goroutines can be preempted) and since it’s in Go
    language, it has the *go* prefix. Similar to the OS thread, when the goroutine
    is blocked on a system call or I/O, the Go scheduler (not OS!) can quickly switch
    to a different goroutine, which will resume on the same thread (or a different
    one if needed).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Go并发框架建立在这样一个前提上，即由于典型工作流程的I/O密集特性，单个CPU指令流（例如函数）很难利用所有CPU周期。虽然操作系统线程抽象通过将线程复用到一组CPU核心中来缓解这一问题，但Go语言带来了另一层——*goroutine*——它在一组线程上多路复用函数。[goroutines的想法](https://oreil.ly/TClXu)类似于[协程](https://oreil.ly/t7oXZ)，但并非完全相同（goroutines可以被抢占），并且因为它是在Go语言中，所以有*go*前缀。与操作系统线程类似，当goroutine在系统调用或I/O上被阻塞时，Go调度器（而非操作系统！）可以快速切换到另一个goroutine，后者会在同一个线程上恢复执行（如果需要，也可以在不同线程上）。
- en: Essentially, Go has turned I/O-bound work [on the application level] into CPU-bound
    work at the OS level. Since all the context switching is happening at the application
    level, we don’t lose the same 12K instructions (on average) per context switch
    that we were losing when using threads. In Go, those same context switches are
    costing you 200 nanoseconds or 2.4K instructions. The scheduler is also helping
    with gains on cache-line efficiencies and NUMA. This is why we don’t need more
    threads than we have virtual cores.
  id: totrans-211
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 实质上，Go已将应用程序级别的I/O密集型工作转化为操作系统级别的CPU密集型工作。由于所有的上下文切换都发生在应用程序级别，因此我们不会像使用线程时那样每次上下文切换损失相同的12K指令（平均）。在Go中，这些相同的上下文切换只会花费你200纳秒或2.4K指令。调度程序还有助于提高缓存行效率和NUMA效率。这就是为什么我们不需要比虚拟核心更多的线程。
- en: ''
  id: totrans-212
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'William Kennedy, [“Scheduling in Go: Part II—Go Scheduler”](https://oreil.ly/Z4sRA)'
  id: totrans-213
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: William Kennedy，《Go中的调度：第二部分—Go调度器》
- en: As a result, we have in Go very cheap execution “threads” in the user space
    (a new goroutine only allocates a few kilobytes for the initial, local stack),
    which reduce the number of competing threads in our machine and allow hundreds
    of goroutines in our program without extensive overhead. Just one OS thread per
    CPU core should be enough to get all the work in our goroutines done.^([21](ch04.html#idm45606835341536))
    This enables many readability patterns—like event loops, map-reduce, pipes, iterators,
    and more—without involving more expensive kernel multithreading.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在Go语言中，我们在用户空间中拥有非常廉价的执行“线程”（一个新的goroutine只分配了几千字节用于初始的本地栈），这减少了我们机器上竞争线程的数量，并允许我们的程序中有数百个goroutine而不会产生过多的开销。每个CPU核心只需一个操作系统线程就足以完成所有goroutine的工作。^([21](ch04.html#idm45606835341536))
    这使得诸如事件循环、映射-归约、管道、迭代器等多种模式成为可能，而无需涉及更昂贵的内核多线程。
- en: 'Using Go concurrency in the form of goroutines is an excellent way to:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Go语言中的并发goroutines形式是执行以下操作的绝佳方式：
- en: Represent complex asynchronous abstractions (e.g., events)
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表示复杂的异步抽象（例如事件）
- en: Utilize our CPU to the fullest for I/O-bound tasks
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 充分利用我们的CPU来处理I/O密集型任务
- en: Create a multithreaded application that can utilize multiple CPUs to execute
    faster
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个能够利用多个CPU以更快速度执行的多线程应用程序
- en: Starting another goroutine is very easy in Go. It is built in the language via
    a `go <func>()` syntax. [Example 4-5](#code-goroutine) shows a function that starts
    two goroutines and finishes its work.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go中启动另一个goroutine非常简单。语言内置了一个`go <func>()`的语法。[示例 4-5](#code-goroutine)展示了一个启动两个goroutine并完成工作的函数。
- en: Example 4-5\. A function that starts two goroutines
  id: totrans-220
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-5\. 启动两个goroutine的函数
- en: '[PRE4]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO5-1)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO5-1)'
- en: The scope of the current goroutine.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 当前goroutine的范围。
- en: '[![2](assets/2.png)](#co_how_go_uses_the_cpu_resource__or_two__CO5-2)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_how_go_uses_the_cpu_resource__or_two__CO5-2)'
- en: The scope of a new goroutine that will run concurrently any moment now.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 新的 goroutine 的作用域将随时并发运行。
- en: '[![3](assets/3.png)](#co_how_go_uses_the_cpu_resource__or_two__CO5-3)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_how_go_uses_the_cpu_resource__or_two__CO5-3)'
- en: '`anotherFunction` will start running concurrently any moment now.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`anotherFunction` 将随时并发运行。'
- en: '[![4](assets/4.png)](#co_how_go_uses_the_cpu_resource__or_two__CO5-4)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_how_go_uses_the_cpu_resource__or_two__CO5-4)'
- en: When `function` terminates, the two goroutines we started can still run.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `function` 终止时，我们启动的两个 goroutine 仍然可以运行。
- en: It’s important to remember that all goroutines have a flat hierarchy between
    each other. Technically, there is no difference when goroutine `A` started `B`
    or `B` started `A`. In both cases, both `A` and `B` goroutines are equal, and
    they don’t know about each other.^([22](ch04.html#idm45606835218752)) They also
    cannot stop each other unless we implement explicit communication or synchronization
    and “ask” the goroutine to shut down. The only exception is the main goroutine
    that starts with the `main()` function. If the main goroutine finishes, the whole
    program terminates, killing all other goroutines forcefully.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，所有的 goroutine 在彼此之间具有平等的层次结构。从技术上讲，当 goroutine `A` 启动 `B` 或 `B` 启动 `A`
    时没有区别。在这两种情况下，`A` 和 `B` goroutines 都是平等的，它们不知道彼此的存在。^([22](ch04.html#idm45606835218752))
    除非我们实现显式的通信或同步并“请求” goroutine 停止，它们也不能彼此停止。唯一的例外是通过 `main()` 函数启动的主 goroutine。如果主
    goroutine 完成，整个程序将终止，强制终止所有其他 goroutines。
- en: Regarding communication, goroutines, similarly to OS threads, have access to
    the same memory space within the process. This means that we can pass data between
    goroutines using shared memory. However, this is not so trivial because almost
    no operation in Go is atomic. Concurrent writing (or writing and reading) from
    the same memory can cause data races, leading to nondeterministic behavior or
    even data corruption. To solve this, we need to use synchronization techniques
    like explicit atomic function (as presented in [Example 4-6](#code-goroutine-atomic))
    or mutex (as shown in [Example 4-7](#code-goroutine-mutex)), so in other words,
    a lock.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 关于通信，goroutines 与操作系统线程类似，可以访问进程内的同一内存空间。这意味着我们可以使用共享内存在 goroutines 之间传递数据。然而，这并不那么简单，因为在
    Go 中几乎没有操作是原子的。从同一内存中并发写入（或写入和读取）可能会导致数据竞争，从而引起非确定性行为甚至数据损坏。为了解决这个问题，我们需要使用像显式原子函数（如
    [示例 4-6](#code-goroutine-atomic) 中所示）或互斥锁（如 [示例 4-7](#code-goroutine-mutex) 中所示）这样的同步技术，换句话说，是一种锁定机制。
- en: Example 4-6\. Safe multigoroutine communication through dedicated atomic addition
  id: totrans-232
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-6\. 通过专用原子加法实现安全的多 goroutine 通信
- en: '[PRE5]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO6-1)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO6-1)'
- en: Notice that while we use atomic to synchronize additions between `concurrentFn`
    goroutines, we use additional `sync.WaitGroup` (another form of locking) to wait
    for all these goroutines to finish. We do the same in [Example 4-7](#code-goroutine-mutex).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，虽然我们使用原子操作在 `concurrentFn` goroutines 之间同步添加，但我们还使用额外的 `sync.WaitGroup`（另一种形式的锁定）等待所有这些
    goroutines 完成。我们在 [示例 4-7](#code-goroutine-mutex) 中也是如此。
- en: Example 4-7\. Safe multigoroutine communication through mutex (lock)
  id: totrans-236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-7\. 通过互斥锁实现安全的多 goroutine 通信（锁定）
- en: '[PRE6]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The choice between atomic and lock depends on readability, efficiency requirements,
    and what operation you want to synchronize. For example, if you want to concurrently
    perform a simple operation on a number like value write or read, addition, substitution,
    or compare and swap, you can consider the [atomic package](https://oreil.ly/NZnXr).
    Atomic is often more efficient than mutexes (lock) since the compiler will translate
    them into special [atomic CPU operations](https://oreil.ly/8g0yM) that can change
    data under a single memory address in a thread-safe way.^([23](ch04.html#idm45606834944896))
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在原子和锁之间的选择取决于可读性、效率要求以及您想要同步的操作。例如，如果您想要在数字上并发执行简单的操作，如写入或读取值、加法、替换或比较和交换，可以考虑使用
    [atomic 包](https://oreil.ly/NZnXr)。原子操作通常比互斥锁更高效，因为编译器将它们转换为特殊的 [原子 CPU 操作](https://oreil.ly/8g0yM)，可以以线程安全的方式更改单个内存地址下的数据。^([23](ch04.html#idm45606834944896))
- en: If, however, using atomic impacts the readability of our code, the code is not
    on a critical path, or we have a more complex operation to synchronize, we can
    use a lock. Go offers `sync.Mutex`, which allows simple locking, and `sync.RWMutex`,
    which allows locking for reads (`RLock()`) and writes (`Lock()`). If you have
    many goroutines that do not modify shared memory, lock them with `RLock()` so
    there is no lock contention between them, since concurrent read of shared memory
    is safe. Only when a goroutine wants to modify that memory can it acquire a full
    lock using `Lock()` that will block all readers.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果使用原子操作影响了代码的可读性，代码不在关键路径上，或者我们有更复杂的操作需要同步，我们可以使用锁。Go语言提供了`sync.Mutex`，允许简单的锁定，以及`sync.RWMutex`，允许读锁定（`RLock()`）和写锁定（`Lock()`）。如果有许多不修改共享内存的goroutine，请使用`RLock()`对它们进行锁定，这样它们之间就不会有锁争用，因为并发读取共享内存是安全的。只有当一个goroutine想要修改该内存时，它才能通过`Lock()`获取完整的锁定，这将阻塞所有读取操作。
- en: On the other hand, lock and atomic are not the only choices. The Go language
    has another ace in its hand on this subject. On top of the coroutine concept,
    Go also utilizes [C. A. R. Hoare’s Communicating Sequential Processes (CSP)](https://oreil.ly/5KXA9)
    paradigm, which can also be seen as a type-safe generalization of Unix pipes.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，锁和原子操作并不是唯一的选择。Go语言在这个主题上还有另一个王牌。在协程概念之上，Go还利用了[C. A. R. Hoare的通信顺序进程（CSP）](https://oreil.ly/5KXA9)范式，这也可以被视为Unix管道的类型安全的泛化。
- en: Do not communicate by sharing memory; instead, share memory by communicating.
  id: totrans-241
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不要通过共享内存进行通信；相反，通过通信共享内存。
- en: ''
  id: totrans-242
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[“Effective Go”](https://oreil.ly/G4Lmq)'
  id: totrans-243
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[“Effective Go”](https://oreil.ly/G4Lmq)'
- en: This model encourages sharing data by implementing a communication pipeline
    between goroutines using a channel concept. Sharing the same memory address to
    pass some data requires extra synchronization. However, suppose one goroutine
    sends that data to some channel, and another receives it. In that case, the whole
    flow naturally synchronizes itself, and shared data is never accessed by two goroutines
    simultaneously, ensuring thread safety.^([24](ch04.html#idm45606834933072)) Example
    channel communication is presented in [Example 4-8](#code-goroutine-channel).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模型鼓励通过使用通道概念在goroutine之间实现通信管道来共享数据。通过共享相同的内存地址来传递数据需要额外的同步。然而，如果一个goroutine将数据发送到某个通道，另一个goroutine接收它，整个流程自然同步，并且共享数据永远不会被两个goroutine同时访问，确保线程安全。^([24](ch04.html#idm45606834933072))
    示例通道通信在[示例 4-8](#code-goroutine-channel)中展示。
- en: Example 4-8\. An example of memory-safe multigoroutine communication through
    the channel
  id: totrans-245
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-8\. 通过通道进行内存安全的多goroutine通信示例
- en: '[PRE7]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO7-1)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_how_go_uses_the_cpu_resource__or_two__CO7-1)'
- en: Channel can be created in Go with the `ch := make(chan <type>, <buffer size>)`
    syntax.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`ch := make(chan <type>, <buffer size>)`语法在Go中创建通道。
- en: '[![2](assets/2.png)](#co_how_go_uses_the_cpu_resource__or_two__CO7-2)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_how_go_uses_the_cpu_resource__or_two__CO7-2)'
- en: We can send values of a given type to our channel.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以向通道发送特定类型的值。
- en: '[![3](assets/3.png)](#co_how_go_uses_the_cpu_resource__or_two__CO7-3)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_how_go_uses_the_cpu_resource__or_two__CO7-3)'
- en: Notice that in this example, we don’t need `sync.WaitGroup` since we abuse the
    knowledge of how many exact messages we expect to receive. If we did not have
    that information, we would need a waiting group or another mechanism.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这个例子中，我们不需要`sync.WaitGroup`，因为我们了解我们期望接收到多少条精确的消息。如果没有这些信息，我们将需要一个等待组或其他机制。
- en: '[![4](assets/4.png)](#co_how_go_uses_the_cpu_resource__or_two__CO7-4)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_how_go_uses_the_cpu_resource__or_two__CO7-4)'
- en: We can read values of a given type from our channel.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从通道读取特定类型的值。
- en: '[![5](assets/5.png)](#co_how_go_uses_the_cpu_resource__or_two__CO7-5)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_how_go_uses_the_cpu_resource__or_two__CO7-5)'
- en: Channels should also be closed if we don’t plan to send anything through them
    anymore. This releases resources and unblocks certain receiving and sending flows
    (more on that later).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不再计划通过通道发送任何内容，也应该关闭通道。这会释放资源并解除某些接收和发送流程的阻塞（稍后会详细说明）。
- en: 'The important aspect of channels is that they can be buffered. In such a case,
    it behaves like a queue. If we create a channel with, e.g., a buffer of three
    elements, a sending goroutine can send exactly three elements before it gets blocked
    until someone reads from this channel. If we send three elements and close the
    channel, the receiving goroutine can still read three elements before noticing
    the channel was closed. A channel can be in three states. It’s important to remember
    how the goroutine sending or receiving from this channel behaves when switching
    between these states:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 通道的重要方面是它们可以具有缓冲区。在这种情况下，它的行为类似于队列。如果我们创建了一个具有三个元素缓冲区的通道，一个发送 goroutine 可以在有人从该通道读取之前发送三个元素。如果我们发送了三个元素并关闭了通道，接收
    goroutine 在注意到通道关闭之前仍然可以读取三个元素。一个通道可以处于三种状态。重要的是记住，当在这些状态之间切换时，从该通道发送或接收的 goroutine
    的行为如何。
- en: Allocated, open channel
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 已分配、开启的通道
- en: If we create a channel using `make(chan <type>)`, it’s allocated and open from
    the start. Assuming no buffer, such a channel will block an attempt to send a
    value until another goroutine receives it or when we use the `select` statement
    with multiple cases. Similarly, the channel receive will block until someone sends
    to that channel unless we receive in a `select` statement with multiple cases
    or the channel was closed.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用`make(chan <type>)`创建一个通道，它将在分配时就开启。假设没有缓冲区，这样的通道将阻塞尝试发送值，直到另一个 goroutine
    接收或者我们在使用带有多个 case 的 `select` 语句时。类似地，通道接收将阻塞，直到有人发送到该通道，除非我们在带有多个 case 的 `select`
    语句中接收，或者该通道已关闭。
- en: Closed channel
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭的通道
- en: If we `close(ch)` the allocated channel, a send to that channel will cause panic
    and receives will return zero values immediately. This is why it is recommended
    to keep responsibility for the closing channel in the goroutine that sends the
    data (sender).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们通过`close(ch)`关闭了分配的通道，发送到该通道将导致恐慌，接收将立即返回零值。这就是为什么建议将关闭通道的责任留给发送数据的 goroutine（发送者）。
- en: Nil channel
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 空通道
- en: If you define channel type (`var ch chan <type>`) without allocating it using
    `make(chan <type>)`, our channel is nil. We can also “nil” an allocated channel
    by assigning nil (`ch = nil`). In this state, sending and receiving will block
    forever. Practically speaking, it’s rarely useful to nil channels.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您定义了通道类型（`var ch chan <type>`）而不使用`make(chan <type>)`分配它，我们的通道是 nil。我们也可以通过赋值
    nil (`ch = nil`) 来“nil”一个已分配的通道。在这种状态下，发送和接收将永远阻塞。实际上，将通道设置为 nil 很少有用。
- en: Go channels is an amazing and elegant paradigm that allows for building very
    readable, event-based concurrency patterns. However, in terms of CPU efficiency,
    they might be the least efficient compared to the `atomic` package and mutexes.
    Don’t let that discourage you! For most practical applications (if not overused!),
    channels can structure our application into robust and efficient concurrent implementation.
    We will explore some practical patterns of using channels in [“Optimizing Latency
    Using Concurrency”](ch10.html#ch-opt-latency-concurrency-example).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: Go 通道是一种令人惊叹和优雅的范式，允许构建非常可读的基于事件的并发模式。然而，就 CPU 效率而言，与`atomic`包和互斥锁相比，它们可能是最低效的。但不要因此灰心！对于大多数实际应用（如果没有过度使用！），通道可以将我们的应用程序结构化为强大且高效的并发实现。我们将探讨一些使用通道的实际模式，在[“通过并发优化延迟”](ch10.html#ch-opt-latency-concurrency-example)中展示。
- en: Before we finish this section, it’s important to understand how we can tune
    concurrency efficiency in the Go program. Concurrency logic is implemented by
    the Go scheduler in the [Go runtime package](https://oreil.ly/q3iCp), which is
    also responsible for other things like garbage collection (see [“Garbage Collection”](ch05.html#ch-hw-garbage)),
    profiles, or stack framing. The Go scheduler is pretty automatic. There aren’t
    many configuration flags. As it stands at the current moment, there are two practical
    ways developers can control concurrency in their code:^([25](ch04.html#idm45606834709824))
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成本节之前，理解如何在 Go 程序中调整并发效率非常重要。并发逻辑由 Go 调度程序在[Go 运行时包](https://oreil.ly/q3iCp)中实现，它还负责其他事务，如垃圾收集（参见[“垃圾收集”](ch05.html#ch-hw-garbage)）、分析或堆栈帧。Go
    调度程序相当自动化。配置标志不多。目前，开发者可以通过两种实际的方式控制代码中的并发：
- en: A number of goroutines
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 一些 goroutine 的数量
- en: As developers, we usually control how many goroutines we create in our program.
    Spawning them for every small workpiece is usually not the best idea, so don’t
    overuse them. It’s also worth noting that many abstractions from standard or third-party
    libraries can spawn goroutines, especially those that require `Close` or cancellation.
    Notably, common operations like `http.Do`, `context.WithCancel`, and `time.After`
    create goroutines. If used incorrectly, the goroutines can be easily leaked (leaving
    orphan goroutines), which typically wastes memory and CPU effort. We will explore
    ways to debug numbers and snapshots of goroutines in [“Goroutine”](ch09.html#ch-obs-pprof-goroutine).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 作为开发人员，我们通常控制我们程序中创建的 goroutines 数量。通常不是为每个小工作单元生成它们是最佳选择，所以不要过度使用它们。还值得注意的是，许多标准或第三方库的抽象可以生成
    goroutines，特别是那些需要 `Close` 或取消的操作。特别是，常见操作如 `http.Do`、`context.WithCancel` 和 `time.After`
    都会创建 goroutines。如果使用不当，goroutines 可能会被泄漏（留下孤立的 goroutines），这通常会浪费内存和 CPU 资源。我们将探讨在
    [“Goroutine”](ch09.html#ch-obs-pprof-goroutine) 中调试 goroutines 数量和快照的方法。
- en: First Rule of Efficient Code
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高效代码的第一条规则
- en: Always close or release the resources you use. Sometimes simple structures can
    cause colossal and unbounded waste of memory and goroutines if we forget to close
    them. We will explore common examples in [“Don’t Leak Resources”](ch11.html#ch-basic-leaks).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 总是关闭或释放您使用的资源。有时，如果忘记关闭它们，简单的结构可能会导致内存和 goroutines 的巨大且无界的浪费。我们将在 [“不要泄露资源”](ch11.html#ch-basic-leaks)
    中探讨常见示例。
- en: '`GOMAXPROCS`'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '`GOMAXPROCS`'
- en: This important environmental variable can be set to control the number of virtual
    CPUs you want to leverage in your Go program. The same configuration value can
    be applied via the `runtime.GOMAXPROCS(n)` function. The underlying logic on how
    the Go scheduler uses this variable is fairly complex,^([26](ch04.html#idm45606834697536))
    but it generally controls how many parallel OS thread executions Go can expect
    (internally called a “proc” number). The Go scheduler will then maintain `GOMAXPROCS/proc`
    number of queues and try to distribute goroutines among them. The default value
    of `GOMAXPROCS` is always the number of virtual CPU cores your OS exposes, and
    that is typically what will give you the best performance. Trim the `GOMAXPROCS`
    value down if you want your Go program to use fewer CPU cores (less parallelism)
    in exchange for potentially higher latency.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这个重要的环境变量可以设置来控制你希望在 Go 程序中利用的虚拟 CPU 数量。可以通过 `runtime.GOMAXPROCS(n)` 函数应用相同的配置值。Go
    调度程序如何使用这个变量的底层逻辑是相当复杂的^([26](ch04.html#idm45606834697536))，但它通常控制 Go 可以期望的并行
    OS 线程执行的数量（内部称为“proc”数）。然后，Go 调度程序将维护 `GOMAXPROCS/proc` 数量的队列，并尝试在它们之间分发 goroutines。`GOMAXPROCS`
    的默认值始终是操作系统公开的虚拟 CPU 核心数，这通常会为您提供最佳性能。如果希望您的 Go 程序使用较少的 CPU 核心（较少的并行性）以换取潜在的更高延迟，请减少
    `GOMAXPROCS` 值。
- en: Recommended GOMAXPROCS Configuration
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐的 `GOMAXPROCS` 配置
- en: Set `GOMAXPROCS` to the number of virtual cores you want your Go program to
    utilize at once. Typically, we want to use the whole machine; thus, the default
    value should work.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `GOMAXPROCS` 设置为您希望您的 Go 程序同时利用的虚拟核心数。通常情况下，我们希望使用整个机器，因此默认值应该适用。
- en: For virtualized environments, especially using lightweight virtualization mechanisms
    like containers, use [Uber’s `automaxprocs` library](https://oreil.ly/ysr40),
    which will adjust `GOMAXPROCS` based on the Linux CPU limits the container is
    allowed to use, which is often what we want.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 对于虚拟化环境，特别是使用像容器这样的轻量级虚拟化机制，请使用 [Uber 的 `automaxprocs` 库](https://oreil.ly/ysr40)，它将根据容器被允许使用的
    Linux CPU 限制调整 `GOMAXPROCS`，这通常是我们想要的。
- en: Multitasking is always a tricky concept to introduce into a language. I believe
    the goroutines with channels in Go are quite an elegant solution to this problem,
    which allows many readable programming patterns without sacrificing efficiency.
    We will explore practical concurrency patterns in [“Optimizing Latency Using Concurrency”](ch10.html#ch-opt-latency-concurrency-example),
    by improving the latency of [Example 4-1](#code-sum) presented in this chapter.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务始终是引入语言的一个棘手概念。我认为在 Go 语言中，带有通道的 goroutines 是这个问题的相当优雅的解决方案，它允许许多可读的编程模式而不会牺牲效率。我们将通过改进本章介绍的
    [“通过并发优化延迟”](ch10.html#ch-opt-latency-concurrency-example) 中所示的 [Example 4-1](#code-sum)
    来探索实际的并发模式。
- en: Let’s now look into when concurrency might be useful in our Go programs.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看在我们的 Go 程序中何时可能会使用并发。
- en: When to Use Concurrency
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用并发
- en: 'As with any efficiency optimization, the same classic rules apply when transforming
    a single goroutine code to a concurrent one. No exceptions here. We have to focus
    on the goal, apply the TFBO loop, benchmark early, and look for the biggest bottleneck.
    As with everything, adding concurrency has trade-offs, and there are cases where
    we should avoid it. Let’s summarize the practical benefits and disadvantages of
    concurrent code versus sequential:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何效率优化一样，将单个 goroutine 代码转换为并发代码时，同样适用经典规则。没有例外。我们必须专注于目标，应用 TFBO 循环，尽早进行基准测试，并寻找最大的瓶颈。像任何事情一样，增加并发性有其权衡，也有一些情况我们应该避免。让我们总结并发代码与顺序代码相比的实际好处和缺点：
- en: Advantages
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 优点
- en: Concurrency allows us to speed up the work by splitting it into pieces and executing
    each part concurrently. As long as the synchronization and shared resources are
    not a significant bottleneck, we should expect an improved latency.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发允许我们通过将工作分解为片段并同时执行每个部分来加快工作进度。只要同步和共享资源不是重要的瓶颈，我们应该期望改善延迟。
- en: Because the Go scheduler implements an efficient preemptive mechanism, concurrency
    improves CPU core utilization for I/O-bound tasks, which should translate into
    lower latency, even with a `GOMAXPROCS=1` (a single CPU core).
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为 Go 调度程序实现了有效的抢占机制，所以并发可以提高 I/O 绑定任务的 CPU 核心利用率，这应该能够在`GOMAXPROCS=1`（单个 CPU
    核心）时减少延迟。
- en: Especially in virtual environments, we often reserve a certain CPU time for
    our programs. Concurrency allows us to distribute work across available CPU time
    in a more even way.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特别是在虚拟环境中，我们经常为程序保留一定的 CPU 时间。并发允许我们在可用的 CPU 时间中更均匀地分配工作。
- en: For some cases, like asynchronous programming and event handling, concurrency
    represents a problem domain well, resulting in improved readability despite some
    complexities. Another example is the HTTP server. Treating each HTTP incoming
    request as a separate goroutine not only allows efficient CPU core utilization
    but also naturally fits into how code should be read and understood.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于某些情况，比如异步编程和事件处理，并发很好地表示了问题领域，尽管存在一些复杂性，但是可以提高可读性。另一个例子是 HTTP 服务器。将每个 HTTP
    进入请求视为单独的 goroutine，不仅可以有效利用 CPU 核心，而且自然地适应了代码的阅读和理解方式。
- en: Disadvantages
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点
- en: Concurrency adds significant complexity to the code, especially when we transform
    existing code into concurrency (instead of building API around channels from day
    one). This hits readability since it almost always obfuscates execution flow,
    but even worse, it limits the developer’s ability to predict all edge cases and
    potential bugs. This is one of the main reasons why I recommend postponing adding
    concurrency as long as possible. And once you have to introduce concurrency, use
    as few channels as possible for the given problem.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发会显著增加代码的复杂性，特别是在将现有代码转换为并发代码时（而不是从一开始就围绕通道构建 API）。这影响了可读性，因为它几乎总是模糊了执行流程，更糟糕的是，它限制了开发者预测所有边缘情况和潜在错误的能力。这是我建议尽可能推迟引入并发的主要原因之一。一旦不得不引入并发，尽量在给定问题中使用尽可能少的通道。
- en: With concurrency, there is a risk of saturating resources due to unbounded concurrency
    (uncontrolled amount of goroutines in a single moment) or leaking goroutines (orphan
    goroutines). This is something we also need to care about and test against (more
    on this in [“Don’t Leak Resources”](ch11.html#ch-basic-leaks)).
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有了并发，由于无限并发（单个时刻的无控 goroutine 数量）或泄露 goroutine（孤立的 goroutine），存在饱和资源的风险。这也是我们需要关注和测试的内容（详见[“不泄露资源”](ch11.html#ch-basic-leaks)）。
- en: Despite Go’s very efficient concurrency framework, goroutines and channels are
    not free of overhead. If used wrongly, it can impact our code efficiency. Focus
    on providing enough work to each goroutine that will justify its cost. Benchmarks
    are a must-have.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管 Go 的并发框架非常高效，但 goroutines 和 channels 并非没有开销。如果使用不当，可能会影响我们代码的效率。专注于为每个 goroutine
    提供足够的工作量来证明其成本是有必要的。基准测试是必不可少的。
- en: When using concurrency, we suddenly add three more nontrivial tuning parameters
    into our program. We have a `GOMAXPROCS` setting, and depending on how we implement
    things, we can control the number of goroutines we spawn and how large a buffer
    of the channel we should have. Finding correct numbers requires hours of benchmarking
    and is still prone to errors.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用并发时，我们突然向程序添加了三个更非平凡的调优参数。我们有一个`GOMAXPROCS`设置，根据我们如何实现事物，我们可以控制我们产生的 goroutine
    数量以及我们应该具有多大的通道缓冲区。找到正确的数字需要数小时的基准测试，并且仍然容易出错。
- en: Concurrent code is hard to benchmark because it depends even more on the environment,
    possible noisy neighbors, multicore settings, OS version, and so on. On the other
    hand, sequential, single-core code has much more deterministic and portable performance,
    which is easier to prove and compare against.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发代码很难进行基准测试，因为它更加依赖环境、可能存在的噪声邻居、多核设置、操作系统版本等。另一方面，顺序的单核代码具有更加确定和可移植的性能，更容易证明并进行比较。
- en: As we can see, using concurrency is not the cure for all performance problems.
    It’s just another tool in our hands that we can use to fulfill our efficiency
    goals.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，使用并发并不是解决所有性能问题的灵丹妙药。这只是我们手中的另一个工具，可以用来实现效率目标。
- en: Adding Concurrency Should Be One of Our Last Deliberate Optimizations to Try
  id: totrans-291
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加并发应该是我们最后尝试的有意义优化之一。
- en: As per our TFBO cycle, if you are still not meeting your RAERs, e.g., in terms
    of speed, make sure you try more straightforward optimization techniques before
    adding concurrency. The rule of thumb is to think about concurrency when our CPU
    profiler (explained in [Chapter 9](ch09.html#ch-observability3)) shows that our
    program spends CPU time only on things that are crucial to our functionality.
    Ideally, before we hit our readability limit, is the most efficient way we know.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的TFBO周期，如果您仍然不能满足您的RAERs，例如速度方面，请确保在添加并发之前尝试更简单的优化技术。经验法则是，在我们的CPU分析器（在[第9章](ch09.html#ch-observability3)中解释）显示我们的程序只在对我们功能至关重要的事务上花费CPU时间之前，是我们知道的最有效的方式。
- en: The mentioned list of disadvantages is one reason, but the second is that our
    program’s characteristics might differ after basic (without concurrency) optimizations.
    For example, we thought our task was CPU bound, but after improvements, we may
    find most of the time is now spent waiting on I/O. Or we might realize we did
    not need the heavy concurrency changes after all.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 上述的缺点列表是一个原因，但第二个原因是，在基本的（不使用并发）优化之后，我们程序的特性可能会有所不同。例如，我们以为我们的任务是CPU密集型的，但在改进之后，我们可能发现大部分时间都花在等待I/O操作上。或者我们可能意识到，其实我们根本不需要大规模的并发修改。
- en: Summary
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: The modern CPU hardware is a nontrivial component that allows us to run our
    software efficiently. With ongoing operating systems, Go language development,
    and advancements in hardware, only more optimization techniques and complexities
    will arise to decrease running costs and increase processing power.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 现代CPU硬件是一个复杂的组件，它允许我们高效地运行我们的软件。随着操作系统的持续发展、Go语言开发和硬件的进步，只会出现更多的优化技术和复杂性，以降低运行成本并增加处理能力。
- en: In this chapter, I hopefully gave you basics that will help you optimize your
    usage of CPU resources and, generally, your software execution speed. First, we
    discussed the Assembly language and how it can be useful during Go development.
    Then, we explored Go compiler functionalities, optimizations, and ways to debug
    its execution.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我希望给了你一些基础知识，帮助你优化CPU资源的使用，以及通常的软件执行速度。首先，我们讨论了汇编语言及其在Go开发中的用处。然后，我们探讨了Go编译器的功能、优化方法和调试方式。
- en: 'Later, we jumped into the main challenge for CPU execution: memory access latency
    in modern systems. Finally, we discussed the various low-level optimizations like
    L-caches, pipelining, CPU branch prediction, and Hyper-Threading.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，我们深入探讨了CPU执行的主要挑战：现代系统中的内存访问延迟。最后，我们讨论了诸如L缓存、流水线处理、CPU分支预测和超线程等各种低级优化技术。
- en: Last, we explored the practical problems of executing our programs in production
    systems. Unfortunately, our machine’s program is rarely the only process, so efficient
    execution matters. Finally, we summarized Go’s concurrency framework’s benefits
    and disadvantages.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们探讨了在生产系统中执行我们程序的实际问题。不幸的是，我们机器上的程序很少是唯一的进程，因此高效的执行非常重要。最后，我们总结了Go并发框架的优缺点。
- en: In practice, CPU resource is essential to optimize in modern infrastructure
    to achieve faster execution and the ability to pay less for our workloads. Unfortunately,
    CPU resource is only one aspect. For example, our choice optimization might prefer
    using more memory to reduce CPU usage or vice versa.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，优化CPU资源是现代基础设施中实现更快执行和减少工作负载成本的关键。不幸的是，CPU资源只是一个方面。例如，我们的选择优化可能更倾向于使用更多内存以减少CPU使用率，或者反之。
- en: As a result, our programs typically use a lot of memory resources (plus I/O
    traffic through disk or network). While execution is tied to CPU resources like
    memory and I/O, it might be the first on our list of optimizations depending on
    what we want (e.g., cheaper execution, faster execution, or both). Let’s discuss
    the memory resource in the next chapter.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的程序通常会使用大量的内存资源（以及通过磁盘或网络的I/O流量）。虽然执行与CPU资源（如内存和I/O）相关联，但根据我们的需求（例如，更便宜的执行、更快的执行或两者兼有），它可能是我们优化列表中的第一项。让我们在下一章讨论内存资源。
- en: ^([1](ch04.html#idm45606836099536-marker)) To be technically strict, modern
    computers nowadays have distinct caches for program instructions and data, while
    both are stored the same on the main memory. This is the so-called modified Harvard
    architecture. At the optimization levels we aim for in this book, we can safely
    skip this level of detail.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch04.html#idm45606836099536-marker)) 严格来说，现代计算机现在为程序指令和数据分别具有不同的缓存，尽管两者都存储在主内存中。这就是所谓的修改后的哈佛架构。在本书中我们追求的优化级别上，我们可以安全地跳过这个细节层次。
- en: ^([2](ch04.html#idm45606835882864-marker)) For scripted (interpreted) languages,
    there is no complete code compilation. Instead, there is an interpreter that compiles
    the code statement by statement. Another unique type of language is represented
    by a family of languages that use Java Virtual Machine (JVM). Such a machine can
    dynamically switch from interpreting to just-in-time (JIT) compilation for runtime
    optimizations.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch04.html#idm45606835882864-marker)) 对于脚本（解释）语言，没有完全的代码编译。相反，有一个解释器逐条编译代码语句。另一种独特类型的语言是由使用Java虚拟机（JVM）的语言系列代表。这样的机器可以在运行时动态地从解释切换到即时（JIT）编译以进行优化。
- en: ^([3](ch04.html#idm45606835843408-marker)) Similar output to [Example 4-2](#code-sum-asm)
    can be obtained by compiling the source code to Assembly using `go build -gcflags
    *-S* <source>`.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch04.html#idm45606835843408-marker)) 通过使用`go build -gcflags *-S* <source>`将源代码编译为汇编，可以获得类似于[示例
    4-2](#code-sum-asm)的输出。
- en: ^([4](ch04.html#idm45606835798912-marker)) Note that in the Go Assembly register,
    names are abstracted for portability. Since we will compile to 64-bit architecture,
    `SP` and `SI` will mean RSP and RSI registers.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch04.html#idm45606835798912-marker)) 请注意，在Go汇编寄存器中，名称被抽象化以实现可移植性。由于我们将编译为64位架构，`SP`和`SI`将表示RSP和RSI寄存器。
- en: ^([5](ch04.html#idm45606835763760-marker)) There can be incompatibilities, but
    mostly with special-purpose instructions like cryptographic or SIMD instructions,
    which can be checked at runtime if they are available before execution.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch04.html#idm45606835763760-marker)) 可能会存在不兼容性，但主要是与特殊用途指令（如加密或SIMD指令）有关，可以在执行前运行时检查它们是否可用。
- en: ^([6](ch04.html#idm45606835723216-marker)) Note that the structure methods,
    from a compiler perspective, are just functions, with the first argument being
    that structure, so the same inlining technique applies here.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch04.html#idm45606835723216-marker)) 注意，从编译器的角度来看，结构方法只是函数，第一个参数就是该结构，因此这里也适用相同的内联技术。
- en: ^([7](ch04.html#idm45606835721776-marker)) A function call needs more CPU instructions
    since the program has to pass argument variables and return parameters through
    the stack, keep the current function’s state, rewind the stack after the function
    call, add the new frame stack, etc.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch04.html#idm45606835721776-marker)) 函数调用需要更多的CPU指令，因为程序必须通过堆栈传递参数变量和返回参数，保持当前函数的状态，在函数调用后重置堆栈，添加新的堆栈帧等。
- en: ^([8](ch04.html#idm45606835712848-marker)) Go tooling allows us to check the
    state of our program through each optimization in the SSA form thanks to the `GOSSAFUNC`
    environment variable. It’s as easy as building our program with `GOSSAFUNC=<function
    to see> go build` and opening the resulting *ssa.html* file. You can read more
    about it [here](https://oreil.ly/32Zbd).
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch04.html#idm45606835712848-marker)) Go工具允许我们通过`GOSSAFUNC`环境变量在SSA形式中检查我们程序的状态，只需构建我们的程序并使用`GOSSAFUNC=<function
    to see> go build`，然后打开生成的*ssa.html*文件。您可以在[这里](https://oreil.ly/32Zbd)了解更多信息。
- en: ^([9](ch04.html#idm45606835698096-marker)) You can unpack it with the `tar <archive>`
    or `go tool pack e <archive>` command. Go archive typically contains the object
    file and package metadata in the *__.PKGDEF* file.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch04.html#idm45606835698096-marker)) 您可以使用`tar <archive>`或`go tool pack
    e <archive>`命令解包它。Go归档通常包含对象文件和*__.PKGDEF*文件中的包元数据。
- en: ^([10](ch04.html#idm45606835689456-marker)) However, there are [discussions
    to remove](https://oreil.ly/xoijc) it from the default building process.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch04.html#idm45606835689456-marker)) 然而，有关从默认构建过程中删除它的讨论。
- en: ^([11](ch04.html#idm45606835684112-marker)) [Bound check elimination](https://oreil.ly/E7FJI)
    is not explained in this book, as it’s a rare optimization idea.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch04.html#idm45606835684112-marker)) [边界检查消除](https://oreil.ly/E7FJI)
    不在本书中详细解释，因为这是一种罕见的优化思想。
- en: ^([12](ch04.html#idm45606835565472-marker)) This is very often used in standard
    libraries for critical code.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch04.html#idm45606835565472-marker)) 这在标准库中的关键代码中非常常见。
- en: ^([13](ch04.html#idm45606835552784-marker)) On top of SISD and SIMD, Flynn’s
    taxonomy also specifies MISD, which describes performing multiple instructions
    on the same data, and MIMD, which describes full parallelism. MISD is rare and
    only happens when reliability is important. For example, four flight control computers
    perform exactly the same computations for quadruple error checks in every NASA
    space shuttle. MIMD, on the other hand, is more common thanks to multicore or
    even multi-CPU designs.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch04.html#idm45606835552784-marker)) 在 SISD 和 SIMD 的基础上，弗林分类法还指定了 MISD，它描述了在同一数据上执行多个指令，并且
    MIMD，描述了完全并行。MISD 是罕见的，仅在可靠性重要时才会发生。例如，四个飞行控制计算机在每个 NASA 航天飞机上执行完全相同的计算，以进行四重错误检查。另一方面，由于多核甚至多
    CPU 设计，MIMD 更为常见。
- en: ^([14](ch04.html#idm45606835540240-marker)) This is why we see specialized chips
    (called Neural Processing Units, or NPUs) appearing in the commodity devices—for
    example, Tensor Processing Unit (TPU) in Google phones, A14 Bionic chip in iPhones,
    and dedicated NPU in the M1 chip in Apple laptops.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch04.html#idm45606835540240-marker)) 这就是为什么我们在通用设备中看到专用芯片（称为神经处理单元或NPU）的原因，例如Google手机中的张量处理单元（TPU），iPhone中的A14仿生芯片，以及苹果笔记本电脑中的专用NPU。
- en: ^([15](ch04.html#idm45606835530224-marker)) Sizes of caches can vary. Example
    sizes are taken from my laptop. You can check the sizes of your CPU caches in
    Linux by using the `sudo dmidecode -t cache` command.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch04.html#idm45606835530224-marker)) 缓存的大小可以不同。示例大小取自我的笔记本电脑。您可以通过使用
    `sudo dmidecode -t cache` 命令在 Linux 中检查 CPU 缓存的大小。
- en: ^([16](ch04.html#idm45606835511424-marker)) If a CPU can in total perform up
    to one instruction per cycle (IPC ⇐ 1), we call it a scalar CPU. Most modern CPU
    cores have IPC ⇐ 1, but one CPU has more than one core, which makes IPC > 1\.
    This makes these CPUs superscalar. IPC has quickly become a performance metric
    for CPUs.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch04.html#idm45606835511424-marker)) 如果一个 CPU 总共每个周期最多执行一条指令（IPC ≤ 1），我们称其为标量
    CPU。大多数现代 CPU 核心的 IPC ≤ 1，但是有一些 CPU 拥有多个核心，使得 IPC > 1。这使得这些 CPU 成为超标量 CPU。IPC
    已经迅速成为 CPU 的性能指标。
- en: ^([17](ch04.html#idm45606835495520-marker)) Huge cost is not an overstatement.
    Latency of context switch depends on many factors, but it was measured that in
    the best case, direct latency (including operating system switch latency) is around
    1,350 nanoseconds—2,200 nanoseconds if it has to migrate to a different core.
    This is only a direct latency, from the end of one thread to the start of another.
    The total latency that would include the indirect cost in the form of cache and
    pipeline warm-up could be as high as 10,000 nanoseconds (and this is what we see
    in [Table A-1](app01.html#table-napkin-math)). During this time, we could compute
    something like 40,000 instructions.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch04.html#idm45606835495520-marker)) 高昂的成本一点也不为过。上下文切换的延迟取决于许多因素，但是据测量，在最佳情况下，直接延迟（包括操作系统切换延迟）约为1,350纳秒
    — 如果必须迁移到不同的核心，则为2,200纳秒。这仅仅是直接延迟，从一个线程的结束到另一个线程的开始。总延迟将包括缓存和流水线预热的间接成本，可能高达10,000纳秒（这是我们在[表A-1](app01.html#table-napkin-math)中看到的情况）。在此期间，我们可以计算大约40,000条指令。
- en: ^([18](ch04.html#idm45606835464576-marker)) In some sources, this technique
    is also called CPU threading (aka hardware threads). I will avoid this terminology
    in this book due to possible confusion with operating system threads.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch04.html#idm45606835464576-marker)) 在一些资料中，这种技术也称为 CPU 线程（又称硬件线程）。由于可能与操作系统线程引起混淆，本书将避免使用这种术语。
- en: ^([19](ch04.html#idm45606835463680-marker)) Do not confuse Hyper-Threading logical
    cores with virtual CPUs (vCPUs) referenced when we use virtualizations like virtual
    machines. Guest operating systems use the machine’s physical or logical CPUs depending
    on host choice, but in both cases, they are called vCPUs.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch04.html#idm45606835463680-marker)) 不要将超线程逻辑核心与在虚拟化中使用的虚拟 CPU（vCPU）混淆。客户操作系统根据主机选择使用机器的物理或逻辑
    CPU，但在两种情况下，它们都被称为 vCPU。
- en: ^([20](ch04.html#idm45606835364128-marker)) There are [lots of good materials](https://oreil.ly/8OPW3)
    about tuning up the operating system. Many virtualization mechanisms, like containers
    with orchestrating systems like Kubernetes, also have their notion of priorities
    and affinities (pinning processes to specific cores or machines). In this book,
    we focus on writing efficient code, but we must be aware that execution environment
    tuning has an important role in ensuring quick and reliable program executions.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](ch04.html#idm45606835364128-marker)) 有关调整操作系统的良好材料，[很多](https://oreil.ly/8OPW3)。许多虚拟化机制，如具有像Kubernetes这样的编排系统的容器，也有它们的优先级和亲和性概念（将进程固定到特定的核心或机器）。在本书中，我们专注于编写高效的代码，但必须意识到执行环境的调整在确保程序快速可靠执行中起着重要作用。
- en: ^([21](ch04.html#idm45606835341536-marker)) Details around Go runtime implementing
    Go scheduling [are pretty impressive](https://oreil.ly/G9bFb). Essentially, Go
    does everything to keep the OS thread busy (spinning the OS thread) so it’s not
    moving to a blocking state as long as possible. If needed, it can steal goroutines
    from other threads, poll networks, etc., to ensure we keep the CPU busy so the
    OS does not preempt the Go process.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch04.html#idm45606835341536-marker)) 围绕Go运行时实现Go调度的细节[相当令人印象深刻](https://oreil.ly/G9bFb)。基本上，Go尽一切努力保持操作系统线程忙碌（旋转操作系统线程），以便尽可能长时间地保持不进入阻塞状态。如果需要，它可以从其他线程窃取goroutine，轮询网络等，以确保我们保持CPU忙碌，使操作系统不会抢占Go进程。
- en: ^([22](ch04.html#idm45606835218752-marker)) In practice, there are ways to get
    this information using debug tracing. However, we should not rely on the program
    knowing which goroutine is a parent goroutine for normal execution flow.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch04.html#idm45606835218752-marker)) 在实践中，有办法使用调试跟踪获取这些信息。但是，我们不应依赖程序知道哪个goroutine是正常执行流的父goroutine。
- en: ^([23](ch04.html#idm45606834944896-marker)) Funny enough, even atomic operations
    on CPU require some kind of locking. The difference is that instead of specialized
    locking mechanisms like [spinlock](https://oreil.ly/ZKXuN), atomic instruction
    can use faster [memory bus lock](https://oreil.ly/9jchk).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](ch04.html#idm45606834944896-marker)) 有趣的是，即使是CPU上的原子操作也需要某种形式的锁定。不同之处在于，与专门的自旋锁机制不同，原子指令可以使用更快的[内存总线锁](https://oreil.ly/9jchk)。
- en: ^([24](ch04.html#idm45606834933072-marker)) Assuming the programmer keeps to
    that rule. There is a way to send a pointer variable (e.g., `*string`) that points
    to shared memory, which violates the rule of sharing information through communicating.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](ch04.html#idm45606834933072-marker)) 假设程序员遵循这个规则。有一种方法可以发送一个指向共享内存的指针变量（例如，`*string`），这违反了通过通信共享信息的规则。
- en: ^([25](ch04.html#idm45606834709824-marker)) I omitted two additional mechanisms
    on purpose. First of all, `runtime.Gosched()` exists, which allows yielding the
    current goroutine so others can do some work in the meantime. This command is
    less useful nowadays since the current Go scheduler is preemptive, and manual
    yielding has become impractical. The second interesting operation, `runtime.LockOSThread()`,
    sounds useful, but it’s not designed for efficiency; rather, it pins the goroutine
    to the OS thread so we can read certain OS thread states from it.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: ^([25](ch04.html#idm45606834709824-marker)) 我特意省略了两个额外的机制。首先，`runtime.Gosched()`
    存在，允许当前goroutine让出执行权，以便其他goroutine在此期间执行一些工作。这个命令如今不太有用，因为当前的Go调度器是抢占式的，手动让出执行权已变得不切实际。第二个有趣的操作，`runtime.LockOSThread()`，听起来有用，但它并非设计用于效率；相反，它将goroutine固定到操作系统线程，以便我们可以从中读取某些操作系统线程状态。
- en: ^([26](ch04.html#idm45606834697536-marker)) I recommend watching [Chris Hines’s
    talk from GopherCon 2019](https://oreil.ly/LoFiH) to learn the low-level details
    around the Go scheduler.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: ^([26](ch04.html#idm45606834697536-marker)) 我建议观看[Chris Hines在GopherCon 2019的演讲](https://oreil.ly/LoFiH)，以了解有关Go调度器的低级细节。
