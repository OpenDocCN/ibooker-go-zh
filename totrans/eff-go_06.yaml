- en: Chapter 6\. Efficiency Observability
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。效率可观察性
- en: In [“Efficiency-Aware Development Flow”](ch03.html#ch-conq-eff-flow), you learned
    to follow the TFBO (test, fix, benchmark, and optimize) flow to validate and achieve
    the required efficiency results with the least effort. Around the elements of
    the efficiency phase, observability takes one of the key roles, especially in
    Chapters [7](ch07.html#ch-observability2) and [9](ch09.html#ch-observability3).
    We focus on that phase in [Figure 6-1](#img-obs-intro).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“高效开发流程”](ch03.html#ch-conq-eff-flow)中，你学会了遵循TFBO（测试、修复、基准测试和优化）流程，以最小的努力验证和实现所需的效率结果。在效率阶段的元素周围，可观察性起着关键作用，特别是在第[7](ch07.html#ch-observability2)和第[9](ch09.html#ch-observability3)章。我们将在[图6-1](#img-obs-intro)中专注于该阶段。
- en: '![efgo 0601](assets/efgo_0601.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0601](assets/efgo_0601.png)'
- en: Figure 6-1\. An excerpt from [Figure 3-5](ch03.html#img-opt-flow) focusing on
    the part that requires good observability
  id: totrans-3
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-1。[图3-5](ch03.html#img-opt-flow)的一部分，重点关注需要良好可观察性的部分
- en: 'In this chapter, I will explain the required observability and monitoring tools
    for this part of the flow. First, we will learn what observability is and what
    problems it solves. Then, we will discuss different observability signals, typically
    divided into logs, tracing, metrics, and, recently, profiles. Next, we will explain
    the first three signals in [“Example: Instrumenting for Latency”](#ch-obs-signals),
    which takes latency as an example of the efficiency information we might want
    to measure (profiling is explained in [Chapter 9](ch09.html#ch-observability3)).
    Last but not least, we will go through the specific semantics and sources of metrics
    related to our program efficiency in [“Efficiency Metrics Semantics”](#ch-obs-semantics).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将解释这一流程所需的可观察性和监控工具。首先，我们将了解什么是可观察性以及它解决了什么问题。然后，我们将讨论不同的可观察性信号，通常分为日志、追踪、指标，以及最近的概要。接下来，我们将在[“示例：为延迟进行仪器化”](#ch-obs-signals)中解释前三个信号，以延迟作为我们可能想要测量的效率信息的示例（概要在[第9章](ch09.html#ch-observability3)中解释）。最后但同样重要的是，我们将通过[“效率指标语义”](#ch-obs-semantics)详细介绍与程序效率相关的指标的特定语义和来源。
- en: You Can’t Improve What You Don’t Measure!
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你无法改进你不测量的东西！
- en: 'This quote, often attributed to Peter Drucker, is a key to improving anything:
    business revenues, car efficiency, family budget, body fat, or [even happiness](https://oreil.ly/eKiIR).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这句经常被归因于彼得·德鲁克的名言是改善任何事物的关键：业务收入、汽车效率、家庭预算、体脂肪，甚至[幸福](https://oreil.ly/eKiIR)。
- en: Especially when it comes to invisible waste that our inefficient software is
    producing, we can say that it’s impossible to optimize software without assessing
    and measuring before and after the change. Every decision must be data driven,
    as our guesses in this virtual space are often wrong.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是当涉及到我们低效软件产生的看不见的浪费时，我们可以说，如果在改变之前和之后不进行评估和测量，优化软件是不可能的。每个决定都必须以数据驱动，因为在这个虚拟空间中，我们的猜测往往是错误的。
- en: With no further ado, let’s learn how to measure the efficiency of our software
    in the easiest possible way—with the concept the industry calls observability.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不拖延，让我们学习如何以最简单的方式来衡量我们软件的效率——这个行业称之为可观察性的概念。
- en: Observability
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可观察性
- en: To control software efficiency, we first need to find a structured and reliable
    way to measure the latency and resource usage of our Go applications. The key
    is to count these as accurately as possible and present them at the end as easy
    to understand numeric values. This is why for consumption measurements, we sometimes
    (not always!) use a “metric signal,” which is a pillar of the essential software
    (or system) characteristics called observability.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要控制软件的效率，我们首先需要找到一种结构化和可靠的方法来测量我们的Go应用程序的延迟和资源使用情况。关键是尽可能准确地计算这些值，并在最后以易于理解的数值形式呈现出来。这就是为什么对于消耗测量，我们有时（并非总是！）使用“度量信号”，这是被称为可观察性的基本软件（或系统）特征的支柱。
- en: Observability
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可观察性
- en: 'In the cloud-native infrastructure world, we often talk about the observability
    of our applications. Unfortunately, observability is a very overloaded word.^([1](ch06.html#idm45606832729952))
    It can be summarized as follows: an ability to deduce the state of a system inferred
    from external signals.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在云原生基础设施世界中，我们经常谈论我们应用程序的可观察性。不幸的是，可观察性是一个非常负载的词。^([1](ch06.html#idm45606832729952))
    它可以总结如下：从外部信号推断系统状态的能力。
- en: 'The external signals the industry uses nowadays can be generally categorized
    into four types: metrics, logs, traces, and profiling.^([2](ch06.html#idm45606832725840))'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当今行业使用的外部信号通常可以大致分为四类：指标、日志、追踪和性能分析。^([2](ch06.html#idm45606832725840))
- en: Observability is a huge topic nowadays as it can help us in many situations
    while developing and operating our software. Observability patterns allow us to
    debug failures or unexpected behaviors of our programs, find root causes of incidents,
    monitor healthiness, alert on unforeseen situations, perform billing, measure
    [SLIs (service level indicators)](https://oreil.ly/hsdXJ), run analytics, and
    much more. Naturally, we will focus only on the parts of observability that will
    help us ensure that our software efficiency matches our requirements (the RAERs
    mentioned in [“Efficiency Requirements Should Be Formalized”](ch03.html#ch-conq-req-formal)).
    So what is an observability signal?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 可观测性是当今一个重要的话题，因为它在开发和运行软件过程中能帮助我们应对许多情况。可观测性模式使我们能够调试程序的失败或意外行为，找到事故的根本原因，监控健康状况，对未预料到的情况进行警报，执行计费，测量[SLI（服务水平指标）](https://oreil.ly/hsdXJ)，进行分析等等。当然，我们只会专注于可观测性的那些部分，这些部分将帮助我们确保软件的效率与我们的需求相匹配（即RAERs在[“效率要求应被正式化”](ch03.html#ch-conq-req-formal)中提到的）。那么，什么是可观测性信号？
- en: Metrics are a numeric representation of data measured over intervals of time.
    Metrics can harness the power of mathematical modeling and prediction to derive
    knowledge of the behavior of a system over intervals of time in the present and
    future.
  id: totrans-15
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标是对时间间隔内数据的数值表示。指标可以利用数学建模和预测的能力，从而推导出系统在当前和未来时间间隔内的行为知识。
- en: 'An event log is an immutable, timestamped record of discrete events that happened
    over time. Event logs in general come in three forms but are fundamentally the
    same: a timestamp and a payload of some context.'
  id: totrans-16
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件日志是一种不可变的、带有时间戳的记录，记录了随时间发生的离散事件。一般来说，事件日志有三种形式，但本质上是相同的：时间戳和一些上下文信息的负载。
- en: A trace is a representation of a series of causally related distributed events
    that encode the end-to-end request flow through a distributed system. Traces are
    a representation of logs; the data structure of traces looks almost like that
    of an event log. A single trace can provide visibility into both the path traversed
    by a request as well as the structure of a request.
  id: totrans-17
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 追踪是一个代表一系列因果相关的分布式事件的表示形式，它编码了通过分布式系统的端到端请求流。追踪是日志的一种表示形式；追踪的数据结构几乎与事件日志相似。一个单独的追踪可以提供对请求经过的路径以及请求结构的可见性。
- en: ''
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Cindy Sridharan, [*Distributed Systems Observability*](https://oreil.ly/YrSIE)
    (O’Reilly, 2018)
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Cindy Sridharan，《分布式系统可观测性》（O’Reilly，2018）
- en: Generally, all those signals can be used to observe our Go applications’ latency
    and resource consumption for optimization purposes. For example, we can measure
    the latency of a specific operation and expose it as a metric. We can send that
    value encoded into a log line or trace annotations (e.g., [“baggage”](https://oreil.ly/V5sQ6)
    items). We can calculate latency by subtracting the timestamps of two log lines—when
    the operation started and when it finished. We can use trace spans, which track
    the latency of a span (individual unit of work done) by design.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，所有这些信号都可以用来观察我们的Go应用程序的延迟和资源消耗，以进行优化。例如，我们可以测量特定操作的延迟，并将其作为指标暴露出来。我们可以将该值编码为日志行或追踪注释（例如，“行李”项）。我们可以通过减去两个日志行的时间戳来计算延迟——操作开始和操作完成的时间戳。我们可以使用追踪跨度来跟踪跨度的延迟（完成的个体工作单元）。
- en: 'However, whatever we use to deliver that information to us (via metric-specific
    tools, logs, traces, or profiles), in the end, it has to have metric semantics.
    We need to derive information to a numeric value so we can gather it over time;
    subtract; find max, min, or average; and aggregate over dimensions. We need the
    information to visualize and analyze. We need it to allow tools to reactively
    alert us when required, potentially build further automation that will consume
    it, and compare other metrics. This is why an efficiency discussion will mostly
    navigate through metric aggregations: the tail latency of our application, maximum
    memory usage over time, etc.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，无论我们用什么方式将这些信息传递给我们（通过特定于度量的工具、日志、追踪或概要文件），最终都必须具有度量语义。我们需要将信息推导为数值，以便随时间收集它；进行减法运算；查找最大值、最小值或平均值；以及按维度聚合。我们需要这些信息来进行可视化和分析。我们需要它允许工具在需要时做出反应并提醒我们，可能构建进一步消费它的自动化，并比较其他指标。这就是为什么效率讨论通常会通过度量聚合进行导航的原因：我们应用程序的尾延迟、随时间的最大内存使用等。
- en: As we discussed, to optimize anything, you have to start measuring it, so the
    industry has developed many metrics and instruments to capture the usage of various
    resources. The process of observing or measuring always starts with the instrumentation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论的那样，为了优化任何东西，您必须开始测量它，因此行业已经开发出许多指标和工具来捕获各种资源的使用情况。观察或测量的过程始终从仪器化开始。
- en: Instrumentation
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 仪器化
- en: Instrumentation is a process of adding or enabling instruments for our code
    that will expose the observability signals we need.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 仪器化是向我们的代码添加或启用仪器，以公开我们所需的可观察信号的过程。
- en: 'Instrumentation can have many forms:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 仪器化可以采用多种形式：
- en: Manual instrumentation
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 手动仪器化
- en: We can add a few statements to our code that import a Go module that generates
    an observability signal (for example, [Prometheus client for metrics](https://oreil.ly/AoWkJ),
    [go-kit logger](https://oreil.ly/adTO3), or [a tracing](https://oreil.ly/o7uYH)
    library) and hook it to the operations we do. Of course, this requires modifying
    our Go code, but it usually leads to more personalized and rich signals with more
    context. Usually, it represents [open box](https://oreil.ly/qMjUP) information
    because we can collect information tailored to the program functionality.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以向我们的代码添加几个语句，导入一个生成可观测信号的Go模块（例如，[Prometheus客户端用于度量](https://oreil.ly/AoWkJ)，[go-kit日志记录器](https://oreil.ly/adTO3)，或者[跟踪库](https://oreil.ly/o7uYH)），并将其连接到我们执行的操作中。当然，这需要修改我们的Go代码，但通常会产生更个性化和丰富的信号以及更多的上下文。通常，它代表了[开箱即用](https://oreil.ly/qMjUP)信息，因为我们可以收集针对程序功能定制的信息。
- en: Autoinstrumentation
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 自动仪器化
- en: Sometimes instrumentation means installing (and configuring) a tool that can
    derive useful information by looking at outside effects. For example, a service
    mesh gathers observability by looking at HTTP requests and responses, or a tool
    hooks to the operating system and gathers information through [cgroups](https://oreil.ly/aCe6S)
    or [eBPF](https://oreil.ly/QjxV9).^([3](ch06.html#idm45606832699376)) Autoinstrumentation
    does not require changing and rebuilding code and usually represents [closed box
    information](https://oreil.ly/UO0gK).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，仪器化意味着安装（和配置）一个工具，该工具可以通过观察外部效果来获取有用信息。例如，服务网格通过观察HTTP请求和响应来收集可观察性，或者工具钩入操作系统并通过[cgroups](https://oreil.ly/aCe6S)或[eBPF](https://oreil.ly/QjxV9)收集信息。^([3](ch06.html#idm45606832699376))
    自动仪器化不需要更改和重新构建代码，并且通常代表了[封闭盒](https://oreil.ly/UO0gK)信息。
- en: 'On top of that, it’s helpful to categorize instrumentation based on the granularity
    of the information:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，基于信息的粒度对仪器化进行分类也很有帮助：
- en: Capturing raw events
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获原始事件
- en: Instrumentation in this category will try to deliver a separate piece of information
    for each event in our process. For example, suppose we would like to know how
    many and what errors are happening in all HTTP requests served by our process.
    In that case, we could have instrumentation that delivers a separate piece of
    information about each request (e.g., as a log line). Furthermore, this information
    usually has some metadata about its context, like the status code, user IP, timestamp,
    and the process and code statement in which it happened (target metadata).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 此类仪器化将尝试为我们过程中的每个事件提供单独的信息。例如，假设我们想知道我们的进程为所有HTTP请求提供了多少次以及发生了什么错误。在这种情况下，我们可以有一个为每个请求提供单独信息的仪器化（例如，作为日志行）。此外，此信息通常包含有关其上下文的一些元数据，例如状态代码、用户IP、时间戳以及发生错误的进程和代码语句（目标元数据）。
- en: Once ingested to some observability backend, such raw data is very rich in context
    and, in theory, allows any ad hoc analysis. For example, we can scan through all
    events to find an average number of errors or the percentile distributions (more
    on that in [“Latency”](#ch-obs-latency)). We can navigate to every individual
    error representing a single event to inspect it in detail. Unfortunately, this
    kind of data is generally the most expensive to use, ingest, and store. We often
    risk an inaccuracy here since it’s likely we’ll miss an individual event or two.
    In extreme cases, it requires complex skills and automation for big data and data
    mining explorations to find the information you want.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦被摄取到某个可观测性后端，这些原始数据在内容上非常丰富，并且理论上允许任何的即席分析。例如，我们可以扫描所有事件以找到错误的平均数或百分位分布（更多内容请参阅[“延迟”](#ch-obs-latency)）。我们可以导航到每个表示单个事件的错误，以便详细检查。不幸的是，这种类型的数据通常是使用、摄取和存储成本最高的数据。我们往往会因此而冒失误的风险，因为可能会错过一个或两个个体事件。在极端情况下，需要复杂的大数据和数据挖掘探索技能和自动化来找到您想要的信息。
- en: Capturing aggregated information
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获聚合信息
- en: We can capture pre-aggregated data instead of raw events. Every piece of information
    delivered by such instrumentation represents certain information about a group
    of events. In our HTTP server example, we could count successful and failed requests,
    and periodically deliver that information. Before forwarding this information,
    we could go even further and pre-calculate the error ratio inside our code. It’s
    worth mentioning that this kind of information also requires metadata, so we can
    summarize, aggregate further, compare, and analyze those aggregated pieces of
    information.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以捕获预聚合数据而不是原始事件。由这种仪器化交付的每一条信息都代表一组事件的某些信息。在我们的 HTTP 服务器示例中，我们可以计算成功和失败的请求，并定期传递该信息。在转发此信息之前，我们甚至可以进一步计算代码内的错误比率。值得一提的是，这种类型的信息也需要元数据，以便我们可以总结、进一步聚合、比较和分析这些聚合的信息片段。
- en: Pre-aggregated instrumentation forces Go processes or autoinstrumentation tools
    to do more work, but the results are generally easier to use. On top of this,
    because of the smaller amount of data, the complexity of the instrumentation,
    signal delivery, and backend is lower, thereby increasing reliability and decreasing
    cost significantly. There are trade-offs here as well. We lose some information
    (commonly called the cardinality). The decision of what information to prebuild
    is made up front, and is coded into instrumentation. If you suddenly have different
    questions to be answered (e.g., how many errors an individual user had across
    your processes) and your instrumentation was not set to pre-aggregate that information,
    you have to change it, which takes time and resources. Yet if you roughly know
    what you will be asking for ahead of time, aggregated type of information is an
    amazing win and a more pragmatic approach.^([4](ch06.html#idm45606832688544))
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 预聚合的仪表化迫使 Go 进程或自动仪器化工具承担更多工作，但通常结果更易使用。此外，由于数据量较小，仪表化、信号传递和后端的复杂性更低，从而显著提高了可靠性并降低了成本。在这里也存在一些权衡。我们会丢失一些信息（通常称为基数）。预建的信息决策是事先做出的，并且编码到仪表化中。如果突然有不同的问题需要回答（例如，跨多个进程的单个用户有多少错误），而您的仪器化未设置为预聚合该信息，那么您就需要进行更改，这需要时间和资源。然而，如果您大致知道将来会询问什么，聚合类型的信息就是一个了不起的胜利和更加务实的方法。^([4](ch06.html#idm45606832688544))
- en: 'Last but not least, generally speaking we can design our observability flows
    into push-and-pull collection models:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，一般而言，我们可以将我们的可观测流程设计成推拉式采集模型：
- en: Push
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 推送
- en: A system where a centralized remote process collects observability signals from
    your applications (including your Go programs).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一个中心化的远程进程系统从您的应用程序（包括您的 Go 程序）中收集可观测信号。
- en: Pull
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 拉取
- en: A system where application processes push the signal to a remote centralized
    observability system.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个应用程序进程将信号推送到远程集中的可观测性系统的系统。
- en: Push Versus Pull
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推送与拉取
- en: Each of the conventions has its pros and cons. You can push your metrics, logs,
    and traces, but you can also pull all of them from your process. We can also use
    a mixed approach, different for each observability signal.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每种惯例都有其利弊。您可以推送您的度量、日志和跟踪，但也可以从您的进程中拉取所有这些。我们还可以使用混合方法，每种可观测信号使用不同的方法。
- en: Push versus pull method is sometimes a controversial topic. The industry is
    polarized as to what is generally better, not only in observability but also for
    any other architectures. We will discuss the pros and cons in [“Metrics”](#ch-obs-metrics),
    but the difficult truth is that both ways can scale equally well, just with different
    solutions, tools, and best practices.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 推送与拉取方法有时是一个有争议的话题。不仅在可观测性方面，在任何其他架构中都是如此。我们将在[“指标”](#ch-obs-metrics)中讨论其利弊，但困难的事实是，两种方式都可以同样良好地扩展，只是使用不同的解决方案、工具和最佳实践。
- en: 'After learning about those three categories, we should be ready to dive further
    into observability signals. To measure and deliver observability information for
    efficiency optimizations, we can’t avoid learning more about instrumenting the
    three common observability signals: logging, tracing, and metrics. In the next
    section, let’s do that while keeping a practical goal in mind—measuring latency.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习了这三个类别之后，我们应该准备深入探讨可观测信号。为了测量和传递效率优化的可观测信息，我们无法避免学习更多关于仪器化这三种常见可观测信号——记录、跟踪和指标的内容。在下一节中，让我们做到这一点，同时保持一个实际的目标——测量延迟。
- en: 'Example: Instrumenting for Latency'
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例：为延迟进行仪器化
- en: 'All three signals you will learn in this section can be used to build observability
    that will fit in any of the three categorizations we discussed. Each signal can:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习的所有三种信号都可以用于构建适合我们讨论的三种类别的可观测性。每种信号都可以：
- en: Be manually or autoinstrumented
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以手动或自动进行仪器化
- en: Give aggregated information or raw events
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供汇总信息或原始事件
- en: Be pulled (collected, tailed, or scraped) from the process or pushed (uploaded)
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以从进程中提取（收集，尾部跟踪或抓取）或推送（上传）
- en: Yet every signal—logging, tracing, or metric—might be better or worse fitted
    in any of those jobs. In this section, we will discuss these predispositions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，每种信号——记录、跟踪或指标——可能在这些工作中更合适或更不合适。在本节中，我们将讨论这些倾向。
- en: The best way to learn how to use observability signals and their trade-offs
    is to focus on the practical goal. Let’s imagine we want to measure the latency
    of a specific operation in our code. As mentioned in the introduction, we need
    to start measuring the latency to assess it and decide if our code needs more
    optimizations during every optimization iteration. As you will learn in this section,
    we can get latency results using any of those observability signals. The details
    around how information is presented, how complex instrumentation is, and so on
    will help you understand what to choose in your journey. Let’s dive in!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 学习如何使用可观测信号及其权衡的最佳方法是专注于实际目标。假设我们想要测量代码中特定操作的延迟。如介绍所述，我们需要开始测量延迟以评估其情况，并在每次优化迭代期间决定是否需要进一步优化我们的代码。正如您将在本节中了解到的，我们可以使用任何一种可观测信号来获得延迟结果。关于信息呈现方式、复杂仪器化等细节将帮助您在旅程中理解选择的内容。让我们深入探讨吧！
- en: Logging
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 记录
- en: Logging might be the clearest signal to understand an instrument. So let’s explore
    the most basic instrumentation that we might categorize as logging to collect
    latency measurements. Taking basic latency measurements for a single operation
    in Go code is straightforward, thanks to the standard [`time` package](https://oreil.ly/t9FDr).
    Whether you do it by hand or use standard or third-party libraries to obtain latencies,
    if they are written in Go, they use the pattern presented in [Example 6-1](#code-latency-simplest)
    using the `time` package.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 日志可能是了解仪器的最清晰信号。因此，让我们探索一下最基本的仪器，我们可以将其归类为记录以收集延迟测量数据。在Go代码中对单个操作进行基本的延迟测量是直接的，这要归功于标准的[`time`包](https://oreil.ly/t9FDr)。无论您是手动操作还是使用标准或第三方库来获取延迟数据，如果它们是用Go语言编写的，它们都使用了[示例 6-1](#code-latency-simplest)中使用`time`包的模式。
- en: Example 6-1\. Manual and simplest latency measurement of a single operation
    in Go
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-1\. Go中手动和最简单的单个操作延迟测量
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO1-1)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO1-1)'
- en: '`time.Now()` captures the current wall time (clock time) from our operating
    system clock in the form `time.Time`. Note the `xTime`, example variable that
    specifies the desired number of runs.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`time.Now()`从操作系统时钟中捕获当前墙上时间（时钟时间），以`time.Time`形式呈现。请注意`xTime`，示例变量指定所需的运行次数。'
- en: '[![2](assets/2.png)](#co_efficiency_observability_CO1-2)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_efficiency_observability_CO1-2)'
- en: After our `cooperation` functions finish, we can capture the time between `start`
    and current time using `time.Since(start)`, which returns the handy `time.Duration`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`协作`函数完成后，我们可以使用`time.Since(start)`捕获从`start`到当前时间的时间，该方法返回方便的`time.Duration`。
- en: '[![3](assets/3.png)](#co_efficiency_observability_CO1-3)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_efficiency_observability_CO1-3)'
- en: We can leverage such an instrument to deliver our metric sample. For example,
    we can print the duration in nanoseconds to the standard output using the `.Nanoseconds()`
    method.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用这样的工具来传递我们的度量样本。例如，我们可以使用`.Nanoseconds()`方法将持续时间以纳秒打印到标准输出。
- en: Arguably, [Example 6-1](#code-latency-simplest) represents the simplest form
    of instrumentation and observability. We take a latency measurement and deliver
    it by printing the result into standard output. Given that every operation will
    output a new line, [Example 6-1](#code-latency-simplest) represents manual instrumentation
    of raw event information.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，[示例 6-1](#code-latency-simplest)代表了最简单的仪器化和可观测性形式。我们进行延迟测量，并通过将结果打印到标准输出来传递它。鉴于每次操作都将输出一行新数据，[示例 6-1](#code-latency-simplest)代表了原始事件信息的手动仪器化。
- en: Unfortunately, this is a little naive. First of all, as we will learn in [“Reliability
    of Experiments”](ch07.html#ch-obs-rel), a single measurement of anything can be
    misleading. We have to capture more of those—ideally hundreds or thousands for
    statistical purposes. When we have one process, and only one functionality we
    want to test or benchmark, [Example 6-1](#code-latency-simplest) will print hundreds
    of results that we can later analyze. However, to simplify the analysis, we could
    try to pre-aggregate some results. Instead of logging raw events, we could pre-aggregate
    using a mathematical average function and output that. [Example 6-2](#code-latency-simplest-aggr)
    presents a modification of [Example 6-1](#code-latency-simplest) that aggregates
    events into an easier-to-consume result.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这有点幼稚。首先，正如我们将在[“实验的可靠性”](ch07.html#ch-obs-rel)中学到的那样，任何单一的测量都可能具有误导性。我们必须捕获更多这样的测量结果，理想情况下是数百或数千次，以供统计目的使用。当我们有一个进程，只有一个我们想要测试或基准测试的功能时，[示例 6-1](#code-latency-simplest)将打印出我们稍后可以分析的数百个结果。然而，为了简化分析，我们可以尝试预先聚合一些结果。与其记录原始事件，我们可以使用数学平均函数进行预先聚合并输出结果。[示例 6-2](#code-latency-simplest-aggr)展示了将事件聚合成更易于消费结果的修改版本。
- en: Example 6-2\. Instrumenting Go to log the average latency of an operation in
    Go
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-2\. 仪器化Go，记录Go操作的平均延迟
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO2-1)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO2-1)'
- en: Instead of printing raw latency, we can gather a sum and number of operations
    in the sum.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是打印原始延迟，我们可以收集总和和操作数的数量。
- en: '[![2](assets/2.png)](#co_efficiency_observability_CO2-2)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_efficiency_observability_CO2-2)'
- en: Those two pieces of information can be used to calculate the accurate average
    and present that for a group of events instead of the unique latency. For example,
    one run printed the `188324467 ns/op` string on my machine.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个信息片段可用于计算组事件的准确平均值，并呈现给用户，而不是唯一的延迟。例如，一次运行在我的机器上打印了`188324467 ns/op`字符串。
- en: Given that we stop presenting latency for raw events, [Example 6-2](#code-latency-simplest-aggr)
    represents a manual, aggregated information observability. This method allows
    us to quickly get the information we need without complex (and time-consuming)
    tools analyzing our logging outputs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们停止了对原始事件的延迟呈现，[示例 6-2](#code-latency-simplest-aggr) 表示了一种手动的、聚合的信息可观测性。这种方法允许我们快速获取所需的信息，而无需复杂（且耗时的）工具分析我们的日志输出。
- en: This example is how the Go benchmarking tool will do the average latency calculations.
    We can achieve exactly the same logic as in [Example 6-2](#code-latency-simplest-aggr)
    using the snippet in [Example 6-3](#code-latency-go-bench) in a file with the
    *_test.go* suffix.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例展示了Go基准测试工具如何进行平均延迟计算。我们可以使用带有*_test.go*后缀的文件中的[示例 6-3](#code-latency-go-bench)片段实现与[示例 6-2](#code-latency-simplest-aggr)完全相同的逻辑。
- en: Example 6-3\. Simplest Go benchmark that will measure average latency per operation
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-3\. 最简单的Go基准测试，将测量每次操作的平均延迟
- en: '[PRE2]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO3-1)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO3-1)'
- en: The `for` loop with the `N` variable is essential in the benchmarking framework.
    It allows the Go framework to try different `N` values to perform enough test
    runs to fulfill the configured number of runs or test duration. For example, by
    default, the Go benchmark runs to fit one second, which is often too short for
    meaningful output reliability.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在基准测试框架中，带有变量 `N` 的 `for` 循环是必不可少的。它允许 Go 框架尝试不同的 `N` 值来执行足够的测试运行，以满足配置的运行次数或测试持续时间。例如，默认情况下，Go
    基准测试运行时间为一秒，这通常对于可靠的输出来说太短了。
- en: Once we run [Example 6-3](#code-latency-go-bench) using `go test` (explained
    in detail in [“Go Benchmarks”](ch08.html#ch-obs-micro-go)), it will print certain
    output. One part of the information is a result line with a number of runs and
    average nanoseconds per operation. One of the runs on my machine gave an output
    latency of `197999371 ns/op`, which generally matches the result from [Example 6-2](#code-latency-simplest-aggr).
    We can say that the Go benchmark is an autoinstrumentation with aggregated information
    using logging signals for things like latency.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用 `go test` 运行 [示例 6-3](#code-latency-go-bench) 时（详细解释见 [“Go 基准测试”](ch08.html#ch-obs-micro-go)），它会输出特定的信息。信息的一部分是一个包含运行次数和每次操作的平均纳秒数的结果行。在我的机器上，其中一个运行的输出延迟为
    `197999371 ns/op`，这通常与 [示例 6-2](#code-latency-simplest-aggr) 的结果相匹配。我们可以说，Go 基准测试是使用日志记录信号进行自动仪器化，用于诸如延迟等的聚合信息。
- en: On top of collecting latency about the whole operation, we can gain a lot of
    insight from having different granularity of those measurements. For example,
    we might wish to capture the latency of a few suboperations inside our single
    operation. Finally, for more complex deployments, when our Go program is part
    of a distributed system, as discussed in [“Macrobenchmarks”](ch08.html#ch-obs-macro),
    we have potentially many processes we have to measure across. For those cases,
    we have to use more sophisticated logging that will give us more metadata and
    ways to deliver a logging signal, not only by simply printing to a file, but by
    other means too.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 除了收集整个操作的延迟信息之外，我们还可以从这些测量的不同粒度中获得许多见解。例如，我们可能希望捕获单个操作内几个子操作的延迟。最后，在更复杂的部署中，当我们的
    Go 程序是分布式系统的一部分时，正如 [“宏基准测试”](ch08.html#ch-obs-macro) 中讨论的那样，我们可能有许多进程需要跨系统进行测量。对于这些情况，我们必须使用更复杂的日志记录器，它们会为我们提供更多的元数据和传递日志信号的方法，不仅仅是简单地打印到文件，还可以通过其他方式实现。
- en: 'The amount of information we have to attach to our logging signal results in
    the pattern called a logger in Go (and other programming languages). A logger
    is a structure that allows us to manually instrument our Go application with logs
    in the easiest and most readable way. A logger hides complexities like:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须附加到日志信号的信息量会导致一种称为 Go 中的日志记录器模式的模式。日志记录器是一种结构，允许我们以最简单和最可读的方式手动为我们的 Go 应用程序加入日志。日志记录器隐藏了复杂性，比如：
- en: Formatting of the log lines.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志行的格式化。
- en: Deciding if we should log or not based on the logging level (e.g., debug, warning,
    error, or more).
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据日志级别（例如调试、警告、错误或更多）决定是否记录。
- en: Delivering the log line to a configured place, such as the output file. Optionally,
    more complex, push-based logging delivery is possible to remote backends, which
    must support back-off retries, authorization, service discovery, etc.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将日志行传递到配置的位置，例如输出文件。还可以选择更复杂的基于推送的日志传递方式，可以将日志传送到远程后端，必须支持退避重试、授权、服务发现等功能。
- en: Adding context-based metadata and timestamps.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加基于上下文的元数据和时间戳。
- en: The Go standard library is very rich with many useful utilities, including logging.
    For example, the [`log` package](https://oreil.ly/JEUjT) contains a simple logger.
    It can work well for many applications, but it is prone to some usage pitfalls.^([5](ch06.html#idm45606832254464))
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Go 标准库非常丰富，包含许多有用的工具，包括日志记录。例如，[`log` 包](https://oreil.ly/JEUjT)包含一个简单的日志记录器。它对许多应用程序都能很好地工作，但也容易出现一些使用上的陷阱。^([5](ch06.html#idm45606832254464))
- en: Be Mindful While Using the Go Standard Library Logger
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在使用 Go 标准库的日志记录器时请谨慎。
- en: 'There are a few things to remember if you want to use the standard Go logger
    from the `log` package:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用 `log` 包中的标准 Go 日志记录器，有几件事需要记住：
- en: Don’t use the global `log.Default()` logger, so `log.Print` functions, and so
    on. Sooner or later, it will bite you.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要使用全局的 `log.Default()` 日志记录器，也不要使用 `log.Print` 等函数。迟早会让你后悔。
- en: Never store or consume `*log.Logger` directly in your functions and structures,
    especially when you write a library.^([6](ch06.html#idm45606832248016)) If you
    do, users will be forced to use a very limited `log` logger instead of their own
    logging libraries. Use a custom interface instead (e.g., [go-kit logger](https://oreil.ly/tCs2g)),
    so users can adapt their loggers to what you use in your code.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 永远不要直接在你的函数和结构中存储或使用`*log.Logger`，特别是当你编写一个库时。^([6](ch06.html#idm45606832248016))
    如果你这样做，用户将被迫使用非常有限的`log`日志记录器，而不是他们自己的日志记录库。相反，使用自定义接口（例如[go-kit日志记录器](https://oreil.ly/tCs2g)），这样用户可以将他们的日志记录器适配到你在代码中使用的日志记录器。
- en: Never use the `Fatal` method outside the main function. It panics, which should
    not be your default error handling.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 永远不要在主函数之外使用`Fatal`方法。它会引发panic，这不应该是你的默认错误处理方式。
- en: To not accidentally get hit by these pitfalls, in the projects I worked on,
    we decided to use the third-party popular [go-kit](https://oreil.ly/ziBdb)^([7](ch06.html#idm45606832242864))
    logger. An additional advantage of the go-kit logger is that it is easy to maintain
    some structure. Structure logic is essential to have reliable parsers for automatic
    log analysis with logging backends like [OpenSearch](https://oreil.ly/RohpZ) or
    [Loki](https://oreil.ly/Fw9I3). To measure latency, let’s go through an example
    of logger usage in [Example 6-4](#code-latency-log). Its output is shown in [Example 6-5](#code-latency-log-result).
    We use the [`go-kit` module](https://oreil.ly/vOafG), but other libraries follow
    similar patterns.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免意外陷入这些陷阱，在我参与的项目中，我们决定使用第三方流行的[go-kit](https://oreil.ly/ziBdb)^([7](ch06.html#idm45606832242864))日志记录器。go-kit日志记录器的额外优势是很容易保持一定的结构。结构逻辑对于拥有可靠解析器的自动日志分析与像[OpenSearch](https://oreil.ly/RohpZ)或[Loki](https://oreil.ly/Fw9I3)这样的日志后端非常重要。为了衡量延迟，让我们通过一个日志记录器使用示例来演示，在[示例 6-4](#code-latency-log)中展示了它的输出。我们使用了[`go-kit`模块](https://oreil.ly/vOafG)，但其他库遵循类似的模式。
- en: Example 6-4\. Capturing latency though logging using the [`go-kit` logger](https://oreil.ly/9uCWi)
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-4\. 使用[`go-kit`日志记录器](https://oreil.ly/9uCWi)捕获延迟
- en: '[PRE3]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO4-1)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO4-1)'
- en: We initialize the logger. Libraries usually allow you to output the log lines
    to a file (e.g., standard output or error) or directly push it to some collections
    tool, e.g., to [fluentbit](https://oreil.ly/pUcmX) or [vector](https://oreil.ly/S0aqR).
    Here we choose to output all logs to standard error^([8](ch06.html#idm45606832090240))
    with a timestamp attached to each log line. We also choose to format logs in the
    human-accessible way with `NewLogfmtLogger` (still structured so that it can be
    parsed by software, with space as the delimiter).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化了日志记录器。通常，库允许你将日志行输出到文件（例如标准输出或错误），或直接推送到某些集合工具，例如[fluentbit](https://oreil.ly/pUcmX)或[vector](https://oreil.ly/S0aqR)。在这里，我们选择将所有日志输出到标准错误中，并为每行日志附加时间戳。我们还选择以人类可读的方式格式化日志，使用`NewLogfmtLogger`（仍然是结构化的，可以被软件解析，以空格作为分隔符）。
- en: '[![2](assets/2.png)](#co_efficiency_observability_CO4-2)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_efficiency_observability_CO4-2)'
- en: In [Example 6-1](#code-latency-simplest), we simply printed the latency number.
    Here we add certain metadata to it to use that information more easily across
    processes and different operations happening in the system. Notice that we maintain
    a certain structure. We pass an even number of arguments representing key values.
    This allows our log line to be structured for easier use by automation. Additionally,
    we choose `level.Info`, meaning this log line will be not printed if we choose
    levels like errors only.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 6-1](#code-latency-simplest)中，我们只是简单地打印了延迟数字。在这里，我们为其添加了某些元数据，以便更轻松地在系统中的不同进程和操作中使用该信息。请注意，我们保持了一定的结构。我们传递了偶数个参数，代表键值对。这使得我们的日志行结构化，更易于自动化使用。此外，我们选择了`level.Info`，这意味着如果我们选择了仅错误级别，这行日志将不会被打印出来。
- en: Example 6-5\. Example output logs generated by [Example 6-4](#code-latency-log)
    (wrapped for readability)
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-5\. 通过[示例 6-4](#code-latency-log)生成的示例输出日志（为了可读性进行了换行）
- en: '[PRE4]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO5-1)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO5-1)'
- en: Thanks to the log structure, it’s both readable to us and automation can clearly
    distinguish among different fields like `msg`, `elapsed`, `info`, etc. without
    expensive and error-prone fuzzy parsing.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了日志结构，这对我们来说很容易阅读，而且自动化可以清楚地区分诸如`msg`、`elapsed`、`info`等不同字段，无需昂贵且易出错的模糊解析。
- en: Logging with a logger might still be the simplest way to deliver our latency
    information manually to us. We can tail the file (or use `docker log` if our Go
    process was running in Docker, or `kubectl logs` if we deployed it on Kubernetes)
    to read those log lines for further analysis. It is also possible to set up an
    automation that tails those from files or pushes them directly to the collector,
    adding further information. Collectors can be then configured to push those log
    lines into free and open source logging backends like [OpenSearch](https://oreil.ly/RohpZ),
    [Loki](https://oreil.ly/Fw9I3), [Elasticsearch](https://oreil.ly/EUlts), or many
    of the paid vendors. As a result, you can keep log lines from many processes in
    a single place, search, visualize, analyze them, or build further automation to
    handle them as you want.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用记录器进行日志记录可能仍然是手动向我们提供延迟信息的最简单方式。我们可以尾随文件（或者如果我们的 Go 进程在 Docker 中运行，则使用 `docker
    log`，或者如果我们在 Kubernetes 上部署它，则使用 `kubectl logs`）以读取这些日志行进行进一步分析。还可以设置一个自动化程序，尾随这些文件或直接将它们推送到收集器，添加更多信息。然后可以配置收集器将这些日志行推送到免费和开源的日志后端，如[OpenSearch](https://oreil.ly/RohpZ)、[Loki](https://oreil.ly/Fw9I3)、[Elasticsearch](https://oreil.ly/EUlts)，或者许多付费供应商。因此，您可以将许多进程的日志行保存在一个地方，搜索、可视化、分析它们，或者构建进一步的自动化来处理它们。
- en: Is logging a good fit for our efficiency observability? Yes and no. For microbenchmarks
    explained in [“Microbenchmarks”](ch08.html#ch-obs-micro), logging is our primary
    tool of measurements because of its simplicity. On the other hand, on a macro
    level, like [“Macrobenchmarks”](ch08.html#ch-obs-macro), we tend to use logging
    for a raw event type of observability, which on such a scale gets very complex
    and expensive to analyze and keep reliable. Still, because logging is so common,
    we can find efficiency bottlenecks in a bigger system with logging.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录是否适合我们的效率可观测性？是和否。对于[“微基准”](ch08.html#ch-obs-micro)中解释的微基准，日志记录是我们的主要测量工具，因为它简单。另一方面，在宏观层面，如[“宏基准”](ch08.html#ch-obs-macro)，我们倾向于使用日志记录作为原始事件类型的可观测性工具，在这样的规模上，分析和保持可靠性变得非常复杂和昂贵。尽管如此，由于日志记录如此普遍，我们可以通过日志记录在更大的系统中找到效率瓶颈。
- en: Logging tools are also constantly evolving. For example, many tools allow us
    to derive metrics from log lines, like Grafana Loki’s [Metric queries inside LogQL](https://oreil.ly/fdoNm).
    In practice, however, simplicity has its cost. One of the problems stems from
    the fact that sometimes logs are used directly by humans, and sometimes by automation
    (e.g., deriving metrics or reacting to situations found in logs). As a result,
    logs are often unstructured. Even with amazing loggers like go-kit in [Example 6-4](#code-latency-log),
    logs are inconsistently structured, making it very hard and expensive to parse
    for automation. For example, things like inconsistent units (as in [Example 6-5](#code-latency-log-result)
    for latency measurements), which are great for humans, become almost impossible
    to derive the value as a metric. Solutions like [Google mtail](https://oreil.ly/Q4wAC)
    try to approach this with custom parsing language. Still, the complexity and ever-changing
    logging structure make it hard to use this signal to measure our code’s efficiency.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录工具也在不断发展。例如，许多工具允许我们从日志行中派生指标，比如 Grafana Loki 的[LogQL 中的度量查询](https://oreil.ly/fdoNm)。然而，在实践中，简单性是有代价的。问题之一源于有时日志直接由人类使用，有时由自动化使用（例如，从日志中派生指标或对日志中发现的情况做出反应）。因此，日志通常是非结构化的。即使使用像
    [示例 6-4](#code-latency-log) 中的 go-kit 这样的出色记录器，日志的结构也是不一致的，这使得解析用于自动化非常困难和昂贵。例如，像[示例
    6-5](#code-latency-log-result)中的延迟测量中存在的不一致单位，对人类来说很好，但几乎不可能将其派生为指标值。像[Google
    mtail](https://oreil.ly/Q4wAC)这样的解决方案尝试使用自定义解析语言来解决这个问题。然而，复杂性和不断变化的日志结构使得难以使用这个信号来衡量我们代码的效率。
- en: Let’s look at the next observability signal—tracing—to learn in which areas
    it can help us with our efficiency goals.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看下一个可观察信号——追踪，以了解它在哪些领域可以帮助我们实现效率目标。
- en: Tracing
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 追踪
- en: Given the lack of consistent structure in logging, tracing signals emerged to
    tackle some of the logging problems. In contrast to logging, tracing is a piece
    of structured information about your system. The structure is built around the
    transaction, for example, requests-response architecture. This means that things
    like status codes, the result of the operation, and the latency of operations
    are natively encoded, thus easier to use by automation and tools. As a trade-off,
    you need an additional mechanism (e.g., a user interface) to expose this information
    to humans in a readable way.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏一致结构的日志记录导致了追踪信号的出现，以解决部分日志问题。与日志记录相比，追踪是关于系统的结构化信息片段。该结构围绕事务建立，例如请求-响应架构。这意味着诸如状态码、操作结果和操作延迟等内容本地编码，因此更易于被自动化工具使用。作为一种权衡，你需要额外的机制（例如用户界面）以可读的方式向人类公开这些信息。
- en: On top of that, operations, suboperations, and even cross-process calls (e.g.,
    RPCs) can be linked together, thanks to context propagation mechanisms working
    well with standard network protocols like HTTP. This feels like a perfect choice
    for measuring latency for our efficiency needs, right? Let’s find out.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，操作、子操作甚至跨进程调用（例如RPC）都可以通过上下文传播机制链接在一起，这些机制与标准的网络协议（如HTTP）良好配合。这感觉就像是我们效率需求中测量延迟的完美选择，对吧？让我们找出答案。
- en: As with logging, there are many different manual instrumentation libraries you
    can choose from. Popular, open source choices for Go are the [OpenTracing](https://oreil.ly/gJeAV)
    library (currently deprecated but still viable), [OpenTelemetry](https://oreil.ly/uxKoW),
    or clients from the dedicated tracing vendor. Unfortunately, at the moment of
    writing, the OpenTelemetry library has a too-complex API to explain in this book,
    plus it’s still changing, so I started a [small project called tracing-go](https://oreil.ly/rs6fQ)
    that encapsulates the OpenTelemetry client SDK into minimal tracing instrumentation.
    While tracing-go is my interpretation of the minimal set of tracing functionalities
    to use, it should teach you the basics of context propagation and span logic.
    Let’s explore an example manual instrumentation using tracing-go to measure dummy
    `doOperation` function latency (and more!) using tracing in [Example 6-6](#code-latency-trace).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '与日志记录一样，你可以选择许多不同的手动仪表化库。对于Go语言，流行的开源选择包括[OpenTracing](https://oreil.ly/gJeAV)库（目前已弃用但仍然可用）、[OpenTelemetry](https://oreil.ly/uxKoW)，或来自专用追踪供应商的客户端。不幸的是，在撰写本书时，OpenTelemetry库具有过于复杂的API，难以在本书中进行解释，并且它仍在变化，因此我开始了一个名为[tracing-go](https://oreil.ly/rs6fQ)的小项目，将OpenTelemetry客户端SDK封装成最小的追踪仪器。虽然tracing-go是我对最小追踪功能集的解释，但它应该教会你上下文传播和span逻辑的基础知识。让我们探索一个使用tracing-go进行手动仪表化的示例，以测量在[示例6-6](#code-latency-trace)中使用追踪测量虚拟`doOperation`函数延迟（及更多！）。  '
- en: Example 6-6\. Capturing latencies of the operation and potential suboperations
    using [tracing-go](https://oreil.ly/1027d)
  id: totrans-109
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例6-6。使用[tracing-go](https://oreil.ly/1027d)捕获操作和潜在子操作的延迟
- en: '[PRE5]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO6-1)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO6-1)'
- en: As with everything, we have to initialize our library. In our example, usually,
    it means creating an instance of `Tracer` that is capable of sending the spans
    that will form traces. We push spans to some collector and eventually to the tracing
    backend. This is why we have to specify some address to send to. In this example,
    you could specify a gRPC `host:port` address of the collector (e.g., [OpenTelemetry
    Collector](https://oreil.ly/z0Pjt)) endpoint that supports the [gRPC OTLP trace
    protocol](https://oreil.ly/4IaBd).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 和其他一切一样，我们必须初始化我们的库。在我们的例子中，通常意味着创建一个能够发送形成跟踪的span的`Tracer`实例。我们将span推送到某个收集器，最终传输到追踪后端。这就是为什么我们必须指定某个地址以发送到的原因。在这个例子中，你可以指定收集器的gRPC
    `host:port`地址（例如，支持[gRPC OTLP追踪协议](https://oreil.ly/4IaBd)的[OpenTelemetry收集器](https://oreil.ly/z0Pjt)端点）。
- en: '[![2](assets/2.png)](#co_efficiency_observability_CO6-2)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_efficiency_observability_CO6-2)'
- en: With the tracer, we can create an initial root `span`. The root means the span
    that spans the whole transaction. A `traceID` is created during creation, identifying
    all spans in the trace. Span represents individual work done. For example, we
    can add a different name or even baggage items like logs or events. We also get
    a `context.Context` instance as part of creation. This Go native context interface
    can be used to create subspans if our `doOperation` function will do any subwork
    pieces worth instrumenting.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用跟踪器，我们可以创建一个初始根 `span`。根表示跨越整个事务的 span。在创建过程中会创建一个`traceID`，用于标识跟踪中的所有 span。每个
    span 代表一个个体工作单元。例如，我们可以添加不同的名称，甚至像日志或事件这样的 baggage 项。创建过程还会得到一个 `context.Context`
    实例。作为创建的一部分，此 Go 原生上下文接口可用于创建子 span，如果我们的 `doOperation` 函数将执行任何值得检测的子工作单元。
- en: '[![3](assets/3.png)](#co_efficiency_observability_CO6-3)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_efficiency_observability_CO6-3)'
- en: In the manual instrumentation, we have to tell the tracing provider when the
    work was done and with what result. In the `tracing-go` library, we can use `end.Stop(<error
    or nil>)` for that. Once you stop the span, it will record the span’s latency
    from its start, the potential error, and mark itself as ready to be sent asynchronously
    by `Tracer`. Tracer exporter implementations usually won’t send spans straightaway
    but buffer them for batch pushes. `Tracer` will also check if a trace containing
    some spans can be sent to the endpoint based on the chosen sampling strategy (more
    on that later).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在手动工具中，我们必须告诉跟踪提供程序工作何时完成以及结果如何。在 `tracing-go` 库中，我们可以使用 `end.Stop(<error 或
    nil>)`。一旦停止 span，它将记录从开始到结束的延迟，潜在的错误，并标记自身为可以异步发送给 `Tracer`。跟踪导出器实现通常不会立即发送 span，而是将它们缓冲以进行批量推送。`Tracer`
    还会检查基于所选采样策略的端点是否可以发送包含某些 span 的跟踪（稍后会详细介绍）。
- en: '[![4](assets/4.png)](#co_efficiency_observability_CO6-4)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_efficiency_observability_CO6-4)'
- en: Once you have context with the injected span creator, we can add subspans to
    it. It’s useful when you want to debug different parts and sequences involved
    in doing one piece of work.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 有了注入的 span 创建器上下文之后，我们可以向其添加子 span。当您希望调试涉及执行一项工作的不同部分和顺序时，这将非常有用。
- en: One of the most valuable parts of tracing is context propagation. This is what
    separates distributed tracing from nondistributed signals. I did not reflect this
    in our examples, but imagine if our operation makes a network call to other microservices.
    Distributed tracing allows passing various tracing information like `traceID`,
    or sampling via a propagation API (e.g., certain encoding using HTTP headers).
    See a [related blog post](https://oreil.ly/Qz6lF) about context propagation. For
    that to work in Go, you have to add a special middleware or HTTP client with propagation
    support, e.g., [OpenTelemetry HTTP transport](https://oreil.ly/Rvq6i).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪中最有价值的部分之一是上下文传播。这就是分布式跟踪与非分布式信号的区别所在。我们在示例中没有反映这一点，但想象一下，如果我们的操作向其他微服务发出网络调用。分布式跟踪允许通过传播
    API（例如，使用 HTTP 标头的某种编码）传递各种跟踪信息，如`traceID`或采样。参见关于上下文传播的[相关博客文章](https://oreil.ly/Qz6lF)。为了在
    Go 中实现这一点，您必须添加一个具有传播支持的特殊中间件或 HTTP 客户端，例如[OpenTelemetry HTTP 传输](https://oreil.ly/Rvq6i)。
- en: Because of the complex structure, raw traces and spans are not readable by humans.
    This is why many projects and vendors help users by providing solutions to use
    tracing effectively. Open source solutions like [Grafana Tempo with Grafana UI](https://oreil.ly/CQ1Aq)
    and [Jaeger](https://oreil.ly/enkG9) exist, which offer nice user interfaces and
    trace collection so you can observe your traces. Let’s look at how our spans from
    [Example 6-6](#code-latency-trace) look in the latter project. [Figure 6-2](#img-obs-tracing)
    shows a multitrace search view, and [Figure 6-3](#img-obs-spans) shows what our
    individual `doOperation` trace looks like.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其复杂结构，原始跟踪和 span 对人类来说不可读。这就是为什么许多项目和供应商通过提供有效使用跟踪的解决方案来帮助用户。存在像 [Grafana
    Tempo with Grafana UI](https://oreil.ly/CQ1Aq) 和 [Jaeger](https://oreil.ly/enkG9)
    这样的开源解决方案，它们提供良好的用户界面和跟踪收集，以便您观察自己的跟踪。让我们看看我们的跟踪从 [Example 6-6](#code-latency-trace)
    在后者项目中的展示。图 6-2 显示了多跟踪搜索视图，图 6-3 显示了我们的单个 `doOperation` 跟踪的外观。
- en: '![efgo 0602](assets/efgo_0602.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0602](assets/efgo_0602.png)'
- en: Figure 6-2\. View of one hundred operations presented as one hundred traces
    with their latency results
  id: totrans-122
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-2。将一百个操作显示为一百个跟踪，并显示它们的延迟结果
- en: '![efgo 0603](assets/efgo_0603.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0603](assets/efgo_0603.png)'
- en: Figure 6-3\. Click one trace to inspect all of its spans and associated data
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-3。单击一个跟踪以查看其所有 span 和关联数据
- en: Tools and user interfaces can vary, but generally they follow the same semantics
    I explain in this section. The view in [Figure 6-2](#img-obs-tracing) allows us
    to search through traces based on their timestamp, durations, service involved,
    etc. The current search matches our one hundred operations, which are then listed
    on the screen. A convenient, interactive graph of its latencies is placed, so
    we can navigate to the operation we want. Once clicked, the view in [Figure 6-3](#img-obs-spans)
    is presented. In this view, we can see a distribution of spans for this operation.
    If the operation spans multiple processes and we used network context propagation,
    all linked spans will be listed here. For example, from [Figure 6-3](#img-obs-spans)
    we can immediately tell that the first operation was responsible for most of the
    latency, and the last operation introduced the error.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 工具和用户界面可能各不相同，但通常它们遵循我在本节中解释的相同语义。在[图 6-2](#img-obs-tracing)中的视图允许我们根据时间戳、持续时间、涉及的服务等搜索跟踪数据。当前的搜索匹配我们的一百个操作，然后在屏幕上列出。它还放置了一个方便的交互式图表，显示其延迟时间，因此我们可以导航到我们想要的操作。一旦点击，[图 6-3](#img-obs-spans)中的视图就会呈现出来。在这个视图中，我们可以看到这个操作的多个跨度分布。如果操作涉及多个进程，并且我们使用了网络上下文传播，所有关联的跨度将在此列出。例如，从[图 6-3](#img-obs-spans)中，我们可以立即看出第一个操作占用了大部分的延迟时间，并且最后一个操作引入了错误。
- en: 'All the benefits of tracing make it an excellent tool for learning the system
    interactions, debugging, or finding fundamental efficiency bottlenecks. It can
    also be used for ad hoc verification of system latency measurements (e.g., in
    our TFBO flow to assess latency). But unfortunately, there are a few downsides
    of tracing that you have to be aware of when planning to use it in practice for
    efficiency or other needs:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 所有跟踪的好处使其成为学习系统交互、调试或找出基本效率瓶颈的优秀工具。它还可以用于系统延迟测量的临时验证（例如在我们的 TFBO 流程中评估延迟）。但不幸的是，在实践中，要用于效率或其他需求时，跟踪也有一些需要注意的缺点：
- en: Readability and maintainability
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 可读性和可维护性
- en: The advantage of tracing is that you can put a huge amount of useful context
    into your code. In extreme cases, you could potentially be able to rewrite the
    whole program or even system just by looking at all traces and their emitted spans.
    But there is a catch. All this manual instrumentation requires code lines. More
    code lines connected to our existing code increases the complexity of our code,
    which in turn decreases readability. We also need to ensure that our instrumentation
    stays updated with ever-changing code.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪的优势在于你可以将大量有用的上下文信息整合到你的代码中。在极端情况下，你甚至可以通过查看所有的跟踪和它们发出的跨度来重写整个程序或甚至整个系统。但是，这种手动仪器化有一个问题。所有这些额外的代码行会增加我们现有代码的复杂性，进而降低可读性。我们还需要确保我们的仪器化能够跟随不断变化的代码而更新。
- en: In practice, the tracing industry tends to prefer autoinstrumentation, which
    in theory can add, maintain, and hide such instrumentation automatically. Proxies
    like Envoy (especially with service mesh technologies) are great examples of successful
    (yet simpler) autoinstrumentation tools for tracing that record the inter-process
    HTTP calls. But unfortunately, more involved auto-instrumentation is not so easy.
    The main problem is that the automation has to hook on to some generic path like
    common database or library operations, HTTP requests, or syscalls (e.g., through
    eBPF probes in Linux). Moreover, it is often hard for those tools to understand
    what more you would like to capture in your application (e.g., the ID of the client
    in a specific code variable). On top of that, tools like eBPF are pretty unstable
    and dependent on the kernel version.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，跟踪行业倾向于偏好自动仪器化，理论上可以自动添加、维护和隐藏这样的仪器化。像 Envoy（尤其是服务网格技术）这样的代理是成功的自动仪器化跟踪工具的绝佳示例，它们记录了跨进程的
    HTTP 调用。但不幸的是，更复杂的自动仪器化并不那么容易。主要问题在于自动化必须连接到一些通用路径，如常见的数据库或库操作、HTTP 请求或系统调用（例如通过
    Linux 中的 eBPF 探针）。此外，这些工具通常难以理解你希望在应用程序中捕获的更多信息（例如特定代码变量中客户端的 ID）。除此之外，像 eBPF
    这样的工具非常不稳定，并且依赖于内核版本。
- en: Hiding Instrumentation Under Abstractions
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在抽象层下隐藏仪器化
- en: There is a middle ground between manual and fully autonomous instrumentation.
    We can manually instrument only a few common Go functions and libraries, so all
    code that uses them will be traced consistently implicitly (automatically!).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在手动和完全自动化工具之间存在一个折衷方案。我们可以仅手动对一些常见的 Go 函数和库进行仪器化，这样使用它们的所有代码将隐式（自动地！）保持一致的跟踪。
- en: For example, we could add a trace for every HTTP or gRPC request to our process.
    There are already [HTTP middlewares](https://oreil.ly/wZ559) and [gRPC interceptors](https://oreil.ly/7gXVF)
    for that purpose.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以为每个HTTP或gRPC请求向我们的进程添加一个追踪。对于这一目的，已经存在[HTTP 中间件](https://oreil.ly/wZ559)和[gRPC
    拦截器](https://oreil.ly/7gXVF)。
- en: Cost and reliability
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 成本和可靠性
- en: Traces by design fall into the raw event category of observability. This means
    that tracing is typically more expensive than pre-aggregated equivalents. The
    reason is the sheer amount of data we send using tracing. Even if we are very
    moderate with this instrumentation for a single operation, we ideally have dozens
    of tracing spans. These days, systems have to sustain many QPS (queries per second).
    In our example, even for 100 QPS, we would generate over 1,000 spans. Each span
    must be delivered to some backend to be used effectively, with replication on
    both the ingestion and storage sides. Then you need a lot of computation power
    to analyze this data to find, for example, average latency across traces or spans.
    This can easily surpass your price for running the systems without observability!
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 由设计追踪事件落入可观察性的原始事件类别。这意味着追踪通常比预先聚合的等效方式更昂贵。原因是我们使用追踪发送的大量数据。即使我们对单个操作非常适度地进行仪表化，我们理想情况下也应该有数十个追踪跨度。如今，系统必须支持许多查询每秒（QPS）。在我们的示例中，即使是100
    QPS，我们也会生成超过1,000个跨度。每个跨度必须被传送到某个后端以有效使用，并在摄取和存储的两端进行复制。然后，您需要大量的计算能力来分析这些数据，以查找例如跨度或追踪之间的平均延迟。这很容易超过您在没有可观察性的情况下运行系统的价格！
- en: The industry is aware of this, and this is why we have tracing sampling, so
    some decision-making configuration or code decides what data to pass forward and
    what to ignore. For example, you might want to only collect traces for failed
    operations or operations that took more than 120 seconds.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 该行业对此有所了解，这就是为什么我们有追踪采样，因此某些决策配置或代码决定传递哪些数据以及忽略哪些数据。例如，您可能希望仅收集失败的操作或操作所花费超过120秒的追踪数据。
- en: Unfortunately, sampling comes with its downsides. For example, it’s challenging
    to perform tail sampling.^([9](ch06.html#idm45606831687072)) Last but not least,
    sampling makes us miss some data (similar to profiling). In our latency example,
    this might mean that the latency we measure represents only part of all operations
    that happened. Sometimes it might be enough, but it’s easy to [get wrong conclusions
    with sampling](https://oreil.ly/R4gtX), which might lead to wrong optimization
    decisions.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，采样也有其缺点。例如，执行尾部采样是具有挑战性的。^([9](ch06.html#idm45606831687072)) 最后但并非最不重要的是，采样使我们错过了一些数据（类似于分析剖析）。在我们的延迟示例中，这可能意味着我们测量的延迟仅代表发生的所有操作的一部分。有时可能足够，但很容易通过采样得出错误的结论，这可能导致错误的优化决策。
- en: Short duration
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 短暂的持续时间
- en: We will discuss this in detail in [“Latency”](#ch-obs-latency), but tracing
    won’t tell us much when we try to improve very fast functions that last only a
    few milliseconds or less. Similar to the `time` package, the span itself introduces
    some latency. On top of that, adding span for many small operations can add a
    huge cost to the overall ingestion, storage, and querying of traces.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[“延迟”](#ch-obs-latency)中详细讨论这一点，但在尝试优化持续时间仅为几毫秒或更短的非常快速函数时，追踪将不会提供太多信息。与`time`包类似，跨度本身会引入一些延迟。此外，为许多小操作添加跨度可能会大大增加整体摄取、存储和追踪查询的成本。
- en: This is especially visible in streamed algorithms like chunked encodings, compressions,
    or iterators. If we perform partial operations, we are still often interested
    in the latency of the sum of all iterations for certain logic. We can’t use tracing
    for that, as we would need to create tiny spans for every iteration. For those
    algorithms, [“Profiling in Go”](ch09.html#ch-obs-profiling) yields the best observability.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这在流式算法中尤为明显，例如分块编码、压缩或迭代器。如果我们执行部分操作，通常我们仍然对某些逻辑所有迭代的延迟感兴趣。我们无法使用追踪来做到这一点，因为我们需要为每次迭代创建微小的跨度。对于这些算法，《Go
    语言中的分析剖析》（“Profiling in Go”）提供了最佳的可观察性。
- en: Despite some downsides, tracing becomes very powerful and even replaces the
    logging signal in many cases. Vendors and projects add more features, for example,
    [Tempo project’s metric generator](https://oreil.ly/SSLye) that allows recording
    metrics from traces (e.g., average or tail latency for our efficiency needs).
    Undoubtedly, tracing would not grow so quickly without the push from the [OpenTelemetry](https://oreil.ly/sPiw9)
    community. Amazing things will come from this community if you are into tracing.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在一些缺点，跟踪在许多情况下变得非常强大，甚至取代日志记录信号。供应商和项目增加了更多功能，例如，[Tempo项目的指标生成器](https://oreil.ly/SSLye)，允许从跟踪记录指标（例如，适合我们效率需求的平均或尾部延迟）。毫无疑问，如果您对跟踪感兴趣，[OpenTelemetry](https://oreil.ly/sPiw9)社区将带来令人惊奇的成果。
- en: The downsides of one framework are often strengths of other frameworks that
    choose different trade-offs. For example, many tracing problems come from the
    fact that it naturally represents raw events happening in the system (that might
    trigger other events). Let’s now discuss a signal on the opposite spectrum—designed
    to capture aggregations changing over time.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 一个框架的缺点往往是选择不同折衷方案的其他框架的优势。例如，许多跟踪问题源于其自然地表示系统中发生的原始事件（可能触发其他事件）。现在让我们讨论一种处于相反方向的信号——设计用于捕获随时间变化的聚合。
- en: Metrics
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标
- en: Metrics is the observability signal that was designed to observe aggregated
    information. Such aggregation-oriented metric instrumentations might be the most
    pragmatic way of solving our efficiency goals. Metrics are also what I used the
    most in my day-to-day job as a developer and SRE to observe and debug production
    workloads. In addition, metrics are [the main signal used for monitoring at Google](https://oreil.ly/x6rNZ).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 指标是旨在观察聚合信息的可观察信号。这种面向聚合的指标工具可能是解决我们效率目标的最实用方式。作为开发人员和SRE，在我的日常工作中，观察和调试生产工作负载时，指标是我使用最多的工具。此外，指标是[谷歌用于监控的主要信号](https://oreil.ly/x6rNZ)。
- en: '[Example 6-7](#code-latency-metric) shows pre-aggregated instrumentation that
    can be used to measure latency. This example uses [Prometheus `client_golang`](https://oreil.ly/1r2zw).^([10](ch06.html#idm45606831665920))'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 6-7](#code-latency-metric)显示了可用于测量延迟的预聚合仪器。此示例使用[Prometheus `client_golang`](https://oreil.ly/1r2zw)。^([10](ch06.html#idm45606831665920))'
- en: Example 6-7\. Measuring `doOperation` latency using the histogram metric with
    Prometheus `client_golang`
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-7。使用Prometheus `client_golang`和直方图指标测量`doOperation`的延迟
- en: '[PRE6]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO7-1)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO7-1)'
- en: Using the Prometheus library always starts with creating a new metric registry.^([11](ch06.html#idm45606831400064))
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Prometheus库始终从创建新的指标注册表开始。^([11](ch06.html#idm45606831400064))
- en: '[![2](assets/2.png)](#co_efficiency_observability_CO7-2)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_efficiency_observability_CO7-2)'
- en: The next step is to populate the registry with the metric definitions you want.
    Prometheus allows a few types of metrics, yet the typical latency measurements
    for efficiency are best done as histograms. So on top of type, help and histogram
    buckets are required. We will talk more about buckets and the choice of histograms
    later.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用您想要的指标定义填充注册表。Prometheus允许几种类型的指标，但是用于效率最佳的典型延迟测量最好是直方图。因此，除了类型之外，还需要帮助和直方图桶。稍后我们将更多地讨论桶和直方图的选择。
- en: '[![3](assets/3.png)](#co_efficiency_observability_CO7-3)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_efficiency_observability_CO7-3)'
- en: As the last parameter, we define the dynamic dimension of this metric. Here
    I propose to measure latency for different types of errors (or no error). This
    is useful as, very often, failures have other timing characteristics.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一个参数，我们定义此指标的动态维度。在这里，我建议测量不同类型的错误（或无错误）的延迟。这非常有用，因为很多时候，故障具有其他时间特性。
- en: '[![4](assets/4.png)](#co_efficiency_observability_CO7-4)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_efficiency_observability_CO7-4)'
- en: We observe the exact latency with a floating number of seconds. We run all operations
    in a simplified goroutine, so we can expose metrics while the functionality is
    performing. The `Observe` method will add such latency into the histogram of buckets.
    Notice that we observe this latency for certain errors. We also don’t take an
    arbitrary error string—we sanitize it to a type using some custom `errorType`
    function. This is important because the controlled number of values in the dimension
    keeps our metric valuable and cheap.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用浮点数秒精确观察延迟。我们在简化的goroutine中运行所有操作，因此我们可以在功能执行时公开度量。`Observe`方法将此类延迟添加到直方图的桶中。请注意，我们观察特定错误的这种延迟。我们也不会随意使用错误字符串——我们会使用自定义的`errorType`函数将其转换为类型。这很重要，因为在维度中控制数值的数量使得我们的度量有价值且廉价。
- en: '[![5](assets/5.png)](#co_efficiency_observability_CO7-5)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_efficiency_observability_CO7-5)'
- en: The default way to consume those metrics is by allowing other processes (e.g.,
    [Prometheus server](https://oreil.ly/2Sa3P)) to pull the current state of the
    metrics. For example, in this simplified^([12](ch06.html#idm45606831336912)) code
    we serve those metrics from our registry through an HTTP endpoint on the `8080`
    port.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 消费这些度量的默认方式是允许其他进程（例如，[Prometheus服务器](https://oreil.ly/2Sa3P)）从我们的注册表中拉取当前度量的状态。例如，在这个简化的^([12](ch06.html#idm45606831336912))代码中，我们通过`8080`端口的HTTP端点提供这些度量。
- en: 'The Prometheus data model supports four metric types, which are well described
    in the [Prometheus documentation](https://oreil.ly/mamdO): counters, gauges, histograms,
    and summaries. There is a reason why I chose a more complex histogram for observing
    latency instead of a counter or a gauge metric. I explain why in [“Latency”](#ch-obs-latency).
    For now, it’s enough to say that histograms allow us to capture distributions
    of the latencies, which is typically what we need when observing production systems
    for efficiency and reliability. Such metrics, defined and instrumented in [Example 6-7](#code-latency-metric),
    will be represented on an HTTP endpoint, as shown in [Example 6-8](#code-latency-metric-om).'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus数据模型支持四种度量类型，在[Prometheus文档](https://oreil.ly/mamdO)中有详细描述：计数器、仪表、直方图和摘要。我选择使用更复杂的直方图来观察延迟，而不是计数器或仪表度量有其原因，我在[“延迟”](#ch-obs-latency)中解释了原因。暂时来说，直方图允许我们捕获延迟的分布，这通常是在观察生产系统的效率和可靠性时所需的。这些度量，定义并在[示例 6-7](#code-latency-metric)中进行仪表化，将显示在HTTP端点上，如[示例 6-8](#code-latency-metric-om)所示。
- en: Example 6-8\. Sample of the metric output from [Example 6-7](#code-latency-metric)
    when consumed from the [OpenMetrics compatible HTTP endpoint](https://oreil.ly/aZ6GT)
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-8\. 从[示例 6-7](#code-latency-metric)消费时度量输出的样本，通过[OpenMetrics兼容的HTTP端点](https://oreil.ly/aZ6GT)。
- en: '[PRE7]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO8-1)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO8-1)'
- en: Each bucket represents a number (counters) of operations that had latency less
    than or equal to the value specified in `le`. For example, we can immediately
    see that we saw two successful operations from the process start. The first was
    faster than 0.1 seconds; and the second was faster than 1 second, but slower than
    0.1 seconds.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 每个桶代表了延迟小于或等于`le`指定值的操作数（计数器）。例如，我们可以立即看到我们从进程启动中看到了两次成功操作。第一次比0.1秒快，第二次比1秒慢但比0.1秒快。
- en: '[![2](assets/2.png)](#co_efficiency_observability_CO8-2)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_efficiency_observability_CO8-2)'
- en: Every histogram also captures a number of observed operations and summarized
    value (sum of observed latencies, in this case).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 每个直方图还捕获了一定数量的观察操作和总结值（在这种情况下是观察延迟的总和）。
- en: As mentioned in [“Observability”](#ch-obs-observability), every signal can be
    pulled or pushed. However, the Prometheus ecosystem defaults to the pull method
    for metrics. Not the naive pull, though. In the Prometheus ecosystem, we don’t
    pull a backlog of events or samples like we would when pulling (tailing) traces
    of logs from, for example, a file. Instead, applications serve HTTP payload in
    the OpenMetrics format (like in [Example 6-8](#code-latency-metric-om)), which
    is then periodically collected (scraped) by Prometheus servers or Prometheus compatible
    systems (e.g., Grafana Agent or OpenTelemetry collector). With the Prometheus
    data model, we scrape the latest information about the process.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [“可观测性”](#ch-obs-observability) 所述，每个信号都可以被拉取或推送。然而，Prometheus 生态系统默认使用拉取方法来获取指标。虽然不是简单的拉取。在
    Prometheus 生态系统中，我们不像从文件中拉取（尾随）日志跟踪的样本或事件堆积那样。相反，应用程序以 OpenMetrics 格式提供 HTTP 负载（例如
    [示例 6-8](#code-latency-metric-om)），然后由 Prometheus 服务器或兼容 Prometheus 的系统（例如 Grafana
    代理或 OpenTelemetry 收集器）定期获取（抓取）。使用 Prometheus 数据模型，我们抓取关于进程的最新信息。
- en: To use Prometheus with our Go program instrumented in [Example 6-7](#code-latency-metric),
    we have to start the Prometheus server and configure the scrape job that targets
    the Go process server. For example, assuming we have the code in [Example 6-7](#code-latency-metric)
    running, we could use the set of commands shown in [Example 6-9](#code-latency-metric-scrape)
    to start metric collection.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Prometheus 和我们在 [示例 6-7](#code-latency-metric) 中仪表化的 Go 程序，我们必须启动 Prometheus
    服务器，并配置目标为 Go 进程服务器的抓取作业。例如，假设我们的代码在 [示例 6-7](#code-latency-metric) 中运行，我们可以使用
    [示例 6-9](#code-latency-metric-scrape) 中显示的一组命令来开始收集指标。
- en: Example 6-9\. The simplest set of commands to run Prometheus from the terminal
    to start collecting metrics from [Example 6-7](#code-latency-metric)
  id: totrans-166
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-9\. 从终端运行 Prometheus 的最简单命令集，开始从 [示例 6-7](#code-latency-metric) 收集指标
- en: '[PRE8]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO9-1)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO9-1)'
- en: For my demo purposes, I can limit the [Prometheus configuration](https://oreil.ly/4cPSa)
    to a single scrape job. One of the first decisions is to specify the scrape interval.
    Typically, it’s around 15–30 seconds for continuous, efficient metric collection.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示目的，我可以将[Prometheus配置](https://oreil.ly/4cPSa)限制为单个抓取作业。首先要决定的是指定抓取间隔。通常，持续、高效的指标收集间隔约为
    15 到 30 秒。
- en: '[![2](assets/2.png)](#co_efficiency_observability_CO9-2)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_efficiency_observability_CO9-2)'
- en: I also provide a target that points to our tiny instrumented Go program in [Example 6-7](#code-latency-metric).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供一个指向我们精简的 Go 程序示例 [示例 6-7](#code-latency-metric) 的目标。
- en: '[![3](assets/3.png)](#co_efficiency_observability_CO9-3)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_efficiency_observability_CO9-3)'
- en: Prometheus is just a single binary written in Go. We install it in [many ways](https://oreil.ly/9CxxD).
    In the simplest configuration, we can point it to a created configuration. When
    started, the UI will be available on the `localhost:9090`.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 只是一个用 Go 编写的单一二进制文件。我们可以通过[多种方式](https://oreil.ly/9CxxD)安装它。在最简单的配置中，我们可以指定一个创建好的配置。启动后，UI
    将在 `localhost:9090` 上可用。
- en: With the preceding setup, we can start analyzing the data using Prometheus APIs.
    The simplest way is to use the Prometheus query language (PromQL) documented [here](https://oreil.ly/nY6Yi)
    and [here](https://oreil.ly/jH3nd). With Prometheus server started as in [Example 6-9](#code-latency-metric-scrape),
    we can use the Prometheus UI and query the data we collected.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述设置完成后，我们可以使用 Prometheus API 开始分析数据。最简单的方法是使用 Prometheus 查询语言（PromQL），其文档在[这里](https://oreil.ly/nY6Yi)和[这里](https://oreil.ly/jH3nd)有详细描述。通过如
    [示例 6-9](#code-latency-metric-scrape) 中所示的启动 Prometheus 服务器后，我们可以使用 Prometheus
    UI 查询和展示收集的数据。
- en: For example, [Figure 6-4](#img-obs-metric-buckets) shows the result of the simple
    query fetching the latest latency histogram numbers over time (from the moment
    of the process start) for our `operation_duration_seconds` metric name that represents
    successful operations. This generally matches the format we see in [Example 6-8](#code-latency-metric-om).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[图 6-4](#img-obs-metric-buckets) 显示了简单查询的结果，该查询在时间轴上（从进程启动时刻起）获取了最新的延迟直方图数据（对应我们的
    `operation_duration_seconds` 指标，表示成功操作）。这通常与我们在 [示例 6-8](#code-latency-metric-om)
    中看到的格式相匹配。
- en: '![efgo 0604](assets/efgo_0604.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0604](assets/efgo_0604.png)'
- en: Figure 6-4\. PromQL query results for simple query for all `operation_duration_​sec⁠onds_bucket`
    metrics graphed in the Prometheus UI
  id: totrans-177
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-4\. PromQL 查询结果，显示了 Prometheus UI 中所有 `operation_duration_​sec⁠onds_bucket`
    指标的简单查询图表化结果
- en: To obtain the average latency of a single operation, we can use certain mathematical
    operations to divide the rates of `operation_duration_seconds_sum` by `oper⁠ation_duration_seconds_count`.
    We use the `rate` function to ensure accurate results across many processes and
    their restart. `rate` transforms Prometheus counters into a rate per second.^([13](ch06.html#idm45606831225328))
    Then we can use `/` to divide the rates of those metrics. The result of such an
    average query is presented in [Figure 6-5](#img-obs-metric-avg).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取单个操作的平均延迟，我们可以使用某些数学操作，通过 `operation_duration_seconds_sum` 除以 `oper⁠ation_duration_seconds_count`
    的速率。我们使用 `rate` 函数确保在许多进程和它们的重启中准确的结果。`rate` 将 Prometheus 计数器转换为每秒速率。^([13](ch06.html#idm45606831225328))
    然后我们可以使用 `/` 来除以这些度量的速率。这种平均查询的结果显示在 [图 6-5](#img-obs-metric-avg) 中。
- en: '![efgo 0605](assets/efgo_0605.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0605](assets/efgo_0605.png)'
- en: Figure 6-5\. PromQL query results representing average latency captured by the
    [Example 6-7](#code-latency-metric) instrumentation graphed in the Prometheus
    UI
  id: totrans-180
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-5\. PromQL 查询结果，代表由[示例 6-7](#code-latency-metric)仪表化的平均延迟，在 Prometheus UI
    中绘制
- en: With another query, we can check total operations or, even better, check the
    rate per minute of those using the `increase` function on our `operation_duration_​sec⁠onds_count`
    counter, as presented in [Figure 6-6](#img-obs-metric-incr).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 使用另一个查询，我们可以检查总操作数，甚至更好地检查使用 `increase` 函数在我们的 `operation_duration_​sec⁠onds_count`
    计数器上的每分钟速率，如 [图 6-6](#img-obs-metric-incr) 所示。
- en: '![efgo 0606](assets/efgo_0606.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0606](assets/efgo_0606.png)'
- en: Figure 6-6\. PromQL query results representing a rate of operations per minute
    in our system graphed in the Prometheus UI
  id: totrans-183
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-6\. PromQL 查询结果，代表系统中操作每分钟的速率，在 Prometheus UI 中绘制
- en: There are many other functions, aggregations, and ways of using metric data
    in the Prometheus ecosystem. We will unpack some of it in later sections.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Prometheus 生态系统中，还有许多其他功能、聚合方式和使用度量数据的方法。我们将在后续章节中详细介绍其中一些。
- en: 'The amazing part about Prometheus with such a specific scrape technique is
    that pulling metrics allows our Go client to be ultrathin and efficient. As a
    result, the Go process does not need to:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 与这种特定的抓取技术的惊人之处在于，拉取度量允许我们的 Go 客户端非常轻量和高效。因此，Go 进程不需要执行以下操作：
- en: Buffer data samples, spans, or logs in memory or on disk
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在内存或磁盘上缓冲数据样本、跨度或日志
- en: Maintain information (and automatically update it!) on where to send potential
    data
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护信息（并自动更新！）关于发送潜在数据的位置
- en: Implement complex buffering and persisting logic if the metric backend is down
    temporarily
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果度量后端暂时宕机，实现复杂的缓冲和持久逻辑
- en: Ensure a consistent sample push interval
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保一致的样本推送间隔
- en: Know about any authentication, authorization, or TLS for metric payload
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于度量负载的认证、授权或 TLS 的任何了解
- en: 'On top of that, the observability experience is better when you pull the data
    in such a way that:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当以这样的方式拉取数据时，可观察性体验更好：
- en: Metric users can easily control the scrape interval, targets, metadata, and
    recordings from a central place. This makes the metric usage simpler, more pragmatic,
    and generally cheaper.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 度量用户可以轻松控制从中心位置的抓取间隔、目标、元数据和记录。这使得度量使用更简单、更实用，通常也更经济。
- en: It is easier to predict the load of such a system, which makes it easier to
    scale it and react to the situations that require scaling the collection pipeline.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更容易预测这种系统的负载，这使得在需要扩展收集管道的情况下更容易做出反应。
- en: Last but not least, pulling metrics allows you to reliably tell your application’s
    health (if we can’t scrape metrics from it, it is most likely unhealthy or down).
    We also typically know what sample is the last one for a metric (staleness).^([14](ch06.html#idm45606831205328))
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后但并非最不重要的，拉取度量允许您可靠地了解应用程序的健康状况（如果我们无法从中抓取度量，那么它很可能是不健康的或宕机）。我们通常也知道度量的最后一个样本是哪个（陈旧度）。^([14](ch06.html#idm45606831205328))
- en: 'As with everything, there are some trade-offs. Each pulled, tailed, or scraped
    signal has its downsides. Typical problems of an observability pull-based system
    include:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 就像一切事物一样，都存在一些权衡。每个拉取、尾随或抓取信号都有其缺点。观察力拉取式系统的典型问题包括：
- en: It is generally harder to pull data from short-lived processes (e.g., CLI and
    batch jobs).^([15](ch06.html#idm45606831202864))
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从短暂的进程（例如 CLI 和批处理作业）中拉取数据通常更具挑战性。^([15](ch06.html#idm45606831202864))
- en: Not every system architecture allows ingress traffic.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非每个系统架构都允许入口流量。
- en: It is generally harder to ensure that all the pieces of information will land
    safely in a remote place (e.g., this pulling is not suitable for auditing).
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常更难确保所有信息安全地落入远程位置（例如这种拉取方式不适合审计）。
- en: The Prometheus metrics are designed to mitigate downsides and leverage the strength
    of the pull model. Most of the metrics we use are counters, which means they only
    increase. This allows Prometheus to skip a few scrapes from the process but still,
    in the end, have a perfectly accurate number for each metric within larger time
    windows, like minutes.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus指标的设计旨在减少缺点并利用拉取模型的优势。我们使用的大多数指标都是计数器，这意味着它们只会增加。这使得Prometheus可以跳过进程的几次抓取，但最终在较大的时间窗口内（如几分钟内）仍能准确统计每个指标的数字。
- en: As mentioned before, in the end, metrics (as numeric values) are what we need
    when it comes to assessing efficiency. It’s all about comparing and analyzing
    numbers. This is why a metric observability signal is a great way to gather required
    information pragmatically. We will use this signal extensively for [“Macrobenchmarks”](ch08.html#ch-obs-macro)
    and [“Root Cause Analysis, but for Efficiency”](ch09.html#ch-obs-cause). It’s
    simple, pragmatic, the ecosystem is huge (you can find metric exporters for almost
    all kinds of software and hardware), it’s generally cheap, and it works great
    with both human users and automation (e.g., alerting).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前提到的，最终，指标（作为数值）是我们在评估效率时所需的内容。一切都是关于比较和分析数字。这就是为什么指标的可观察性信号是收集所需信息的一种极好的方式。我们将在[“宏基准测试”](ch08.html#ch-obs-macro)和[“效率根本原因分析”](ch09.html#ch-obs-cause)中广泛使用这一信号。它简单、实用，生态系统庞大（几乎可以找到所有类型软件和硬件的指标导出器），成本通常较低，且在人类用户和自动化（例如警报）中都运作良好。
- en: Metric observability signals, especially with the Prometheus data model, fit
    into aggregated information instrumentation. We discussed the benefits, but some
    limits and downsides are important to understand. All downsides come from the
    fact that we generally cannot narrow pre-aggregated data down to a state before
    aggregation, for example, a single event. We might know with metrics how many
    requests failed, but we don’t know the exact stack trace, error message, and so
    on for a singular error that happened. The most granular information we typically
    have is a type of error (e.g., status code). This makes the surface of possible
    questions we can ask a metric system smaller than if we would capture all raw
    events. Another essential characteristic that might be considered a downside is
    the cardinality of the metrics and the fact that it has to be kept low.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 指标的可观察性信号，特别是在Prometheus数据模型中，适用于聚合信息的仪表化。我们讨论了其优势，但有些限制和缺点也很重要。所有的缺点都源于一个事实，即我们通常不能将预聚合数据缩小到聚合之前的状态，例如单个事件。对于指标，我们可能知道有多少请求失败，但对于发生的单个错误的确切堆栈跟踪、错误消息等我们是不清楚的。我们通常拥有的最精细的信息是错误类型（例如状态码）。这使得我们能向指标系统提出的问题的范围较小，比起捕获所有原始事件而言。另一个可能被认为是缺点的重要特征是指标的基数必须保持较低。
- en: High Metric Cardinality
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高指标基数
- en: Cardinality means the uniqueness of our metric. For example, imagine in [Example 6-7](#code-latency-metric)
    we would inject a unique error string instead of the `error_type` label. Every
    new label value creates a new, possibly short-lived unique metric. A metric with
    just a single or a few samples represents more of a raw event, not aggregation
    over time. Unfortunately, if users try to push event-like information to a system
    designed for metrics (like Prometheus), it tends to be expensive and slow.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 基数表示我们指标的唯一性。例如，想象一下在[示例 6-7](#code-latency-metric)中，我们将一个唯一的错误字符串注入，而不是使用`error_type`标签。每个新的标签值都会创建一个可能是短暂的唯一指标。只有一个或少数样本的指标更多代表一个原始事件，而非随时间的聚合。不幸的是，如果用户试图将类似事件的信息推送到设计用于指标的系统（如Prometheus），这往往是昂贵且缓慢的。
- en: It is very tempting to push more cardinal data to a system designed for metrics.
    This is because it’s only natural to want to learn more from such cheap and reliable
    signal-like metrics. Avoid that and keep your cardinality low with metric budgets,
    recording rules, and allow-list relabeling. Switch to event-based systems like
    logging and tracing if you wish to capture unique information like exact error
    messages or the latency for a single, specific operation in the system!
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 将更多基础数据推送到为指标设计的系统是非常诱人的。这是因为想要从这些类似信号般便宜和可靠的指标中学到更多是很自然的。避免这样做，通过指标预算、记录规则和允许列表重标记来保持低基数。如果希望捕获诸如确切错误消息或系统中单个特定操作的延迟等唯一信息，请切换到基于事件的系统，如日志和追踪！
- en: Whether gathered from logs, traces, profiles, or metric signals, we already
    touched on some metrics in previous chapters—for example, CPU core used per second,
    memory bytes allocated on the heap, or residential memory bytes used per operation.
    So let’s go through some of those in detail and talk about their semantics, how
    we should interpret them, potential granularity, and example code that illustrates
    them using signals you have just learned.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是从日志、追踪、性能分析还是度量信号中收集的信息，我们在前几章已经涉及了一些指标，例如每秒使用的CPU核心、堆上分配的内存字节或每个操作使用的居住内存字节。因此，让我们详细讨论其中一些，谈论它们的语义、我们应该如何解释它们、潜在的细粒度以及使用刚学到的信号来举例说明的示例代码。
- en: There Is No Observability Silver Bullet!
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 没有可观测的银弹！
- en: Metrics are powerful. Yet as you learned in this chapter, logging and traces
    also give enormous opportunities to improve the efficiency observability experience
    with dedicated tools that allow us to derive metrics from them. In this book,
    you will see me using all of those tools (together with profiling, which we haven’t
    covered yet) to improve the efficiency of Go programs.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 指标非常强大。然而，正如您在本章中所学到的，日志和追踪也为我们提供了巨大的机会，通过专门的工具提高效率观测体验，使我们能够从中衍生指标。在本书中，您将看到我使用所有这些工具（以及我们尚未涵盖的性能分析）来提高Go程序的效率。
- en: The pragmatic system captures enough of each of those observability signals
    that fit your use cases. It’s unlikely to build metric-only, trace-only, or profiling-only
    systems!
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 实用系统会捕获适合您用例的每个可观测性信号的足够信息。不太可能构建仅基于指标、仅基于追踪或仅基于性能分析的系统！
- en: Efficiency Metrics Semantics
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 效率指标的语义
- en: Observability feels like a vast and deep topic that takes years to grasp and
    set up. The industry constantly evolves, and creating new solutions does not help.
    However, it will be easier to understand once we start using observability for
    a specific goal like the efficiency effort. Let’s talk about exactly which observability
    bits are essential to start measuring latency and consumption of the resources
    we care about, e.g., CPU and memory.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 可观测性感觉像是一个广阔而深远的主题，需要多年才能掌握和设置。行业不断发展，创建新解决方案并不总是有帮助的。然而，一旦我们开始为像效率工作这样的具体目标使用可观测性，理解将会更加容易。让我们具体讨论一下哪些可观测性要素对于开始测量我们关心的资源消耗和延迟（例如CPU和内存）至关重要。
- en: Metrics As Numeric Value Versus Metric Observability Signal
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指标作为数字值与指标可观测性信号
- en: In [“Metrics”](#ch-obs-metrics), we discussed the metric observability signal.
    Here we discuss specific metric semantics that are useful to capture for efficiency
    efforts. To clarify, we can capture those specific metrics in various ways. We
    can use metric observability signals, but we can also derive them from other signals,
    like logs, traces, and profiling!
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“指标”](https://wiki.example.org/ch-obs-metrics)中，我们讨论了指标的可观测性信号。在这里，我们讨论了对效率工作有用的特定指标语义。澄清一下，我们可以以各种方式捕获这些具体指标。我们可以使用指标的可观测性信号，但我们也可以从其他信号（如日志、追踪和性能分析）中衍生它们！
- en: 'Two things can define every metric:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 每个指标都可以由两个因素定义：
- en: Semantics
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 语义
- en: What’s the meaning of that number? What do we measure? With what unit? How do
    we call it?
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 那个数字的含义是什么？我们如何测量？使用什么单位？我们称之为什么？
- en: Granularity
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 细粒度
- en: How detailed is this information? For example, is it per a unique operation?
    Is it per a result type of this operation (success versus error)? Per goroutine?
    Per process?
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息有多详细？例如，它是每个唯一操作的吗？它是这个操作的结果类型（成功与错误）吗？每个goroutine吗？每个进程吗？
- en: Metric semantics and granularity both heavily depend on the instrumentation.
    This section will focus on defining the semantics, granularity, and example instrumentation
    for the typical metrics we can use to track resource consumption and latency of
    our software. It is essential to understand the specific measurements we will
    operate with to work effectively with the benchmark and profiling tools we will
    learn in [“Benchmarking Levels”](ch07.html#ch-obs-benchmarking) and [“Profiling
    in Go”](ch09.html#ch-obs-profiling). While iterating over those semantics, we
    will uncover common best practices and pitfalls we have to be aware of. Let’s
    go!
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 测量语义和粒度都严重依赖于仪器设备。本节将重点定义典型度量衡的语义、粒度以及示例仪器，用于追踪我们软件资源消耗和延迟。理解我们将要操作的具体测量是至关重要的，以有效地使用我们将在[“基准测试级别”](ch07.html#ch-obs-benchmarking)和[“Go中的性能分析”](ch09.html#ch-obs-profiling)学习的基准和分析工具。在迭代这些语义时，我们将揭示需要注意的常见最佳实践和陷阱。出发吧！
- en: Latency
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 延迟
- en: If we want to improve how fast our program performs certain operations, we need
    to measure the latency. Latency means the duration of the operation from the start
    to either success or failure. Thus, the semantics we need feel pretty simple at
    first glance—we generally want the “amount of time” required to complete our software
    operation. Our metric will usually have a name containing the words *latency*,
    *duration*, or *elapsed* with the desired unit. But the devil is in the details,
    and as you will learn in this section, measuring latency is prone to mistakes.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想提高程序执行特定操作的速度，我们需要测量延迟。延迟意味着操作从开始到成功或失败所需的持续时间。因此，我们在第一眼看起来需要的语义似乎非常简单——我们通常希望“完成软件操作所需的时间量”。我们的度量通常会以*延迟*、*持续时间*或*经过的时间*为名，并使用所需的单位。但魔鬼藏在细节中，正如您将在本节中了解的那样，测量延迟容易出错。
- en: The preferable unit of the typical latency measurement depends on what kind
    of operations we measure. If we measure very short operations like compression
    latency or OS context switch latencies, we must focus on granular nanoseconds.
    Nanoseconds are also the most granular timing we can count on in typical modern
    computers. This is why the Go standard library [`time.Time`](https://oreil.ly/QGCme)
    and [`time.Duration`](https://oreil.ly/9agLb) structures measure time in nanoseconds.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 典型延迟测量的首选单位取决于我们所测量的操作类型。如果我们测量非常短的操作，比如压缩延迟或操作系统上下文切换延迟，我们必须关注细粒度的纳秒。在典型现代计算机中，纳秒也是我们可以依赖的最细粒度计时单位。这就是为什么Go标准库[`time.Time`](https://oreil.ly/QGCme)和[`time.Duration`](https://oreil.ly/9agLb)结构以纳秒计量时间的原因。
- en: 'Generally speaking, the typical measurements of software operations are almost
    always in milliseconds, seconds, minutes, or hours. This is why it’s often enough
    to measure latency in seconds, as a floating value, for up to nanoseconds granularity.
    Using seconds has another advantage: it is a base unit. Using the base unit is
    often what’s natural and consistent across many solutions.^([16](ch06.html#idm45606831155568))
    Consistency is critical here. You don’t want to measure one part of the system
    in nanoseconds, another in seconds, and another in hours if you can avoid it.
    It’s easy enough to get confused by our data and have a wrong conclusion without
    trying to guess a correct unit or writing transformations between those.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，软件操作的典型测量几乎总是以毫秒、秒、分钟或小时为单位。这就是为什么通常足以以秒为单位测量延迟，作为浮点值，达到纳秒级粒度。使用秒还有另一个优势：它是一个基本单位。使用基本单位通常是自然和一致的，适用于许多解决方案。^([16](ch06.html#idm45606831155568))
    在这里一致性至关重要。如果可以避免，你不希望在系统的一个部分以纳秒为单位测量，另一个部分以秒为单位，再另一个部分以小时为单位。在尝试猜测正确单位或编写单位转换时，很容易因为数据混淆而得出错误的结论。
- en: 'In the code examples in [“Example: Instrumenting for Latency”](#ch-obs-signals),
    we already mentioned many ways we can instrument latency using various observability
    signals. Let’s extend [Example 6-1](#code-latency-simplest) in [Example 6-10](#code-latency-simplest-ext)
    to show important details that ensure latency is measured as reliably as possible.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“示例：测量延迟的仪器化”](#ch-obs-signals)中的代码示例中，我们已经提到了许多使用各种可观测信号仪器化延迟的方法。让我们扩展[示例 6-1](#code-latency-simplest)至[示例 6-10](#code-latency-simplest-ext)，展示确保尽可能可靠地测量延迟的重要细节。
- en: Example 6-10\. Manual and simplest latency measurement of a single operation
    that can error out and has to prepare and tear down phases
  id: totrans-224
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-10\. 单一操作的手动和最简单的延迟测量，可能会出错，并且需要准备和清除阶段
- en: '[PRE9]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO10-1)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO10-1)'
- en: We capture the `start` time as close as possible to the start of our `doOperation`
    invocation. This ensures nothing unexpected will get between `start` and operation
    start that might introduce unrelated latency, which can mislead the conclusion
    we might take from this metric further on. This, by design, should exclude any
    potential preparation or setup we have to do for an operation we measure. Let’s
    measure those explicitly as another operation. This is also why you should avoid
    putting any newline (empty line) between `start` and the invocation of the operation.
    As a result, the next programmer (or yourself, after some time) won’t add anything
    in between, forgetting about the instrumentation you added.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尽可能接近我们的`doOperation`调用的开始时间来捕获`start`时间。这确保在`start`和操作开始之间不会出现意外的延迟，这些延迟可能会误导我们后续对此度量结果的结论。这是有意设计的，应该排除我们必须为测量的操作做的任何潜在准备或设置。让我们明确地将这些作为另一个操作进行测量。这也是为什么你应该避免在`start`和操作调用之间添加任何换行（空行）。结果，下一个程序员（或者经过一段时间的你自己）不会在其中添加任何内容，忘记你添加的仪表化工具。
- en: '[![2](assets/2.png)](#co_efficiency_observability_CO10-2)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_efficiency_observability_CO10-2)'
- en: Similarly, it’s important to capture the `finish` time using the `time.Since`
    helper as soon as we finish, so no unrelated duration is captured. For example,
    similar to excluding `prepare()` time, we want to exclude any potential close
    or `tearDown()` duration. Moreover, if you are an advanced Go programmer, your
    intuition is always to check errors when some functions finish. This is critical,
    but we should do that for instrumentation purposes after we capture the latency.
    Otherwise, we might increase the risk that someone will not notice our instrumentation
    and will add unrelated statements between what we measure and `time.Since`. On
    top of that, in most cases, you want to make sure you measure the latency of both
    successful and failed operations to understand the complete picture of what your
    program is doing.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 同样重要的是，我们要尽快使用`time.Since`辅助函数捕获`finish`时间，以便不会捕获到任何不相关的持续时间。例如，类似于排除`prepare()`时间，我们希望排除任何潜在的`close`或`tearDown()`持续时间。此外，如果你是一个高级的
    Go 程序员，你的直觉总是在某些函数完成时检查错误。这是至关重要的，但我们应该出于仪表化的目的在捕获延迟之后进行。否则，我们可能会增加未注意到我们的仪表化而在我们测量和`time.Since`之间添加不相关语句的风险。此外，在大多数情况下，你希望确保测量成功和失败操作的延迟，以了解程序正在做什么的完整图片。
- en: Shorter Latencies Are Harder to Measure Reliably
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 较短的延迟更难以可靠地测量
- en: The method for measuring operation latency shown in [Example 6-10](#code-latency-simplest-ext)
    won’t work well for operations that finish under, let’s say, 0.1 microseconds
    (100 nanoseconds). This is because the effort of taking the system clock number,
    allocating variables, and further computing `time.Now()` and `time.Since` functions
    can take its time too, which is significant for such short measurements.^([17](ch06.html#idm45606831016880))
    Furthermore, as we will learn in [“Reliability of Experiments”](ch07.html#ch-obs-rel),
    every measurement has some variance. The shorter latency, the more impactful this
    noise can be.^([18](ch06.html#idm45606831013664)) This also applies to tracing
    spans measuring latency.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 测量操作延迟的方法如 [示例 6-10](#code-latency-simplest-ext) 所示，对于在0.1微秒（100纳秒）以下完成的操作效果不佳。这是因为获取系统时钟数字、分配变量以及进一步计算`time.Now()`和`time.Since`函数可能也需要时间，对于这样短的测量来说是相当显著的。^([17](ch06.html#idm45606831016880))
    此外，正如我们将在 [“实验的可靠性”](ch07.html#ch-obs-rel) 中学到的那样，每次测量都存在一定的变化。延迟越短，这种噪音的影响就越大。^([18](ch06.html#idm45606831013664))
    这也适用于跟踪跨度测量延迟。
- en: One solution for measuring very fast functions is used by the Go benchmark as
    presented by [Example 6-3](#code-latency-go-bench), where we estimate average
    latency per operation by doing many of them. More on that in [“Microbenchmarks”](ch08.html#ch-obs-micro).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 测量非常快速函数的一个解决方案是由 Go 基准测试所使用，正如 [示例 6-3](#code-latency-go-bench) 中所展示的，我们通过执行多次操作来估算每次操作的平均延迟。更多详细信息请参见
    [“微基准测试”](ch08.html#ch-obs-micro)。
- en: Time Is Infinite; the Software Structures Measuring that Time Are Not!
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间是无限的；测量时间的软件结构却不是！
- en: 'When measuring latency, we have to be aware of the limitations of time or duration
    measurements in software. Different types can contain different ranges of numeric
    values, and not all of them can contain negative numbers. For example:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在测量延迟时，我们必须意识到软件中时间或持续时间测量的限制。不同类型可以包含不同范围的数字值，并非所有类型都能包含负数。例如：
- en: '`time.Time` can only measure time from January 1, 1885^([19](ch06.html#idm45606831005584))
    up until 2157.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time.Time` 只能测量从1885年1月1日^([19](ch06.html#idm45606831005584))到2157年之间的时间。'
- en: The `time.Duration` type can measure time (in nanoseconds) approximately between
    -290 years before your “starting” point and up to 290 years after your “starting”
    point.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time.Duration` 类型可以测量大约在您的“起点”之前290年到“起点”之后290年之间的时间（以纳秒为单位）。'
- en: If you want to measure things outside of those typical values, you need to extend
    those types or use your own. Last but not least, Go is prone [to the leap second
    problem](https://oreil.ly/MeZ4b) and time skews of the operating systems. On some
    systems, the `time.Duration` (monotonic clock) will also stop if the computer
    goes to sleep (e.g., laptop or virtual machine suspend), which will lead to wrong
    measurements, so keep that in mind.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要测量超出这些典型值以外的事物，您需要扩展这些类型或使用自己的类型。最后但同样重要的是，Go 存在 [闰秒问题](https://oreil.ly/MeZ4b)
    和操作系统时间偏差的问题。在某些系统上，`time.Duration`（单调时钟）也会在计算机休眠（例如笔记本电脑或虚拟机暂停）时停止，这将导致错误的测量结果，因此请注意这一点。
- en: We discussed some typical latency metric semantics. Now let’s move to the granularity
    question. We can decide to measure the latency of operation A or B in our process.
    We can measure a group of operations (e.g., transaction) or a single suboperation
    of it. We can gather this data across many processes or look only at one, depending
    on what we want to achieve.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了一些典型的延迟度量语义。现在让我们转向粒度问题。我们可以决定在我们的流程中测量操作 A 或 B 的延迟。我们可以测量一组操作（例如事务）或其单个子操作。我们可以跨多个流程收集此数据，也可以仅查看一个流程，这取决于我们想要实现的目标。
- en: To make it even more complex, even if we choose a single operation as our granularity
    to measure latency, that single operation has many stages. In a single process
    this can be represented by stack trace, but for multiprocess systems with some
    network communication, we might need to establish additional boundaries.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 要使其更加复杂，即使我们选择单个操作作为我们测量延迟的粒度，该单个操作也具有许多阶段。在单个进程中，这可以由堆栈跟踪表示，但对于具有某些网络通信的多进程系统，我们可能需要建立额外的边界。
- en: Let’s take some programs as an example, as the Caddy HTTP web server explained
    in the previous chapter, with a simple [REST](https://oreil.ly/SHEor) HTTP call
    to retrieve an HTML as our example operation. What latencies should we measure
    if we install such a Go program in a cloud on production to serve our REST HTTP
    call to the client (e.g., someone’s browser)? The example granularities we could
    measure latency for are presented in [Figure 6-7](#img-obs-latency-stages).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一些程序作为例子，正如前一章中解释的 Caddy HTTP Web 服务器，通过一个简单的 [REST](https://oreil.ly/SHEor)
    HTTP 调用来检索 HTML 作为我们的示例操作。如果我们在生产中的云上安装这样一个 Go 程序来为客户端（例如某人的浏览器）提供我们的 REST HTTP
    调用，我们应该测量哪些延迟？我们可以测量延迟的示例粒度如图6-7中所示的 [Figure 6-7](#img-obs-latency-stages)。
- en: '![efgo 0607](assets/efgo_0607.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0607](assets/efgo_0607.png)'
- en: Figure 6-7\. Example latency stages we can measure for in our Go web server
    program communicating with the user’s web browser
  id: totrans-242
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-7\. 我们可以在与用户的 Web 浏览器通信的 Go Web 服务器程序中测量的示例延迟阶段
- en: 'We can outline five example stages:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以概述五个示例阶段：
- en: Absolute (total) client-side latency
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 绝对（总）客户端端延迟
- en: The latency measured exactly from the moment the user hits Enter in the URL
    input in the browser, up until the whole response is retrieved, content is loaded,
    and the browser renders all.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟精确地从用户在浏览器中 URL 输入框中按下回车的时刻开始，直到检索到整个响应，加载内容并且浏览器渲染完毕。
- en: HTTP client-side latency (response time)
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 客户端端延迟（响应时间）
- en: The latency captured from the moment the first bytes of the HTTP request on
    the client side are being written to a new or reused TCP connection, up until
    the client receives all bytes of the response. This excludes everything that happens
    before (e.g., DNS lookup) or after (rendering HTML and JavaScript in the browser)
    on the client side.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 从客户端开始写入 HTTP 请求的第一个字节，直到客户端接收到响应的所有字节。这不包括客户端之前（例如 DNS 查询）或之后（在浏览器中渲染 HTML
    和 JavaScript）发生的任何事情。
- en: HTTP server-side latency
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 服务器端延迟
- en: The latency is measured from the moment the server receives the first bytes
    of the HTTP request from the client, up until the server finishes writing all
    bytes of the HTTP response. This is typically what we are measuring if we use
    [the HTTP middlewares pattern](https://oreil.ly/Js0NO) in Go.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟是从服务器接收到客户端的 HTTP 请求的第一个字节，直到服务器完成写入 HTTP 响应的所有字节。如果我们在 Go 中使用 [HTTP 中间件模式](https://oreil.ly/Js0NO)
    进行测量，通常是我们正在测量的内容。
- en: Server-side latency (service time)
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器端延迟（服务时间）
- en: The latency of server-side computation required to answer the HTTP request,
    measured without HTTP request parsing and response encoding. Latency is from the
    moment of having the HTTP request parsed to the moment when we start encoding
    and sending the HTTP response.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 请求解析和响应编码无关的服务器端计算延迟。延迟是从解析 HTTP 请求开始到开始编码和发送 HTTP 响应的时刻。
- en: Server-side function latency
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器端函数延迟
- en: The latency of a single server-side function computation from the moment of
    invocation, up until the function work is finished and return arguments are in
    the context of the caller function.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 单个服务器端函数计算的延迟，从调用开始到函数工作完成并返回参数在调用者函数上下文中。
- en: These are just some of the many permutations we can use to measure latency in
    our Go programs or systems. Which one should we pick for our optimizations? Which
    matters the most? It turns out that all of them have their use case. The priority
    of what latency metric granularity we should use and when depends solely on our
    goals, the accuracy of measurements as explained in [“Reliability of Experiments”](ch07.html#ch-obs-rel),
    and the element we want to focus on as discussed in [“Benchmarking Levels”](ch07.html#ch-obs-benchmarking).
    To understand the big picture and find the bottleneck, we have to measure a few
    of those different granularities at once. As discussed in [“Root Cause Analysis,
    but for Efficiency”](ch09.html#ch-obs-cause), tools like tracing and profiling
    can help with that.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是我们在 Go 程序或系统中测量延迟时可以使用的许多排列组合之一。我们应该为优化选择哪个？哪个更重要？事实证明，它们每一个都有其用例。我们应该使用哪种延迟度量粒度以及何时取决于我们的目标，如[“实验可靠性”](ch07.html#ch-obs-rel)中所述的测量准确性，以及我们想要专注的元素，如[“基准测试级别”](ch07.html#ch-obs-benchmarking)中所讨论的。为了理解整体情况并找出瓶颈，我们必须同时测量几个不同的粒度。正如[“根本原因分析，但是效率”](ch09.html#ch-obs-cause)中讨论的，像追踪和分析这样的工具可以帮助解决这个问题。
- en: Whatever Metric Granularity You Choose, Understand and Document What You Measure!
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无论您选择哪种度量粒度，请理解并记录您所测量的内容！
- en: We waste a lot of time if we take the wrong conclusions from measurements. It
    is easy to forget or misunderstand what parts of granularity we are measuring.
    For example, you thought you were measuring server-side latency, but slow client
    software is introducing latency you felt you didn’t include in your metric. As
    a result, you might be trying to find a bottleneck on the server side, whereas
    a potential problem might be in a different process.^([20](ch06.html#idm45606830976592))
    Understand, document, and be explicit with your instrumentation to avoid those
    mistakes
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从测量中得出错误的结论，就会浪费大量时间。很容易忘记或误解我们正在测量的粒度的哪些部分。例如，您可能认为自己在测量服务器端延迟，但是慢速客户端软件引入了您没有包括在度量中的延迟。因此，您可能试图找出服务器端的瓶颈，而潜在的问题可能在另一个进程中。^([20](ch06.html#idm45606830976592))
    为了避免这些错误，请理解、记录并明确您的仪器。
- en: 'In [“Example: Instrumenting for Latency”](#ch-obs-signals), we discussed how
    we could gather latencies. We mentioned that generally, we use two main measuring
    methods for efficiency needs in the Go ecosystem. Those two ways are typically
    the most reliable and cheapest (useful when performing load tests and benchmarks):'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“示例：为延迟进行仪器化”](#ch-obs-signals)中，我们讨论了如何收集延迟。我们提到了通常在 Go 生态系统中用于效率需要的两种主要测量方法。这两种方式通常是最可靠且最便宜的（在执行负载测试和基准测试时非常有用）。
- en: Basic logging using [“Microbenchmarks”](ch08.html#ch-obs-micro) for isolated
    functionality, single process measurements
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于单独功能和单一进程测量，使用基本的日志记录[“微基准”](ch08.html#ch-obs-micro)。
- en: Metrics such as [Example 6-7](#code-latency-metric) for macro measurements that
    involve larger systems with multiple processes
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，[示例 6-7](#code-latency-metric) 等度量标准适用于涉及多个进程的大型系统的宏观测量。
- en: 'Especially in the second case, as mentioned previously, we have to measure
    latency many times for a single operation to get reliable efficiency conclusions.
    We don’t have access to raw latency numbers for each operation with metrics—we
    have to choose some aggregation. In [Example 6-2](#code-latency-simplest-aggr),
    we proposed a simple average aggregation mechanism inside instrumentation. With
    metric instrumentation, this would be trivial to achieve. It’s as easy as creating
    two counters: one for the `sum` of latencies and one for the `count` of operations.
    We can evaluate collected data with those two metrics into a mean (arithmetic
    average).'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是在第二种情况下，正如前面提到的，我们必须多次测量单个操作的延迟，以获得可靠的效率结论。我们没有每个操作的原始延迟数据——我们必须选择一些聚合方式。在[示例 6-2](#code-latency-simplest-aggr)中，我们提出了一个简单的平均聚合机制在仪表化内部。使用度量仪表化，这将变得非常容易。只需创建两个计数器：一个用于延迟的`sum`和一个用于操作的`count`。我们可以用这两个度量值来计算平均值（算术平均）来评估收集到的数据。
- en: Unfortunately, the average is too naive an aggregation. We can miss lots of
    important information about the characteristics of our latency. In [“Microbenchmarks”](ch08.html#ch-obs-micro),
    we can do a lot with the mean for basic statistics (this is what the Go benchmarking
    tool is using), but in measuring the efficiency of our software in the bigger
    system with more unknowns, we have to be mindful. For example, imagine we want
    to improve the latency of one operation that used to take around 10 seconds. We
    made a potential optimization using our TFBO flow. We want to assess the efficiency
    on the macro level. During our tests, the system performed 500 operations within
    5 seconds (faster!), but 50 operations were extremely slow, with a 40-second latency.
    Suppose we would stick to the average (8.1 seconds). In that case, we could make
    the wrong conclusion that our optimization was successful, missing the potential
    big problem that our optimization caused, leading to 9% of operations being extremely
    slow.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，平均值过于简单化了聚合方式。我们可能会错过大量关于我们延迟特性的重要信息。在[“微基准”](ch08.html#ch-obs-micro)中，我们可以用平均值进行基本统计（这是Go基准测试工具在使用的方法），但在衡量我们软件在更复杂系统中的效率时，我们必须谨慎。例如，想象一下，我们想要提高一个操作的延迟，该操作过去大约需要10秒。我们使用我们的TFBO流程进行了潜在的优化。我们想在宏观层面评估效率。在我们的测试期间，系统在5秒内执行了500次操作（更快！），但有50次操作的延迟非常慢，达到了40秒。假设我们坚持使用平均值（8.1秒）。那么，我们可能会错误地得出结论，认为我们的优化成功了，忽视了我们的优化可能导致的潜在大问题，导致9%的操作延迟非常慢。
- en: This is why it’s helpful to measure specific metrics (like latency) in percentiles.
    This is what [Example 6-7](#code-latency-metric) instrumentation is for with the
    metric histogram type for our latency measurements.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么在百分位数中测量特定度量指标（如延迟）非常有帮助。这就是[示例 6-7](#code-latency-metric)仪表化的目的，用于我们的延迟测量的度量直方图类型。
- en: 'Most metrics are better thought of as distributions rather than averages. For
    example, for a latency SLI [service level indicator], some requests will be serviced
    quickly, while others will invariably take longer—sometimes much longer. A simple
    average can obscure these tail latencies, as well as changes in them. (...) Using
    percentiles for indicators allows you to consider the shape of the distribution
    and its differing attributes: a high-order percentile, such as the 99th or 99.9th,
    shows you a plausible worst-case value, while using the 50th percentile (also
    known as the median) emphasizes the typical case.'
  id: totrans-263
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 大多数度量更适合视为分布而不是平均值。例如，对于延迟SLI [服务水平指标]，一些请求将被快速服务，而其他请求则不可避免地需要更长的时间——有时更长得多。简单的平均值可能会掩盖这些尾延迟以及它们的变化。(...)
    使用百分位数指标允许您考虑分布的形状及其不同的属性：高阶百分位数，如第99或第99.9，显示可能的最坏情况值，而使用第50百分位数（也称为中位数）强调典型情况。
- en: ''
  id: totrans-264
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: C. Jones et al., [*Site Reliability Engineering*, “Service Level Objectives”](https://oreil.ly/rMBW3)
    (O’Reilly, 2016)
  id: totrans-265
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: C. Jones 等人，[*网站可靠性工程*, “服务级别目标”](https://oreil.ly/rMBW3)（O’Reilly，2016）
- en: The histogram metric I mentioned in [Example 6-8](#code-latency-metric-om) is
    great for latency measurements, as it counts how many operations fit into a certain
    latency range. In [Example 6-7](#code-latency-metric), I have chosen^([21](ch06.html#idm45606830952080))
    exponential buckets `0.001, 0.01, 0.1, 1, 10, 100`. The largest bucket should
    represent the longest operation duration you expect in your system (e.g., a timeout).^([22](ch06.html#idm45606830949872))
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我在[示例 6-8](#code-latency-metric-om)中提到的直方图指标非常适合延迟测量，因为它计算了多少操作适合特定的延迟范围。在[示例
    6-7](#code-latency-metric)中，我选择了指数桶 `0.001, 0.01, 0.1, 1, 10, 100`。（参见^([21](ch06.html#idm45606830952080))）最大的桶应该代表您在系统中预期的最长操作持续时间（例如，超时）。（参见^([22](ch06.html#idm45606830949872))）
- en: In [“Metrics”](#ch-obs-metrics), we discussed how we can use metrics using `PromQL`.
    For the histogram type of metrics and our latency semantics, the best way to understand
    this is to use the `histogram_quantile` function. See the example output in [Figure 6-8](#img-obs-metric-perc-5)
    for the median, and [Figure 6-9](#img-obs-metric-perc-9) for the 90th percentile.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“度量”](#ch-obs-metrics)中，我们讨论了如何使用 `PromQL` 这种度量标准。对于直方图类型的度量和我们的延迟语义，理解这一点的最佳方法是使用
    `histogram_quantile` 函数。请参阅[图 6-8](#img-obs-metric-perc-5)中的中位数示例输出和[图 6-9](#img-obs-metric-perc-9)中的第
    90 分位数示例输出。
- en: '![efgo 0608](assets/efgo_0608.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0608](assets/efgo_0608.png)'
- en: Figure 6-8\. Fiftieth percentile (median) of latency across an operation per
    error type from our [Example 6-7](#code-latency-metric) instrumentation
  id: totrans-269
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-8\. 我们在[示例 6-7](#code-latency-metric)中对每种错误类型的操作的五十分位数（中位数）。
- en: '![efgo 0609](assets/efgo_0609.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0609](assets/efgo_0609.png)'
- en: Figure 6-9\. Ninetieth percentile of latency across the operation per error
    type from our [Example 6-7](#code-latency-metric) instrumentation
  id: totrans-271
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-9\. 我们在[示例 6-7](#code-latency-metric)中对每种错误类型的操作的延迟的九十分位数。
- en: 'Both results can lead to interesting conclusions for the program I measured.
    We can observe a few things:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个结果可以为我所测量的程序得出有趣的结论。我们可以观察到几件事情：
- en: Half of the operations were generally faster than 590 milliseconds, while 90%
    were faster than 1 second. So if our RAER ([“Resource-Aware Efficiency Requirements”](ch03.html#ch-conq-req))
    states that 90% of operations should be less than 1 second, it could mean we don’t
    need to optimize further.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一半的操作通常快于 590 毫秒，而 90% 的操作快于 1 秒。因此，如果我们的 RAER（“资源感知效率要求”）声明 90% 的操作应在 1 秒内完成，这可能意味着我们不需要进一步优化。
- en: Operations that failed with `error_type=error1` were considerably slower (most
    likely some bottleneck exists in that code path).
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 失败于 `error_type=error1` 的操作明显较慢（很可能在该代码路径中存在某种瓶颈）。
- en: Around 17:50 UTC, we can see a slight increase in latencies for all operations.
    This might mean some side effect or change in the environment that caused my laptop’s
    operating system to give less CPU to my test.^([23](ch06.html#idm45606830933632))
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大约在 17:50 UTC，我们可以看到所有操作的延迟略有增加。这可能意味着一些副作用或环境变化导致我的笔记本操作系统为我的测试分配了较少的 CPU。（参见^([23](ch06.html#idm45606830933632))）
- en: Such measured and defined latency can help us determine if our latency is good
    enough for our requirements and if any optimization we do helps or not. It can
    also help us to find parts that cause slowness using different benchmarking and
    bottleneck-finding strategies. We will explore those in [Chapter 7](ch07.html#ch-observability2).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这种测量和定义的延迟可以帮助我们确定我们的延迟是否足够满足我们的要求，以及我们所做的任何优化是否有帮助。它还可以帮助我们使用不同的基准测试和瓶颈查找策略找到导致速度变慢的部分。我们将在[第
    7 章](ch07.html#ch-observability2)中探讨这些内容。
- en: 'With the typical latency metric definition and example instrumentation, let’s
    move to the next resource we might want to measure in our efficiency journey:
    CPU usage.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 根据典型的延迟度量定义和示例仪器化，让我们继续移动到我们可能希望在效率旅程中测量的下一个资源：CPU 使用情况。
- en: CPU Usage
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CPU 使用情况
- en: In [Chapter 4](ch04.html#ch-hardware), you learned how CPU is used when we execute
    our Go programs. I also explained that we look at CPU usage to reduce CPU-driven
    latency^([24](ch06.html#idm45606830921280)) and cost, and to enable running more
    processes on the same machine.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 4 章](ch04.html#ch-hardware)中，您学习了我们在执行 Go 程序时如何使用 CPU。我还解释了我们查看 CPU 使用情况以减少
    CPU 驱动的延迟（参见^([24](ch06.html#idm45606830921280))）和成本，以及在同一台机器上运行更多进程的能力。
- en: 'A variety of metrics allow us to measure different parts of our program’s CPU
    usage. For example, with Linux tools like the [`proc` filesystem](https://oreil.ly/MJVHl)
    and [`perf`](https://oreil.ly/QPMD9), we can measure our [Go program’s miss and
    hit rates, CPU branch prediction hit rates](https://oreil.ly/VdENl), and other
    low-level statistics. However, for basic CPU efficiency, we usually focus on the
    CPU cycles, instructions, or time used:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 各种度量指标允许我们测量程序CPU使用的不同部分。例如，借助Linux工具如[`proc`文件系统](https://oreil.ly/MJVHl)和[`perf`](https://oreil.ly/QPMD9)，我们可以测量我们的[Go程序的未命中和命中率，CPU分支预测命中率](https://oreil.ly/VdENl)以及其他低级别的统计信息。但是，对于基本的CPU效率，我们通常关注CPU周期、指令或使用时间：
- en: CPU cycles
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: CPU周期
- en: The total number of CPU clock cycles used to execute the program thread instructions
    on each CPU core.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 每个CPU核心上执行程序线程指令所使用的总CPU时钟周期数。
- en: CPU instructions
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: CPU指令
- en: The total number of CPU instructions of our program’s threads executed in each
    CPU core. On some CPUs from the [RISC architecture](https://oreil.ly/ofvB7) (e.g.,
    ARM processors), this might be equal to the number of cycles, as one instruction
    always takes one cycle (amortized cost). However, on the CISC architecture (e.g.,
    AMD and Intel x64 processors), different instructions might use additional cycles.
    Thus, counting how many instructions our CPU had to do to complete some program’s
    functionality might be more stable.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们程序线程在每个CPU核心上执行的总CPU指令数。在某些来自[RISC体系结构](https://oreil.ly/ofvB7)的CPU上（例如ARM处理器），这可能等于周期数，因为一个指令总是需要一个周期（摊销成本）。然而，在CISC体系结构（例如AMD和Intel
    x64处理器）上，不同的指令可能会使用额外的周期。因此，计算CPU必须完成某些程序功能所需的指令数可能更加稳定。
- en: 'Both cycles and instructions are great for comparing different algorithms with
    each other. It is because they are less noisy as:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是周期还是指令，都非常适合比较不同的算法。这是因为它们的噪声较小，例如：
- en: They don’t depend on the frequency the CPU core had during the program run
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们不依赖于CPU核心在程序运行期间的频率。
- en: Latency of memory fetches, including different caches, misses, and RAM latency
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存提取的延迟，包括不同的缓存、未命中和RAM延迟
- en: CPU time
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: CPU时间
- en: The time (in seconds or nanoseconds) our program thread spends executing on
    each CPU core. As you will learn in [“Off-CPU Time”](ch09.html#ch-obs-pprof-latency),
    this time is different (longer or shorter) from the latency of our program, as
    CPU time does not include I/O waiting time and OS scheduling time. Furthermore,
    our program’s OS threads might execute simultaneously on multiple CPU cores. Sometimes
    we also use CPU time divided by the CPU capacity, often referred to as CPU usage.
    For example, 1.5 CPU usage in seconds means our program requires (on average)
    one CPU core for 1 second and a second core for 0.5 seconds.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的程序线程在每个CPU核心上执行的时间（以秒或纳秒为单位）。正如您将在[“Off-CPU时间”](ch09.html#ch-obs-pprof-latency)中了解到的那样，这段时间与我们程序的延迟不同（更长或更短），因为CPU时间不包括I/O等待时间和操作系统调度时间。此外，我们程序的OS线程可能同时在多个CPU核心上执行。有时我们还会使用CPU时间除以CPU容量，通常称为CPU使用率。例如，1.5秒的CPU使用率意味着我们的程序平均需要一个CPU核心执行1秒，第二个核心执行0.5秒。
- en: 'On Linux, the CPU time is often split into User and System time:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux上，CPU时间通常分为用户时间和系统时间：
- en: User time represents the time the program spends executing on the CPU in the
    user space.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户时间表示程序在用户空间执行CPU上的时间。
- en: System time is the CPU time spent executing certain functions in the kernel
    space on behalf of the user, e.g., syscalls like [`read`](https://oreil.ly/xEQuM).
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统时间是CPU在内核空间上代表用户执行某些函数的时间，例如像[`read`](https://oreil.ly/xEQuM)这样的系统调用。
- en: Usually, on higher levels such as containers, we don’t have the luxury of having
    all three metrics. We mostly have to rely on CPU time. Fortunately, the CPU time
    is typically a good enough metric to track down the work needed from our CPUs
    to execute our workload. On Linux, the simplest way to retrieve the current CPU
    time counted from the start of the process is to go to */proc/`<PID>`/stat* (where
    `PID` means the process ID). We also have similar statistics on the thread level
    in */proc/`<PID>`/tasks/`<TID>`/stat* (where `TID` means the thread ID). This
    is exactly what utilities like `ps` or `htop` use.^([25](ch06.html#idm45606830897680))
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，在更高级别，比如容器中，我们没有所有三个度量的奢侈条件。我们大多数时候必须依赖CPU时间。幸运的是，CPU时间通常是一个足够好的度量，用来追踪我们的CPU执行工作负载所需的情况。在Linux上，从进程启动时算起获取当前CPU时间的最简单方法是访问
    */proc/`<PID>`/stat*（其中`PID`表示进程ID）。我们在线程级别上也有类似的统计信息，例如 */proc/`<PID>`/tasks/`<TID>`/stat*（其中`TID`表示线程ID）。这正是像`ps`或`htop`这样的实用程序所使用的。^([25](ch06.html#idm45606830897680))
- en: 'The `ps` and `htop` tools might be indeed the simplest tools to measure the
    CPU time in the current moment. However, we usually need to assess the CPU time
    required for the full functionality we are optimizing. Unfortunately, [“Go Benchmarks”](ch08.html#ch-obs-micro-go)
    is not providing CPU time (only latency and allocations) per operation. You could
    perhaps obtain that number from the `stat` file, e.g., programmatically using
    the [`procfs` Go library](https://oreil.ly/ZcCDn), but there are two main ways
    I would suggest instead:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '`ps`和`htop`工具确实可能是当前测量CPU时间的最简单工具。然而，我们通常需要评估我们正在优化的完整功能所需的CPU时间。不幸的是，[“Go
    Benchmarks”](ch08.html#ch-obs-micro-go)没有提供每个操作的CPU时间（仅延迟和分配）。您可以从`stat`文件中获取该数字，例如，使用[`procfs`
    Go库](https://oreil.ly/ZcCDn)以编程方式获取，但我建议另外两种主要方法：'
- en: CPU profiling, explained in [“CPU”](ch09.html#ch-obs-pprof-cpu).
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU分析，详见[“CPU”](ch09.html#ch-obs-pprof-cpu)。
- en: Prometheus metric instrumentation. Let’s quickly look at that method next.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus指标仪表化。接下来让我们快速看一下这种方法。
- en: In [Example 6-7](#code-latency-metric), I showed a Prometheus instrumentation
    that registers custom latency metrics. It’s also very easy to add the CPU time
    metric, but the Prometheus [client library](https://oreil.ly/1r2zw) has already
    built helpers for that. The recommended way is presented in [Example 6-11](#code-cpu-metric).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 6-7](#code-latency-metric)中，我展示了一个注册自定义延迟指标的Prometheus仪器。添加CPU时间度量也非常简单，但Prometheus的[客户端库](https://oreil.ly/1r2zw)已经为此构建了帮助程序。推荐的方法在[示例
    6-11](#code-cpu-metric)中呈现。
- en: Example 6-11\. Registering `proc` `stat` instrumentation about your process
    for Prometheus use
  id: totrans-298
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-11\. 注册有关您的进程用于Prometheus的`proc` `stat`仪器信息
- en: '[PRE10]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO11-1)'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO11-1)'
- en: The only thing you have to do to have the CPU time metric with Prometheus is
    to register the `collectors.NewProcessCollector` that uses the `/proc` `stat`
    file mentioned previously.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 您唯一需要做的就是使用之前提到的`/proc` `stat`文件注册`collectors.NewProcessCollector`来获取Prometheus的CPU时间度量。
- en: The `collectors.ProcessCollector` provides multiple metrics, like `pro⁠cess_​open_fds`,
    `process_max_fds`, `process_start_time_seconds`, and so on. But the one we are
    interested in is `process_cpu_seconds_total`, which is a counter of CPU time used
    from the beginning of our program. What’s special about using Prometheus for this
    task is that it collects the values of this metric periodically from our Go program.
    This means we can query Prometheus for the process CPU time for a certain time
    window and map that to real time. We can do that with the [`rate`](https://oreil.ly/8BaUw)
    function duration that gives us the per second rate of that CPU time in a given
    time window. For example, `rate(process_cpu_sec⁠onds_​total{}[5m])` will give
    us the average CPU per second time that our program had during the last five minutes.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '`collectors.ProcessCollector`提供多个指标，如`pro⁠cess_​open_fds`，`process_max_fds`，`process_start_time_seconds`等等。但我们感兴趣的是`process_cpu_seconds_total`，它是从我们程序开始运行以来使用的CPU时间计数器。使用Prometheus处理此任务的特别之处在于它周期性地从我们的Go程序中收集此指标的值。这意味着我们可以查询Prometheus以获取特定时间窗口内的进程CPU时间，并将其映射到实时。我们可以使用[`rate`](https://oreil.ly/8BaUw)函数的持续时间来获取CPU时间每秒的平均速率。例如，`rate(process_cpu_sec⁠onds_​total{}[5m])`将给出我们的程序在过去五分钟内的平均每秒CPU时间。'
- en: You will find an example CPU time analysis based on this kind of metric in [“Understanding
    Results and Observations”](ch08.html#ch-obs-macro-results). However, for now,
    I would love to show you one interesting and common case, where `process_cpu_seconds_total`
    helps narrow down a major efficiency problem. Imagine your machine has only two
    CPU cores (or we limit our program to use two CPU cores), you run the functionality
    you want to assess, and you see the CPU time rate of your Go program looking like
    [Figure 6-10](#img-obs-metric-cpu).
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在基于此类度量标准的示例CPU时间分析中找到，见[“理解结果和观察”](ch08.html#ch-obs-macro-results)。但是，现在，我愿意向您展示一个有趣且常见的情况，即`process_cpu_seconds_total`有助于缩小主要效率问题的范围。想象一下，您的机器只有两个CPU核心（或者我们限制我们的程序使用两个CPU核心），您运行要评估的功能，然后看到您的Go程序的CPU时间率看起来像[图
    6-10](#img-obs-metric-cpu)。
- en: 'Thanks to this view, we can tell that the `labeler` process is experiencing
    a state of CPU saturation. This means that our Go process requires more CPU time
    than was available. Two signals tell us about the CPU saturation:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了这个视图，我们可以知道`labeler`进程正在经历CPU饱和状态。这意味着我们的Go进程需要比可用的CPU时间更多。有两个信号告诉我们CPU饱和状态：
- en: The typical “healthy” CPU usage is spikier (e.g., as presented in [Figure 8-4](ch08.html#img-macrobench-cpu)
    later in the book). This is because it’s unlikely that typical applications use
    the same amount of CPU all the time. However, in [Figure 6-10](#img-obs-metric-cpu),
    we see the same CPU usage for five minutes.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 典型的“健康”CPU 使用是波动的（例如，如本书后面[图 8-4](ch08.html#img-macrobench-cpu)所示）。这是因为典型应用程序不太可能一直使用相同数量的
    CPU。然而，在[图 6-10](#img-obs-metric-cpu)中，我们看到了五分钟内相同的 CPU 使用情况。
- en: Because of this, we never want our CPU time to be so close to the CPU limit
    (two in our case). In [Figure 6-10](#img-obs-metric-cpu), we can clearly see a
    small choppiness around the CPU limit, which indicates full CPU saturation.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，我们永远不希望我们的 CPU 时间接近 CPU 限制（在我们的情况中是两个）。在[图 6-10](#img-obs-metric-cpu)中，我们可以清楚地看到
    CPU 限制周围的轻微波动，这表明 CPU 完全饱和。
- en: '![efgo 0610](assets/efgo_0610.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![efgo 0610](assets/efgo_0610.png)'
- en: Figure 6-10\. The Prometheus graph view of the CPU time for the `labeler` Go
    program (we will use it in an example in [“Macrobenchmarks”](ch08.html#ch-obs-macro))
    after a test
  id: totrans-308
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-10\. `labeler` Go 程序的 Prometheus CPU 时间图（我们将在[“宏基准”](ch08.html#ch-obs-macro)章节中使用）经过一次测试后
- en: Knowing when we are at saturation of our CPU is critical. First of all, it might
    give the wrong impression that the current CPU time is the maximum that the process
    needs. Moreover, this situation also significantly slows down our program’s execution
    time (increases latency) or even stalls it completely. This is why the Prometheus-based
    CPU time metric, as you learned here, has proven to be critical for me in learning
    about such saturation cases. It is also one of the first things you must find
    out when analyzing your program’s efficiency. When saturation happens, we have
    to give more CPU cores to the process, optimize the CPU usage, or decrease the
    concurrency (e.g., limit the number of HTTP requests it can do concurrently).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 知道我们的 CPU 饱和时至关重要。首先，这可能会给人错误的印象，即当前 CPU 时间是进程需要的最大值。此外，这种情况也会显著减慢我们程序的执行时间（增加延迟）或者完全使其停滞。这就是为什么基于
    Prometheus 的 CPU 时间指标，正如您在这里学到的那样，对我来说在了解这种饱和情况方面至关重要。这也是在分析程序效率时必须首先找出的事情之一。当发生饱和时，我们必须给该进程更多的
    CPU 核心，优化 CPU 使用，或者减少并发性（例如，限制它能够同时处理的 HTTP 请求数量）。
- en: On the other hand, CPU time allows us to find out about opposite cases where
    the process might be blocked. For example, if you expect CPU-bound functionality
    to run with 5 goroutines, and you see the CPU time of 0.5 (50% of one CPU core),
    it might mean the goroutines are blocked (more on that in [“Off-CPU Time”](ch09.html#ch-obs-pprof-latency))
    or whole machine and OS are busy.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，CPU 时间让我们了解到可能被阻塞的相反情况。例如，如果你期望 CPU 密集型功能以 5 个 goroutine 运行，并且看到 CPU 时间为
    0.5（占一个 CPU 核心的 50%），这可能意味着 goroutine 被阻塞了（关于此更多内容见[“Off-CPU 时间”](ch09.html#ch-obs-pprof-latency)）或整个机器和操作系统都很忙。
- en: Let’s now look at memory usage metrics.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一下内存使用指标。
- en: Memory Usage
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存使用
- en: As we learned in [Chapter 5](ch05.html#ch-hardware2), there are complex layers
    of different mechanics on how our Go program uses memory. This is why the actual
    physical memory (RAM) usage is one of the most tricky to measure and attribute
    to our program. On most systems with an OS memory management mechanism like virtual
    memory, paging, and shared pages, every memory usage metric will be only an estimation.
    While imperfect, this is what we have to work with, so let’s take a short look
    at what works best for the Go program.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第 5 章](ch05.html#ch-hardware2)中学到的，关于我们的 Go 程序如何使用内存有各种复杂的层次。这就是为什么实际物理内存（RAM）使用是最棘手的测量之一，并归因于我们的程序。在像虚拟内存、分页和共享页面这样的操作系统内存管理机制上，每个内存使用指标只能是估计。虽然不完美，但这是我们必须处理的，所以让我们简要看一下哪种方法最适合
    Go 程序。
- en: 'There are two main sources of memory usage information for our Go process:
    the Go runtime heap memory statistics and the information that OS holds about
    memory pages. Let’s start with the in-process runtime stats.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们 Go 进程的内存使用信息主要来自两个来源：Go 运行时堆内存统计和操作系统关于内存页面的信息。让我们从进程内运行时统计开始。
- en: runtime heap statistics
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行时堆统计
- en: As we learned in [“Go Memory Management”](ch05.html#ch-hw-go-mem), the heap
    segment of the Go program virtual memory can be an adequate proxy for memory usage.
    This is because most bytes are allocated on the heap for typical Go applications.
    Moreover, such memory is also never evicted from the RAM (unless the swap is enabled).
    As a result, we can effectively assess our functionality’s memory usage by looking
    at the heap size.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[“Go内存管理”](ch05.html#ch-hw-go-mem)中所学到的，Go程序虚拟内存的堆段可以作为内存使用的足够代理。这是因为对于典型的Go应用程序，大多数字节都分配在堆上。此外，这种内存也从不从RAM中逐出（除非启用交换）。因此，我们可以通过查看堆大小有效评估我们功能的内存使用。
- en: 'We are often most interested in assessing the memory space or the number of
    memory blocks needed to perform a certain operation. To try to estimate this,
    we usually use two semantics:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常最感兴趣的是评估执行某种操作所需的内存空间或内存块数。为了尝试估计这一点，我们通常使用两种语义：
- en: The total allocations of bytes or objects on the heap allow us to look at memory
    allocations without often nondeterministic GC impact.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆上的总字节或对象分配使我们能够查看内存分配，而不经常非确定性GC影响。
- en: The number of currently in-use bytes or objects on the heap.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆上当前正在使用的字节或对象的数量。
- en: The preceding statistics are very accurate and quick to access because Go runtime
    is responsible for heap management, so it tracks all the information we need.
    Before Go 1.16, the recommended way to access those statistics programmatically
    was using the [`runtime.ReadMemStats` function](https://oreil.ly/AwX75). It still
    works for compatibility reasons, but unfortunately, it requires STW (stop the
    world) events to gather all memory statistics. As a result of Go 1.16, we should
    all use the [`runtime/metrics`](https://oreil.ly/WYiOd) package that provides
    many cheap-to-collect insights about GC, memory allocations, and so on. The example
    usage of this package to get memory usage metrics is presented in [Example 6-12](#code-rtm).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的统计数据非常准确且快速访问，因为Go运行时负责堆管理，所以它跟踪我们需要的所有信息。在Go 1.16之前，通过[`runtime.ReadMemStats`函数](https://oreil.ly/AwX75)是以编程方式访问这些统计数据的推荐方式，尽管出于兼容性原因它仍然可用，但不幸的是，它需要STW（停止世界）事件来收集所有内存统计信息。从Go
    1.16开始，我们应该全部使用提供有关GC、内存分配等许多廉价收集见解的[`runtime/metrics`](https://oreil.ly/WYiOd)包。此包的示例用法用于获取内存使用度量在[Example 6-12](#code-rtm)中介绍。
- en: Example 6-12\. The simplest code prints total heap allocated bytes and currently
    used ones
  id: totrans-321
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例6-12。最简单的代码打印总堆分配的字节和当前使用的字节
- en: '[PRE11]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](assets/1.png)](#co_efficiency_observability_CO12-1)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_efficiency_observability_CO12-1)'
- en: To read samples from `runtime/metrics`, we must first define them by referencing
    the desired metric name. The full list of metrics might be different (mostly added
    ones) across different Go versions, and you can see the list with descriptions
    at [*pkg.go.dev*](https://oreil.ly/HWGUJ). For example, we can obtain the number
    of objects in a heap.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 要从`runtime/metrics`读取样本，我们必须首先通过引用所需的度量名称来定义它们。不同Go版本中可能会有不同（主要是添加的）度量的完整列表，并且您可以在[*pkg.go.dev*](https://oreil.ly/HWGUJ)上查看具有描述的列表。例如，我们可以获取堆中对象的数量。
- en: '[![2](assets/2.png)](#co_efficiency_observability_CO12-2)'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_efficiency_observability_CO12-2)'
- en: Memory statistics are recorded right after a GC run, so we can trigger GC to
    have the latest information about the heap.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 内存统计在GC运行后立即记录，因此我们可以触发GC以获取有关堆的最新信息。
- en: '[![3](assets/3.png)](#co_efficiency_observability_CO12-3)'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_efficiency_observability_CO12-3)'
- en: '`metrics.Read` populates the value of our samples. You can reuse the same sample
    slice if you only care about the latest values.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '`metrics.Read`填充我们样本的值。如果您只关心最新值，可以重用相同的样本切片。'
- en: '[![4](assets/4.png)](#co_efficiency_observability_CO12-4)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_efficiency_observability_CO12-4)'
- en: Both metrics are of `uint64` type, so we use the `Uint64()` method to retrieve
    the value.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个度量都是`uint64`类型，因此我们使用`Uint64()`方法来检索值。
- en: 'Programmatically accessing this information is useful for local debugging purposes,
    but it’s not sustainable on every optimization attempt. That’s why in the community,
    we typically see other ways to access that data:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 编程访问此信息对于本地调试目的很有用，但在每次优化尝试中并不可持续。这就是为什么在社区中，我们通常看到其他访问这些数据的方式：
- en: Go benchmarking, explained in [“Go Benchmarks”](ch08.html#ch-obs-micro-go)
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go基准测试，在[“Go基准测试”](ch08.html#ch-obs-micro-go)中解释
- en: Heap profiling, explained in [“Heap”](ch09.html#ch-obs-pprof-heap)
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆分析，在[“堆”](ch09.html#ch-obs-pprof-heap)中解释
- en: Prometheus metric instrumentation
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus度量仪器
- en: 'To register `runtime/metric` as Prometheus metrics, we can add a single line
    to [Example 6-11](#code-cpu-metric): `reg.MustRegister(collectors.NewGoCollector())`.
    The Go collector is a structure that, by default, exposes [various memory statistics](https://oreil.ly/Ib8D2).
    For historical reasons, those map to the `MemStats` Go structure, so the equivalents
    to the metrics defined in [Example 6-12](#code-rtm) would be `go_mem⁠stats_​heap_alloc_bytes_total`
    for a counter, and `go_memstats_heap_alloc_bytes` for a current usage gauge. We
    will show an analysis of Go heap metrics in [“Go e2e Framework”](ch08.html#ch-obs-macro-example).'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 `runtime/metric` 注册为 Prometheus 指标，我们可以在 [Example 6-11](#code-cpu-metric)
    中添加一行：`reg.MustRegister(collectors.NewGoCollector())`。Go 收集器默认公开各种内存统计信息（参见 [各种内存统计](https://oreil.ly/Ib8D2)）。出于历史原因，这些统计信息映射到
    `MemStats` Go 结构体，因此在 [Example 6-12](#code-rtm) 中定义的指标的等价物将是`go_mem⁠stats_​heap_alloc_bytes_total`作为计数器，以及`go_memstats_heap_alloc_bytes`作为当前使用的计量表。我们将在
    [“Go e2e Framework”](ch08.html#ch-obs-macro-example) 中展示 Go 堆统计的分析。
- en: Unfortunately, heap statistics are only an estimation. It is likely that the
    smaller the heap on our Go program, the better the memory efficiency. However,
    suppose you add some deliberate mechanisms like large off-heap memory allocations
    using explicit `mmap` syscall or thousands of goroutines with large stacks. In
    that case, that can cause an OOM on your machine, yet it’s not reflected in the
    heap statistics. Similarly, in [“Go Allocator”](ch05.html#ch-hw-allocator), I
    explained rare cases where only part of the heap space is allocated on physical
    memory.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，堆统计仅仅是一个估算值。我们的 Go 程序堆越小，内存效率可能越好。但是，如果你添加一些像使用显式的`mmap`系统调用进行大量的堆外存储器分配或者数千个大堆栈
    goroutine 的有意机制，那可能会在你的机器上导致内存溢出，但这在堆统计中并不反映出来。类似地，在 [“Go Allocator”](ch05.html#ch-hw-allocator)
    中，我解释了只有堆空间的一部分被分配到物理内存的罕见情况。
- en: Still, despite the downsides, heap allocations remain the most effective way
    to measure memory usage in modern Go programs.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这些不利因素，堆分配仍然是现代 Go 程序中测量内存使用效果最好的方法。
- en: OS memory pages statistics
  id: totrans-338
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 操作系统内存页统计
- en: We can check the numbers the Linux OS tracks per thread to learn more realistic
    yet more complex memory usage statistics. Similar to [“CPU Usage”](#ch-obs-cpu-usage),
    `/proc/*<PID>*/statm` provides the memory usage statistics, measured in pages.
    Even more accurate numbers can be retrieved from per memory mapping statistics
    that we can see in `/proc/*<PID>*/smaps` ([“OS Memory Mapping”](ch05.html#ch-hw-memory-mmap-os)).
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以检查 Linux 操作系统每个线程跟踪的数字，以了解更真实但更复杂的内存使用统计。与 [“CPU Usage”](#ch-obs-cpu-usage)
    类似，`/proc/*<PID>*/statm` 提供了以页面为单位的内存使用统计。更精确的数字可以从每个内存映射统计中检索，我们可以在 `/proc/*<PID>*/smaps`
    中看到这些统计信息（参见 [“OS Memory Mapping”](ch05.html#ch-hw-memory-mmap-os)）。
- en: Each page in this mapping can have a different state. A page might or might
    not be allocated on physical memory. Some pages might be shared across processes.
    Some pages might be allocated in physical memory and accounted for as memory used,
    yet marked by the program as “free” (see the `MADV_FREE` release method mentioned
    in [“Garbage Collection”](ch05.html#ch-hw-garbage)). Some pages might not even
    be accounted for in the `smaps` file, because for example, [it’s part of filesystem
    Linux cache buffers](https://oreil.ly/uchws). For these reasons, we should be
    very skeptical about the absolute values observed in the following metrics. In
    many cases, OS is lazy in releasing memory; e.g., part of the memory used by the
    program is cached in the best way that will be released immediately as long as
    somebody else is needing that.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 这种映射中的每一页可能具有不同的状态。一页可能已经在物理内存上分配，也可能没有。有些页面可能会在多个进程之间共享。有些页面可能在物理内存中分配，并且作为已使用内存进行记账，但被程序标记为“空闲”（参见
    [“Garbage Collection”](ch05.html#ch-hw-garbage) 中提到的`MADV_FREE`释放方法）。有些页面甚至可能不会在`smaps`文件中计入，例如，因为它是
    [文件系统 Linux 缓存缓冲区的一部分](https://oreil.ly/uchws)。因此，我们对以下指标中观察到的绝对值应持怀疑态度。在许多情况下，操作系统在释放内存时都是懒惰的；例如，程序使用的部分内存被以最佳方式缓存，并且只要有其他程序需要，它们就会立即释放。
- en: 'There are a few typical memory usage metrics we can obtain from the OS about
    our process:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从操作系统获取一些关于我们进程的典型内存使用指标：
- en: VSS
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: VSS
- en: Virtual set size represents the number of pages (or bytes, depending on instrumentation)
    allocated for the program. Not very useful metrics, as most virtual pages are
    never allocated on RAM.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟集大小代表为程序分配的页面数（或字节，取决于仪表）。这些指标并不是很有用，因为大多数虚拟页面从未分配在 RAM 上。
- en: RSS
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: RSS
- en: Residential set size represents the number of pages (or bytes) resident in RAM.
    Note that different metrics might account for that differently; e.g., the [cgroups
    RSS metric](https://oreil.ly/NL5Ab) does not include file-mapped memory, which
    is tracked separately.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 住宅集大小表示驻留在RAM中的页面（或字节）数量。请注意，不同的度量可能以不同的方式考虑这一点；例如，[cgroups的RSS指标](https://oreil.ly/NL5Ab)不包括单独跟踪的文件映射内存。
- en: PSS
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: PSS
- en: Proportional set size represents memory with shared memory pages divided equally
    among all users.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 比例集大小代表了共享内存页面平均分配给所有用户的内存。
- en: WSS
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: WSS
- en: Working set size estimates the number of pages (or bytes) currently used to
    perform work by our program. It was initially [introduced by Brendan Gregg](https://oreil.ly/rWy8D)
    as the hot, frequently used memory—the minimum memory requirement by the program.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 工作集大小估计了我们程序当前用于执行工作的页面（或字节）数量。它最初由[Brendan Gregg引入](https://oreil.ly/rWy8D)作为热点，频繁使用的内存——程序的最小内存需求。
- en: The idea is that a program might have allocated 500 GB of memory, but within
    a couple of minutes, it might use only 50 MB for some localized computation. The
    rest of the memory could be, in theory, safely offloaded to disk.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 思路是，一个程序可能已经分配了500 GB的内存，但在几分钟内，可能只使用了50 MB来进行某些局部计算。理论上，其余的内存可以安全地转移到磁盘上。
- en: There are many implementations of WSS, but the most common I see is the [cadvisor
    interpretation](https://oreil.ly/mXjA3) using the [cgroup memory controller](https://oreil.ly/ovSlH).
    It calculates the WSS as the RSS (including file mapping), plus some part of the
    cache pages (cache used for disk reads or writes), minus the `inactive_file` entry—so
    file mapping that were not touched for some time. It does not include inactive
    anonymous pages because the typical OS configuration can’t offload anonymous pages
    to disk (swap is disabled).
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多WSS的实现，但我看到最常见的是使用[cadvisor解释](https://oreil.ly/mXjA3)，利用[cgroup内存控制器](https://oreil.ly/ovSlH)计算WSS，计算公式为RSS（包括文件映射）加上一部分缓存页面（用于磁盘读取或写入），减去`inactive_file`条目——因此一段时间内未被触及的文件映射。它不包括非活动匿名页面，因为典型的操作系统配置无法将匿名页面转移到磁盘上（交换已禁用）。
- en: In practice, RSS or WSS is used to determine the memory usage of our Go program.
    Which one highly depends on the other workloads on the same machine and follows
    the flow of the RAM usage expanding to all available space, as mentioned in [“Do
    We Have a Memory Problem?”](ch05.html#ch-hw-memory). The usefulness of each depends
    on the current Go version and instrumentation that gives you those metrics. In
    my experience, with the latest Go version and cgroup metrics, the RSS metric tends
    to give more reliable results.^([26](ch06.html#idm45606830443712)) Unfortunately,
    accurate or not, WSS is used in systems like [Kubernetes to trigger evictions
    (e.g., OOM)](https://oreil.ly/lnDkI), thus we should use it to assess memory efficiency
    that might lead to OOMs.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际中，RSS或WSS用于确定我们Go程序的内存使用情况。其中一个高度依赖于同一台机器上的其他工作负载，并遵循RAM使用扩展到所有可用空间的流程，正如[“我们是否有内存问题？”](ch05.html#ch-hw-memory)中所述。每个的有用性取决于当前的Go版本和提供这些指标的仪器。根据我的经验，使用最新的Go版本和cgroup指标，RSS指标往往提供更可靠的结果。^([26](ch06.html#idm45606830443712))
    不幸的是，无论准确与否，像[Kubernetes用于触发驱逐（例如，OOM）的系统](https://oreil.ly/lnDkI)中仍然使用WSS，因此我们应该使用它来评估可能导致OOM的内存效率。
- en: Given my focus on infrastructure Go programs, I heavily lean on a metric exporter
    called [cadvisor](https://oreil.ly/RJzKd) that converts cgroup metrics to Prometheus
    metrics. I will explain using it in detail in [“Go e2e Framework”](ch08.html#ch-obs-macro-example).
    It allows analyzing metrics like `container_memory_rss + container_memory_mapped_file`
    and `container_memory_working_set_bytes`, which are commonly used in the community.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我专注于基础架构Go程序，我倾向于使用名为[cadvisor的度量导出器](https://oreil.ly/RJzKd)，将cgroup指标转换为Prometheus指标。我将在[“Go
    e2e框架”](ch08.html#ch-obs-macro-example)中详细解释其使用方法。它允许分析像`container_memory_rss
    + container_memory_mapped_file`和`container_memory_working_set_bytes`这样的指标，这在社区中是常用的。
- en: Summary
  id: totrans-354
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Modern observability offers a set of techniques essential for our efficiency
    assessments and improvements. However, some argue that this kind of observability
    designed primarily for DevOps, SREs, and cloud-native solutions can’t work for
    developer use cases (in the past known as Application Performance Monitoring [APM]).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 现代可观察性提供了一套技术，对我们的效率评估和改进至关重要。然而，一些人认为这种主要设计给DevOps、SRE和云原生解决方案使用的可观察性无法适用于开发者用例（过去被称为应用性能监控[APM]）。
- en: I would argue that the same tools can be used for both developers (for those
    efficiency and debugging journeys) and system admins, operators, DevOps, and SREs
    to ensure the programs delivered by others are running effectively.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为同样的工具可以用于开发人员（用于效率和调试之旅）以及系统管理员、运维人员、DevOps 和 SRE，以确保他人交付的程序运行有效。
- en: 'In this chapter, we discussed the three first observability signals: metrics,
    logs, and tracing. Then, we went through example instrumentations for those in
    Go. Finally, I explained common semantics for the latency, CPU time, and memory
    usage measurements we will use in later chapters.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了三个最初的可观测性信号：度量、日志和追踪。然后，我们通过Go语言示例讲解了这些的仪器化。最后，我解释了我们将在后续章节中使用的延迟、CPU时间和内存使用量的常见语义。
- en: Now it’s time to learn how to use that efficiency observability to make data-driven
    decisions in practice. First, we will focus on how to simulate our program to
    assess the efficiency on different levels.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是学习如何利用效率可观测性进行数据驱动决策的时候了。首先，我们将专注于如何模拟我们的程序，以评估不同层次的效率。
- en: ^([1](ch06.html#idm45606832729952-marker)) Some of you might ask why I am sticking
    to the word *observability* and don’t mention monitoring. In my eyes, I have to
    agree with my friend [Björn Rabenstein](https://oreil.ly/9ado0) that the difference
    between monitoring and observability tends to be driven by marketing needs too
    much. One might say that observability has become meaningless these days. In theory,
    monitoring means answering known unknown problems (known questions), whereas observability
    allows learning about unknown unknowns (any question you might have in the future).
    In my eyes, monitoring is a subset of observability. In this book, we will stay
    pragmatic. Let’s focus on how we can leverage observability practically, not using
    theoretical concepts.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch06.html#idm45606832729952-marker)) 你们中的一些人可能会问为什么我坚持使用“可观测性”这个词，而不提及监控。在我看来，我必须同意我的朋友[Björn
    Rabenstein](https://oreil.ly/9ado0)的观点，即监控和可观测性之间的差异过于受到营销需求的驱动。有人可能会说，可观测性如今已经变得毫无意义。理论上，监控意味着回答已知的未知问题（已知问题），而可观测性允许了解未知的未知问题（未来可能会遇到的任何问题）。在我看来，监控是可观测性的一个子集。在本书中，我们将保持务实。让我们专注于如何在实践中利用可观测性，而不是使用理论概念。
- en: ^([2](ch06.html#idm45606832725840-marker)) The fourth signal, profiling, just
    started to be considered by some as an observability signal. This is because only
    recently did the industry see a value and need for gathering profiling continuously.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch06.html#idm45606832725840-marker)) 第四个信号，性能分析，最近开始被一些人视为一种可观测信号。这是因为直到最近，行业才意识到持续收集性能分析的价值和必要性。
- en: ^([3](ch06.html#idm45606832699376-marker)) As a recent example, we can give
    [this repository](https://oreil.ly/sPlPe) that gathers information through eBPF
    probes and tries to search popular functions or libraries.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch06.html#idm45606832699376-marker)) 作为一个最近的例子，我们可以提到这个仓库，通过eBPF探针收集信息，并尝试搜索流行的函数或库。
- en: ^([4](ch06.html#idm45606832688544-marker)) In some way, I am trying in this
    book to establish helpful processes around optimizations and efficiency, which
    by design yield standard questions we know up front. This aggregated information
    is usually enough for us here.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch06.html#idm45606832688544-marker)) 在本书中，我试图建立围绕优化和效率的有益流程，这些流程旨在提前获得标准问题。这些聚合信息通常对我们来说已经足够了。
- en: ^([5](ch06.html#idm45606832254464-marker)) Given Go compatibility guarantees,
    even if the community agrees to improve it, we cannot change it until Go 2.0.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch06.html#idm45606832254464-marker)) 鉴于Go的兼容性保证，即使社区同意改进它，我们也无法在Go 2.0之前进行更改。
- en: ^([6](ch06.html#idm45606832248016-marker)) A nonexecutable module or package
    intended to be imported by others.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch06.html#idm45606832248016-marker)) 一个供他人引入的非可执行模块或包。
- en: ^([7](ch06.html#idm45606832242864-marker)) There are many Go libraries for logging.
    `go-kit` has a good enough API that allows us to do all kinds of logging we need
    in all the Go projects I have helped with so far. This does not mean `go-kit`
    is without flaws (e.g., it’s easy to forget you have to put an even number of
    arguments for the key-value–like logic). There is also a pending proposal from
    the Go community on [structure logging in standard libraries (`slog` package)](https://oreil.ly/qnJ6y).
    Feel free to use any other libraries, but make sure their API is simple, readable,
    and useful. Also make sure that the library of your choice is not introducing
    efficiency problems.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch06.html#idm45606832242864-marker)) 记录日志的 Go 语言库很多。`go-kit` 提供了足够好的 API，能够在我迄今为止帮助的所有
    Go 项目中满足我们所有需要的日志记录。这并不意味着 `go-kit` 没有缺陷（例如，很容易忘记必须为键值对逻辑提供偶数个参数）。此外，Go 社区还有一个关于[标准库中的结构化日志（`slog`
    包）的提案](https://oreil.ly/qnJ6y)。欢迎使用任何其他库，但请确保它们的 API 简单、可读且有用。同时确保你选择的库不会引入效率问题。
- en: ^([8](ch06.html#idm45606832090240-marker)) It’s a typical pattern allowing processes
    to print something useful to standard output and keep logs separate in the `stderr`
    Linux file.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch06.html#idm45606832090240-marker)) 这是一种典型模式，允许进程将有用信息打印到标准输出并将日志保留在
    `stderr` Linux 文件中。
- en: ^([9](ch06.html#idm45606831687072-marker)) Tail sampling is a logic that defers
    the decision if the trace should be excluded or sampled at the end of the transaction,
    for example, only after we know its status code. The problem with tail sampling
    is that your instrumentation might have already assumed that all spans will be
    sampled.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch06.html#idm45606831687072-marker)) 尾部抽样是一种逻辑，延迟决定是否在事务结束时排除或抽样跟踪，例如，仅在我们知道其状态码之后。尾部抽样的问题在于你的工具可能已经假定所有跨度将被抽样。
- en: ^([10](ch06.html#idm45606831665920-marker)) I maintain this library together
    with the Prometheus team. The `client_golang` is also the most used metric client
    SDK for Go when writing this book, [with over 53,000 open source projects](https://oreil.ly/UW0fG)
    using it. It is free and open source.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch06.html#idm45606831665920-marker)) 我与 Prometheus 团队共同维护这个库。在编写本书时，`client_golang`
    是最常用的 Go 语言度量客户端 SDK，[有超过 53,000 个开源项目](https://oreil.ly/UW0fG)使用它。它是免费开源的。
- en: ^([11](ch06.html#idm45606831400064-marker)) It’s tempting to use global `prometheus.DefaultRegistry`.
    Don’t do this. We try to get away from this pattern that can cause many problems
    and side effects.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch06.html#idm45606831400064-marker)) 使用全局的 `prometheus.DefaultRegistry`
    是一种典型模式。但请不要这样做。我们试图摆脱这种可能会引起许多问题和副作用的模式。
- en: ^([12](ch06.html#idm45606831336912-marker)) Always check errors and perform
    graceful termination on process teardown. See production-grade usage in the [Thanos
    project](https://oreil.ly/yvvTM) that leverages the [run goroutine helper](https://oreil.ly/sDIwW).
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch06.html#idm45606831336912-marker)) 在进程拆除时，始终检查错误并执行优雅的终止。查看在[Thanos
    项目](https://oreil.ly/yvvTM)中的生产级使用，该项目利用[运行 goroutine 辅助程序](https://oreil.ly/sDIwW)。
- en: ^([13](ch06.html#idm45606831225328-marker)) Note that doing `rate` on the gauges
    type of metric will yield incorrect results.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch06.html#idm45606831225328-marker)) 请注意，在 `rate` 类型的度量标准上执行可能会产生不正确的结果。
- en: ^([14](ch06.html#idm45606831205328-marker)) On the contrary, for the push-based
    system, if you don’t see expected data, it’s hard to tell if it’s because the
    sender is down or the pipeline to send is down.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch06.html#idm45606831205328-marker)) 相反，对于推送式系统，如果没有看到预期的数据，很难判断是发送方宕机还是发送管道宕机。
- en: ^([15](ch06.html#idm45606831202864-marker)) See our talk from [KubeCon EU 2022](https://oreil.ly/TtKwH)
    about such cases.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch06.html#idm45606831202864-marker)) 查看我们在[KubeCon EU 2022](https://oreil.ly/TtKwH)的演讲，讨论了这类情况。
- en: ^([16](ch06.html#idm45606831155568-marker)) This is why the [Prometheus ecosystem
    suggests base units](https://oreil.ly/oJozb).
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch06.html#idm45606831155568-marker)) 这就是为什么[Prometheus 生态系统建议使用基本单位](https://oreil.ly/oJozb)。
- en: ^([17](ch06.html#idm45606831016880-marker)) For example, on my machine `time.Now`
    and `time.Since` take around 50–55 nanoseconds.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch06.html#idm45606831016880-marker)) 例如，在我的机器上，`time.Now` 和 `time.Since`
    大约需要 50-55 纳秒。
- en: ^([18](ch06.html#idm45606831013664-marker)) This is why it’s better to make
    thousands or even more of the same operation, measure the total latency, and get
    the average by dividing it by a number of operations. As a result, this is what
    Go benchmark is doing, as we will learn in [“Go Benchmarks”](ch08.html#ch-obs-micro-go).
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch06.html#idm45606831013664-marker)) 这就是为什么最好执行数千甚至更多次相同的操作，测量总延迟，并通过操作数进行平均。这就是
    Go 基准测试所做的，正如我们将在[“Go 基准测试”](ch08.html#ch-obs-micro-go)中学到的。
- en: ^([19](ch06.html#idm45606831005584-marker)) Did you know this date was picked
    simply because of [*Back to the Future Part II*](https://oreil.ly/Oct6X)?
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch06.html#idm45606831005584-marker)) 你知道这个日期之所以被选中，仅仅是因为[*回到未来第二部*](https://oreil.ly/Oct6X)吗？
- en: ^([20](ch06.html#idm45606830976592-marker)) The noteworthy example from my experience
    is measuring server-side latency of REST with a large response or HTTP/gRPC with
    a streamed response. The server-side latency does not depend only on the server
    but also on how fast the network and client side can consume those bytes (and
    write back acknowledge packets within [TCP control flow](https://oreil.ly/jcrSF)).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](ch06.html#idm45606830976592-marker)) 根据我的经验，一个显著的例子是测量具有大响应的REST服务端延迟或带有流式响应的HTTP/gRPC服务端延迟。服务端延迟不仅取决于服务器本身，还取决于网络和客户端多快能够消耗这些字节（并在[TCP控制流](https://oreil.ly/jcrSF)中写回确认数据包）。
- en: ^([21](ch06.html#idm45606830952080-marker)) Right now, the choice of buckets
    in a histogram if you want to use Prometheus is manual. However, the Prometheus
    community is working on [sparse histograms](https://oreil.ly/qFdC1) with a dynamic
    number of buckets that adjust automatically.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch06.html#idm45606830952080-marker)) 现在，如果你想要使用Prometheus，直方图中的桶的选择是手动的。然而，Prometheus社区正在研究[稀疏直方图](https://oreil.ly/qFdC1)，这些直方图具有动态的桶数，可以自动调整。
- en: ^([22](ch06.html#idm45606830949872-marker)) More on using histograms can be
    read [here](https://oreil.ly/VrWGe).
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch06.html#idm45606830949872-marker)) 更多关于使用直方图的内容可以在[这里](https://oreil.ly/VrWGe)阅读。
- en: ^([23](ch06.html#idm45606830933632-marker)) It makes sense. I was utilizing
    my web browser heavily during the test, which confirms the knowledge we will discuss
    in [“Reliability of Experiments”](ch07.html#ch-obs-rel).
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](ch06.html#idm45606830933632-marker)) 很有道理。我在测试期间大量使用了我的网络浏览器，这证实了我们将在[“实验可靠性”](ch07.html#ch-obs-rel)中讨论的知识。
- en: ^([24](ch06.html#idm45606830921280-marker)) As a reminder, we can improve the
    latency of our program’s functionality in many ways other than just by optimizing
    its CPU usage. We can improve that latency using concurrent execution that often
    increases total CPU time.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](ch06.html#idm45606830921280-marker)) 作为提醒，我们可以通过多种方式来改善程序功能的延迟，而不仅仅是通过优化CPU使用率。我们可以通过并发执行来提高延迟，通常会增加总CPU时间。
- en: ^([25](ch06.html#idm45606830897680-marker)) Also a useful [`procfs` Go library](https://oreil.ly/ZcCDn)
    that allows retrieving `stats` file data number programmatically.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: ^([25](ch06.html#idm45606830897680-marker)) 还有一个有用的[`procfs` Go library](https://oreil.ly/ZcCDn)，可以通过编程方式检索`stats`文件数据的数字。
- en: ^([26](ch06.html#idm45606830443712-marker)) One reason is the [issue](https://oreil.ly/LKmSA)
    in cadvisor that includes some still-reclaimable memory in the WSS.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: ^([26](ch06.html#idm45606830443712-marker)) 其中一个原因是在cadvisor中存在的[问题](https://oreil.ly/LKmSA)，其中包括一些仍可回收的内存。
