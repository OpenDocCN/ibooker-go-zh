- en: Chapter 9\. Resilience
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A distributed system is one in which the failure of a computer you didn’t even
    know about can render your own computer unusable.^([1](ch09.xhtml#idm45983623944264))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Leslie Lamport, DEC SRC Bulletin Board (May 1987)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Late one September night, at just after two in the morning, a portion of Amazon’s
    internal network quietly stopped working.^([2](ch09.xhtml#idm45983623938904))
    This event was brief, and not particularly interesting, except that it happened
    to affect a sizable number of the servers that supported the DynamoDB service.
  prefs: []
  type: TYPE_NORMAL
- en: Most days, this wouldn’t be such a big deal. Any affected servers would just
    try to reconnect to the cluster by retrieving their membership data from a dedicated
    metadata service. If that failed, they would temporarily take themselves offline
    and try again.
  prefs: []
  type: TYPE_NORMAL
- en: But this time, when the network was restored, a small army of storage servers
    simultaneously requested their membership data from the metadata service, overwhelming
    it so that requests—even ones from previously unaffected servers—started to time
    out. Storage servers dutifully responded to the timeouts by taking themselves
    offline and retrying (again), further stressing the metadata service, causing
    even more servers to go offline, and so on. Within minutes, the outage had spread
    to the entire cluster. The service was effectively down, taking a number of dependent
    services down with it.
  prefs: []
  type: TYPE_NORMAL
- en: To make matters worse, the sheer volume of retry attempts—a “retry storm”—put
    such a burden on the metadata service that it even became entirely unresponsive
    to requests to add capacity. The on-call engineers were forced to explicitly block
    requests to the metadata service just to relieve enough pressure to allow them
    to manually scale up.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, nearly five hours after the initial network hiccup that triggered the
    incident, normal operations resumed, putting an end to what must have been a long
    night for all involved.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keeping on Ticking: Why Resilience Matters'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, what was the root cause of Amazon’s outage? Was it the network disruption?
    Was it the storage servers’ enthusiastic retry behavior? Was it the metadata service’s
    response time, or maybe its limited capacity?
  prefs: []
  type: TYPE_NORMAL
- en: 'Clearly, what happened that early morning didn’t have a single root cause.
    Failures in complex systems never do.^([3](ch09.xhtml#idm45983623929384)) Rather,
    the system failed as complex systems do: with a failure in a subsystem, which
    triggered a latent fault in another subsystem causing *it* to fail, followed by
    another, and another, until eventually the entire system went down. What’s interesting,
    though, is that if any of the components in our story—the network, the storage
    servers, the metadata service—had been able to isolate and recover from failures
    elsewhere in the system, the overall system likely would have recovered without
    human intervention.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, this is just one example of a common pattern. Complex systems
    fail in complex (and often surprising) ways, but they don’t fail all at once:
    they fail one subsystem at a time. For this reason, resilience patterns in complex
    systems take the form of bulwarks and safety valves that work to isolate failures
    at component boundaries. Frequently, a failure contained is a failure avoided.'
  prefs: []
  type: TYPE_NORMAL
- en: This property, the measure of a system’s ability to withstand and recover from
    errors and failures, is its *resilience*. A system can be considered *resilient*
    if it can continue operating correctly—possibly at a reduced level—rather than
    failing completely when one of its subsystems fails.
  prefs: []
  type: TYPE_NORMAL
- en: What Does It Mean for a System to Fail?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For want of a nail the shoe was lost,
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: for want of a shoe the horse was lost;
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: for want of a horse the rider was lost;
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: all for want of care about a horse-shoe nail.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Benjamin Franklin, The Way to Wealth (1758)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If we want to know what it means for a system to fail, we first have to ask
    what a “system” is.
  prefs: []
  type: TYPE_NORMAL
- en: This is important. Bear with me.
  prefs: []
  type: TYPE_NORMAL
- en: 'By definition, a *system* is a set of components that work together to accomplish
    an overall goal. So far, so good. But here’s the important part: each component
    of a system—a *subsystem*—is also a complete system unto itself, that in turn
    is composed of still smaller subsystems, and so on, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a car, for example. Its engine is one of dozens of subsystems, but it—like
    all the others—is also a very complex system with a number of subsystems of its
    own, including a cooling subsystem, which includes a thermostat, which includes
    a temperature switch, and so on. That’s just some of thousands of components and
    subcomponents and sub-subcomponents. It’s enough to make the mind spin: so many
    things that can fail. But what happens when they do?'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned earlier—and discussed in some depth in [Chapter 6](ch06.xhtml#chapter_6)—failures
    of complex systems don’t just happen all at once. They unravel in predictable
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: All systems contain *faults*, which we lovingly refer to as “bugs” in the software
    world. A tendency for a temperature switch in a car engine to stick would be a
    fault. So would the metadata service’s limited capacity and the storage server’s
    retry behavior in the DynamoDB case study.^([5](ch09.xhtml#idm45983623900600))
    Under the right conditions, a fault can be exercised to produce an *error*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An *error* is any discrepancy between the system’s intended and actual behavior.
    Many errors can be caught and handled appropriately, but if they’re not they can—singly
    or in accumulation—give rise to a *failure*. A stuck temperature switch in a car
    engine’s thermostat is an error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, a system can be said to be experiencing a *failure* when it’s no longer
    able to provide correct service.^([6](ch09.xhtml#idm45983623894792)) A temperature
    switch that no longer responds to high temperatures can be said to have failed.
    A failure at the subsystem level becomes a fault at the system level.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This last bit bears repeating: *a failure at the subsystem level becomes a
    fault at the system level.* A stuck temperature switch causes a thermostat to
    fail, preventing coolant from flowing through the radiator, raising the temperature
    of the engine, causing it to stall and the car to stop.^([7](ch09.xhtml#idm45983623892568))'
  prefs: []
  type: TYPE_NORMAL
- en: That’s how systems fail. It starts with the failure of one component—one subsystem—which
    causes an error in one or more components that interact with it, and ones that
    interact with that, and so on, propagating upward until the entire system fails.
  prefs: []
  type: TYPE_NORMAL
- en: 'This isn’t just academic. Knowing how complex systems fail—one component at
    a time—makes the means of resisting failures clearer: if a fault can be contained
    before it propagates all the way to the system level, the system may be able to
    recover (or at least fail on its own terms).'
  prefs: []
  type: TYPE_NORMAL
- en: Building for Resilience
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a perfect world it would be possible to rid a system of every possible fault,
    but this isn’t realistic, and it’s wasteful and unproductive to try. By instead
    assuming that all components are destined to fail eventually—which they absolutely
    are—and designing them to respond gracefully to errors when they do occur, you
    can produce a system that’s functionally healthy even when some of its components
    are not.
  prefs: []
  type: TYPE_NORMAL
- en: There are lots of ways to increase the resiliency of a system. Redundancy, such
    as deploying multiple components of the same type, is probably the most common
    approach. Specialized logic like circuit breakers and request throttles can be
    used to isolate specific kinds of errors, preventing them from propagating. Faulty
    components can even be reaped—or intentionally allowed to fail—to benefit the
    health of the larger system.
  prefs: []
  type: TYPE_NORMAL
- en: Resilience is a particularly rich subject. We’ll explore several of these approaches—and
    more—over the remainder of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Cascading Failures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The reason the DynamoDB case study is so appropriate is that it demonstrates
    so many different ways that things that can go wrong at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Take, for example, how the failure of a group of storage servers caused requests
    to the metadata service to time out, which in turn caused more storage servers
    to fail, which increased the pressure on the metadata service, and so on. This
    is an excellent example of a particular—and particularly common—failure mode known
    as a *cascading failure*. Once a cascading failure has begun, it tends to spread
    very quickly, often on the order of a few minutes.
  prefs: []
  type: TYPE_NORMAL
- en: The mechanisms of cascading failures can vary a bit, but one thing they share
    is some kind of positive feedback mechanism. One part of a system experiences
    a local failure—a reduction in capacity, an increase in latency, etc.—that causes
    other components to attempt to compensate for the failed component in a way that
    exacerbates the problem, eventually leading to the failure of the entire system.
  prefs: []
  type: TYPE_NORMAL
- en: The classic cause of cascading failures is overload, illustrated in [Figure 9-1](#image_ch09_cascading_failures).
    This occurs when one or more nodes in a set fails, causing the load to be catastrophically
    redistributed to the survivors. The increase in load overloads the remaining nodes,
    causing them to fail from resource exhaustion, taking the entire system down.
  prefs: []
  type: TYPE_NORMAL
- en: '![cngo 0901](Images/cngo_0901.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-1\. Server overload is a common cause of cascade failures; each server
    handles 600 requests per second, so when server B fails, server A is overloaded
    and also fails
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The nature of positive feedback often makes it very difficult to scale your
    way out of a cascading failure by adding more capacity. New nodes can be overwhelmed
    as quickly as they come online, often contributing the feedback that took the
    system down in the first place. Sometimes, the only fix is to take your entire
    service down—perhaps by explicitly blocking the problematic traffic—in order to
    recover, and then slowly reintroduce load.
  prefs: []
  type: TYPE_NORMAL
- en: But how do you prevent cascading failures in the first place? This will be the
    subject of the next section (and, to some extent, most of this chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Preventing Overload
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every service, however well-designed and implemented, has its functional limitations.
    This is particularly evident in services intended to handle and respond to client
    requests.^([8](ch09.xhtml#idm45983623867528)) For any such service there exists
    some request frequency, a threshold beyond which bad things will start to happen.
    So, how do we keep a large number of requests from accidentally (or intentionally!)
    bringing our service down?
  prefs: []
  type: TYPE_NORMAL
- en: 'Ultimately, a service that finds itself in such a situation has no choice but
    to reject—partially or entirely—some number of requests. There are two main strategies
    for doing this:'
  prefs: []
  type: TYPE_NORMAL
- en: Throttling
  prefs: []
  type: TYPE_NORMAL
- en: Throttling is a relatively straightforward strategy that kicks in when requests
    come in faster than some predetermined frequency, typically, by just refusing
    to handle them. This is often used as a preventative measure by ensuring that
    no particular user consumes more resources than they would reasonably require.
  prefs: []
  type: TYPE_NORMAL
- en: Load shedding
  prefs: []
  type: TYPE_NORMAL
- en: Load shedding is a little more adaptive. Services using this strategy intentionally
    drop (“shed”) some proportion of load as they approach overload conditions by
    either refusing requests or falling back into a degraded mode.
  prefs: []
  type: TYPE_NORMAL
- en: These strategies aren’t mutually exclusive; a service may choose to employ either
    or both of them, according to its needs.
  prefs: []
  type: TYPE_NORMAL
- en: Throttling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we discussed in [Chapter 4](ch04.xhtml#chapter_4), a throttle pattern works
    a lot like the throttle in a car, except that instead of limiting the amount of
    fuel entering an engine, it limits the number of requests that a user (human or
    otherwise) can make to a service in a set period of time.
  prefs: []
  type: TYPE_NORMAL
- en: The general-purpose throttle example that we provided in [“Throttle”](ch04.xhtml#section_ch04_throttle)
    was relatively simple, and effectively global, at least as written. However, throttles
    are also frequently applied on a per-user basis to provide something like a usage
    quota, so that no one caller can consume too much of a service’s resources.
  prefs: []
  type: TYPE_NORMAL
- en: In the following, we demonstrate a throttle implementation that, while still
    using a token bucket,^([9](ch09.xhtml#idm45983623725192)) is otherwise quite different
    in several ways.
  prefs: []
  type: TYPE_NORMAL
- en: First, instead of having a single bucket that’s used to gate all incoming requests,
    the following implementation throttles on a per-user basis, returning a function
    that accepts a “key” parameter, that’s meant to represent a username or some other
    unique identifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, rather than attempting to “replay” a cached value when imposing a throttle
    limit, the returned function returns a Boolean that indicates when a throttle
    has been imposed. Note that the throttle doesn’t return an `error` when it’s activated:
    throttling isn’t an error condition, so we don’t treat it as one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, and perhaps most interestingly, it doesn’t actually use a timer (a
    `time.Ticker`) to explicitly add tokens to buckets on some regular cadence. Rather,
    it refills buckets on demand, based on the time elapsed between requests. This
    strategy means that we don’t have to dedicate background processes to filling
    buckets until they’re actually used, which will scale much more effectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Like the example in [“Throttle”](ch04.xhtml#section_ch04_throttle), this `Throttle`
    function accepts a function literal that conforms to the `Effector` contract,
    plus some values that define the size and refill rate of the underlying token
    bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of returning another `Effector`, however, it returns a `Throttled` function,
    which in addition to wrapping the effector with the throttling logic adds a “key”
    input parameter, which represents a unique user identifier, and a Boolean return
    value, which indicates whether the function has been throttled (and therefore
    not executed).
  prefs: []
  type: TYPE_NORMAL
- en: As interesting as you may (or may not) find the `Throttle` code, it’s still
    not production ready. First of all, it’s not entirely safe for concurrent use.
    A production implementation will probably want to lock on the `record` values,
    and possibly the `bucket` map. Second, there’s no way to purge old records. In
    production, we’d probably want to use something like an LRU cache, like the one
    we described in [“Efficient Caching Using an LRU Cache”](ch07.xhtml#section_ch07_lru_cache),
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following, we show a toy example of how `Throttle` might be used in
    a RESTful web service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The previous code creates a small web service with a single (somewhat contrived)
    endpoint at `/hostname` that returns the service’s hostname. When the program
    is run, the `throttled` var is created by wrapping the `getHostname` function—which
    provides the actual service logic—by passing it to `Throttle`, which we defined
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: When the router receives a request for the `/hostname` endpoint, the request
    is forwarded to the `throttledHandler` function, which performs the calls to `throttled`,
    receiving a `bool` indicating throttling status, the hostname `string`, and an
    `error` value. A defined error causes us to return a `500 Internal Server Error`,
    and a throttled request gets a `429 Too Many Requests`. If all else goes well,
    we return the hostname and a status `200 OK`.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the bucket values are stored locally, so this implementation can’t
    really be considered production-ready either. If you want this to scale out, you
    might want to store the record values in an external cache of some kind so that
    multiple service replicas can share them.
  prefs: []
  type: TYPE_NORMAL
- en: Load shedding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s an unavoidable fact of life that, as load on a server increases beyond
    what it can handle, something eventually has to give.
  prefs: []
  type: TYPE_NORMAL
- en: '*Load shedding* is a technique used to predict when a server is approaching
    that saturation point and then mitigating the saturation by dropping some proportion
    of traffic in a controlled fashion. Ideally, this will prevent the server from
    overloading and failing health checks, serving with high latency, or just collapsing
    in a graceless, uncontrolled failure.'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike quota-based throttling, load shedding is reactive, typically engaging
    in response to depletion of a resource like CPU, memory, or request-queue depth.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps the most straightforward form of load shedding is a per-task throttling
    that drops requests when one or more resources exceed a particular threshold.
    For example, if your service provides a RESTful endpoint, you might choose to
    to return an HTTP 503 (service unavailable). The `gorilla/mux` web toolkit, which
    we found very effective in [Chapter 5](ch05.xhtml#chapter_5) in the section [“Building
    an HTTP Server with gorilla/mux”](ch05.xhtml#section_ch05_building_with_gorilla),
    makes this fairly straightforward by [supporting “middleware” handler functions](https://oreil.ly/GTxes)
    that are called on every request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Gorilla Mux middlewares are called on every request, each taking a request,
    doing something with it, and passing it down to another middleware or the final
    handler. This makes them perfect for implementing general request logging, header
    manipulation, `ResponseWriter` hijacking, or in our case, resource-reactive load
    shedding.
  prefs: []
  type: TYPE_NORMAL
- en: Our middleware uses the fictional `CurrentQueueDepth()` (your actual function
    will depend on your implementation) to check the current queue depth, and rejects
    requests with an HTTP 503 (service unavailable) if the value is too high. More
    sophisticated implementations might even be smarter about choosing which work
    is dropped by prioritizing particularly important requests.
  prefs: []
  type: TYPE_NORMAL
- en: Graceful service degradation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Resource-sensitive load shedding works well, but in some applications it’s possible
    to act a little more gracefully by significantly decreasing the quality of responses
    when the service is approaching overload. Such *graceful degradation* takes the
    concept of load shedding one step further by strategically reducing the amount
    of work needed to satisfy each request instead of just rejecting requests.
  prefs: []
  type: TYPE_NORMAL
- en: There are as many ways of doing this as there are services, and not every service
    can be degraded in a reasonable manner, but common approaches include falling
    back on cached data or less expensive—if less precise—algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Play It Again: Retrying Requests'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a request receives an error response, or doesn’t receive a response at
    all, it should just try again, right? Well, kinda. Retrying makes sense, but it’s
    a lot more nuanced than that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take this snippet for example, a version of which I’ve found in a production
    system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: It seems seductively straightforward, doesn’t it? It *will* repeat failed requests,
    but that’s also *exactly* what it will do. So when this logic was deployed to
    a few hundred servers and the service to which it was issuing requests went down,
    the entire system went with it. A review of the service metrics, shown in [Figure 9-2](#image_ch09_retry_storm),
    revealed this.
  prefs: []
  type: TYPE_NORMAL
- en: '![cngo 0902](Images/cngo_0902.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-2\. The anatomy of a “retry storm”
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It seems that when the downstream service failed, our service—every single instance
    of it—entered its retry loop, making *thousands* of requests per second and bringing
    the network to its knees so severely that we were forced to essentially restart
    the entire system.
  prefs: []
  type: TYPE_NORMAL
- en: This is actually a very common kind of cascading failure known as a *retry storm*.
    In a retry storm, well-meaning logic intended to add resilience to a component,
    acts against the larger system. Very often, even when the conditions that caused
    the downstream service to go down are resolved, it can’t come back up because
    it’s instantly brought under too much load.
  prefs: []
  type: TYPE_NORMAL
- en: But, retries are a good thing, right?
  prefs: []
  type: TYPE_NORMAL
- en: Yes, but whenever you implement retry logic, you should always include a *backoff
    algorithm*, which we’ll conveniently discuss in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Backoff Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When a request to a downstream service fails for any reason, “best” practice
    is to retry the request. But how long should you wait? If you wait too long, important
    work may be delayed. Too little and you risk overwhelming the target, the network,
    or both.
  prefs: []
  type: TYPE_NORMAL
- en: The common solution is to implement a backoff algorithm that introduces a delay
    between retries to reduce the frequency of attempts to a safe and acceptable rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a variety of backoff algorithms available, the simplest of which
    is to include a short, fixed-duration pause between retries, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In the previous snippet, `SendRequest` is used to issue a request, returning
    string and error values. However, if `err` isn’t `nil`, the code enters a loop,
    sleeping for two seconds before retrying, repeating indefinitely until it receives
    a nonerror response.
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 9-3](#image_ch09_backoffs_1), we illustrate the number of requests
    generated by 1,000 simulated instances using this method.^([10](ch09.xhtml#idm45983622826936))
    As you can see, while the fixed-delay approach might reduce the request count
    compared to having no backoff at all, the overall number of requests is still
    quite consistently high.
  prefs: []
  type: TYPE_NORMAL
- en: '![cngo 0903](Images/cngo_0903.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-3\. Requests/second of 1,000 simulated instances using a two-second
    retry delay
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A fixed-duration backoff delay might work fine if you have a very small number
    of retrying instances, but it doesn’t scale very well, since a sufficient number
    of requestors can still overwhelm the network.
  prefs: []
  type: TYPE_NORMAL
- en: However, we can’t always assume that any given service will have a small enough
    number of instances not to overwhelm the network with retries, or that our service
    will even be the only one retrying. For this reason, many backoff algorithms implement
    an *exponential backoff*, in which the durations of the delays between retries
    roughly doubles with each attempt up to some fixed maximum.
  prefs: []
  type: TYPE_NORMAL
- en: 'A very common (but flawed, as you’ll soon see) exponential backoff implementation
    might look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this snippet, we specify a starting duration, `base`, and a fixed maximum
    duration, `cap`. In the loop, the value of `backoff` starts at `base` and doubles
    each iteration to a maximum value of `cap`.
  prefs: []
  type: TYPE_NORMAL
- en: You would think that this logic would help to mitigate the network load and
    retry request burden on downstream services. Simulating this implementation for
    1,000 nodes, however, tells another story, illustrated in [Figure 9-4](#image_ch09_backoffs_2).
  prefs: []
  type: TYPE_NORMAL
- en: '![cngo 0904](Images/cngo_0904.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-4\. Requests/second of 1,000 simulated instances using an exponential
    backoff
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It would seem that having 1,000 nodes with exactly the same retry schedule still
    isn’t optimal, since the retries are now clustering, possibly generating enough
    load in the process to cause problems. So, in practice, pure exponential backoff
    doesn’t necessarily help as much we’d like.
  prefs: []
  type: TYPE_NORMAL
- en: 'It would seem that we need some way to spread the spikes out so that the retries
    occur at a roughly constant rate. The solution is to include an element of randomness,
    called *jitter*. Adding jitter to our previous backoff function results in something
    like the snippet here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Simulating running this code on 1,000 nodes produces the pattern presented in
    [Figure 9-5](#image_ch09_backoffs_3).
  prefs: []
  type: TYPE_NORMAL
- en: '![cngo 0905](Images/cngo_0905.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-5\. Requests/second of 1,000 simulated instances using an exponential
    backoff with jitter
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The `rand` package’s top-level functions produce a deterministic sequence of
    values each time the program is run. If you don’t use the `rand.Seed` function
    to provide a new seed value, they behave as if seeded by `rand.Seed(1)` and always
    produce the same “random” sequence of numbers.
  prefs: []
  type: TYPE_NORMAL
- en: When we use exponential backoff with jitter, the number of retries decreases
    over a short interval—so as not to overstress services that are trying to come
    up—and spreads them out over time so that they occur at an approximately constant
    rate.
  prefs: []
  type: TYPE_NORMAL
- en: Who would have thought there was more to retrying requests than retrying requests?
  prefs: []
  type: TYPE_NORMAL
- en: Circuit Breaking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We first introduced the Circuit Breaker pattern in [Chapter 4](ch04.xhtml#chapter_4)
    as a function that degrades potentially failing method calls as a way to prevent
    larger or cascading failures. That definition still holds, and because we’re not
    going to extend or change it much, we won’t dig into it in *too* much detail here.
  prefs: []
  type: TYPE_NORMAL
- en: To review, the Circuit Breaker pattern tracks the number of consecutive failed
    requests made to a downstream component. If the failure count passes a certain
    threshold, the circuit is “opened,” and all attempts to issue additional requests
    fail immediately (or return some defined fallback). After a waiting period, the
    circuit automatically “closes,” resuming its normal state and allowing requests
    to be made normally.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Not all resilience patterns are defensive.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes it pays to be a good neighbor.
  prefs: []
  type: TYPE_NORMAL
- en: A properly applied Circuit Breaker pattern can make the difference between system
    recovery and cascading failure. In addition to the obvious benefits of not wasting
    resources or clogging the network with doomed requests, a circuit breaker (particularly
    one with a backoff function) can give a malfunctioning service enough room to
    recover, allowing it to come back up and restore correct service.
  prefs: []
  type: TYPE_NORMAL
- en: The Circuit Breaker pattern was covered in some detail in [Chapter 4](ch04.xhtml#chapter_4),
    so that’s all we’re going to say about it here. Take a look at [“Circuit Breaker”](ch04.xhtml#section_ch04_circuit_breaker)
    for more background and code examples. The addition of jitter to the example’s
    backoff function is left as an exercise for the reader.^([11](ch09.xhtml#idm45983622584440))
  prefs: []
  type: TYPE_NORMAL
- en: Timeouts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The importance of timeouts isn’t always appreciated. However, the ability for
    a client to recognize when a request is unlikely to be satisfied allows the client
    to release resources that it—and any upstream requestors it might be acting on
    behalf of—might otherwise hold on to. This holds just as true for a service, which
    may find itself holding onto requests until long after a client has given up.
  prefs: []
  type: TYPE_NORMAL
- en: For example, imagine a basic service that queries a database. If that database
    should suddenly slow so that queries take a few seconds to complete, requests
    to the service—each holding onto a database connection—could accumulate, eventually
    depleting the connection pool. If the database is shared, it could even cause
    other services to fail, resulting in a cascading failure.
  prefs: []
  type: TYPE_NORMAL
- en: If the service had timed out instead of holding on to the database, it could
    have degraded service instead of failing outright.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, if you think you’re going to fail, fail fast.
  prefs: []
  type: TYPE_NORMAL
- en: Using Context for service-side timeouts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We first introduced `context.Context` back in [Chapter 4](ch04.xhtml#chapter_4)
    as Go’s idiomatic means of carrying deadlines and cancellation signals between
    processes.^([12](ch09.xhtml#idm45983622576120)) If you’d like a refresher, or
    just want to put yourself in the right frame of mind before continuing, go ahead
    and take a look at [“The Context Package”](ch04.xhtml#section_ch04_context).
  prefs: []
  type: TYPE_NORMAL
- en: You might also recall that later in the same chapter, in [“Timeout”](ch04.xhtml#section_ch04_timeout),
    we covered the *Timeout* pattern, which uses `Context` to not only allow a process
    to stop waiting for an answer once it’s clear that a result may not be coming,
    but to also notify other functions with derived `Context`s to stop working and
    release any resources that they might also be holding on to.
  prefs: []
  type: TYPE_NORMAL
- en: This ability to cancel not just local functions, but subfunctions, is so powerful
    that it’s generally considered good form for functions to accept a `Context` value
    if they have the potential to run longer than a caller might want to wait, which
    is almost always true if the call traverses a network.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, there are many excellent samples of `Context`-accepting functions
    scattered throughout Go’s standard library. Many of these can be found in the
    `sql` package, which includes `Context`-accepting versions of many of its functions.
    For example, the `DB` struct’s `QueryRow` method has an equivalent `QueryRowContext`
    that accepts a `Context` value.
  prefs: []
  type: TYPE_NORMAL
- en: 'A function that uses this technique to provide the username of a user based
    on an ID value might look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `UserName` function accepts a `context.Context` and an `id` integer, but
    it also creates its own derived `Context` with a rather long timeout. This approach
    provides a default timeout that automatically releases any open connections after
    15 seconds—longer than many clients are likely to be willing to wait—while also
    being responsive to cancellation signals from the caller.
  prefs: []
  type: TYPE_NORMAL
- en: 'The responsiveness to outside cancellation signals can be quite useful. The
    `http` framework provides yet another excellent example of this, as demonstrated
    in the following `UserGetHandler` HTTP handler function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In `UserGetHandler`, the first thing we do is retrieve the request’s `Context`
    via its `Context` method. Conveniently, this `Context` is canceled when the client’s
    connection closes, when the request is canceled (with HTTP/2), or when the `ServeHTTP`
    method returns.
  prefs: []
  type: TYPE_NORMAL
- en: From this we create a derived context, applying our own explicit timeout, which
    will cancel the `Context` after 10 seconds, no matter what.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the derived context is passed to the `UserName` function, we are able
    to draw a direct causative line between closing the HTTP request and closing the
    database connection: if the request’s `Context` closes, all derived `Context`s
    close as well, ultimately ensuring that all open resources are released as well
    in a loosely coupled manner.'
  prefs: []
  type: TYPE_NORMAL
- en: Timing out HTTP/REST client calls
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Back in [“A Possible Pitfall of Convenience Functions”](ch08.xhtml#sidebar_ch08_convenience_functions),
    we presented one of the pitfalls of the `http` “convenience functions” like `http.Get`
    and `http.Post`: that they use the default timeout. Unfortunately, the default
    timeout value is `0`, which Go interprets as “no timeout.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'The mechanism we presented at the time for setting timeouts for client methods
    was to create a custom `Client` value with a nonzero `Timeout` value, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This works perfectly fine, and in fact, will cancel a request in exactly the
    same way as if its `Context` is canceled. But what if you want to use an existing
    or derived `Context` value? For that you’ll need access to the underlying `Context`,
    which you can get by using `http.NewRequestWithContext`, the `Context`-accepting
    equivalent of `http.NewRequest`, which allows a programmer to specify a `Context`
    that controls the entire lifetime of the request and its response.
  prefs: []
  type: TYPE_NORMAL
- en: 'This isn’t as much of a divergence as it might seem. In fact, looking at the
    source code for the `Get` method on the `http.Client` shows that under the covers,
    it’s just using `NewRequest`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the standard `Get` method calls `NewRequest` to create a `*Request`
    value, passing it the method name and URL (the last parameter accepts an optional
    `io.Reader` for the request body, which we don’t need here). A call to the `Do`
    function executes the request proper.
  prefs: []
  type: TYPE_NORMAL
- en: Not counting an error check and the return, the entire method consists of just
    one call. It would seem that if we wanted to implement similar functionality that
    also accepts a `Context` value, we could do so without much hassle.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to do this might be to implement a `GetContext` function that accepts
    a `Context` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Our new `GetContext` function is functionally identical to the canonical `Get`,
    except that it also accepts a `Context` value, which it uses to call `http.NewRequestWithContext`
    instead of `http.NewRequest`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using our new `ClientContext` would be very similar to using a standard `http.Client`
    value, except instead of calling `client.Get` we’d call `client.GetContext` (and
    pass along a `Context` value, of course):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'But does it work? It’s not a *proper* test with a testing library, but we can
    manually kick the tires by setting the deadline to `0` and running it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: And it would seem that it does! Excellent.
  prefs: []
  type: TYPE_NORMAL
- en: Timing out gRPC client calls
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Just like `http.Client`, gRPC clients default to “no timeout,” but also allow
    timeouts to be explicitly set.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in [“Implementing the gRPC client”](ch08.xhtml#section_ch08_impl_grpc_client),
    gRPC clients typically use the `grpc.Dial` function to establish a connection
    to a client, and that a list of `grpc.DialOption` values—constructed via functions
    like `grpc.WithInsecure` and `grpc.WithBlock`—can be passed to it to configure
    how that connection is set up.
  prefs: []
  type: TYPE_NORMAL
- en: 'Among these options is `grpc.WithTimeout`, which can be used to configure a
    client dialing timeout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: However, while `grpc.WithTimeout` might seem convenient on the face of it, it’s
    actually been deprecated for some time, largely because its mechanism is inconsistent
    (and redundant) with the preferred `Context` timeout method. We show it here for
    the sake of completion.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The `grpc.WithTimeout` option is deprecated and will eventually be removed.
    Use `grpc.DialContext` and `context.WithTimeout` instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, the preferred method of setting a gRPC dialing timeout is the very
    convenient (for us) `grpc.DialContext` function, which allows us to use (or reuse)
    a `context.Context` value. This is actually doubly useful, because gRPC service
    methods accept a `Context` value anyway, so there really isn’t even any additional
    work to be done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As advertised, `TimeoutKeyValueGet` uses `grpc.DialContext`—to which we pass
    a `context.Context` value with a 5-second timeout—instead of `grpc.Dial`. The
    `opts` list is otherwise identical except, obviously, that it no longer includes
    `grpc.WithTimeout`.
  prefs: []
  type: TYPE_NORMAL
- en: Note the `client.Get` method call. As we mentioned previously, gRPC service
    methods accept a `Context` parameter, so we simply reuse the existing one. Importantly,
    reusing the same `Context` value will constrain both operations under the same
    timeout calculation—a `Context` will time out regardless of how it’s used—so be
    sure to take that into consideration when planning your timeout values.
  prefs: []
  type: TYPE_NORMAL
- en: Idempotence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we discussed at the top of [Chapter 4](ch04.xhtml#chapter_4), cloud native
    applications by definition exist in and are subject to all of the idiosyncrasies
    of a networked world. It’s a plain fact of life that networks—all networks—are
    unreliable, and messages sent across them don’t always arrive at their destination
    on time (or at all).
  prefs: []
  type: TYPE_NORMAL
- en: What’s more, if you send a message but don’t get a response, you have no way
    to know what happened. Did the message get lost on its way to the recipient? Did
    the recipient get the message, and the response get lost? Maybe everything is
    working fine, but the round trip is just taking a little longer than usual?
  prefs: []
  type: TYPE_NORMAL
- en: In such a situation, the only option is to send the message again. But it’s
    not enough to cross your fingers and hope for the best. It’s important to plan
    for this inevitability by making it safe to resend messages by designing the functions
    for *idempotence*.
  prefs: []
  type: TYPE_NORMAL
- en: You might recall that we briefly introduced the concept of idempotence in [“What
    Is Idempotence and Why Does It Matter?”](ch05.xhtml#section_ch05_idempotence),
    in which we defined an idempotent operation as one that has the same effect after
    multiple applications as a single application. As the designers of HTTP understood,
    it also happens to be an important property of any cloud native API that guarantees
    that any communication can be safely repeated (see [“The Origins of Idempotence
    on the Web”](#sidebar_ch09_origins_of_idempotence) for a bit on that history).
  prefs: []
  type: TYPE_NORMAL
- en: The actual means of achieving idempotence will vary from service to service,
    but there are some consistent patterns that we’ll review in the remainder of this
    section.
  prefs: []
  type: TYPE_NORMAL
- en: How do I make my service idempotent?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Idempotence isn’t baked into the logic of any particular framework. Even in
    HTTP—and by extension, REST—idempotence is a matter of convention and isn’t explicitly
    enforced. There’s nothing stopping you from—by oversight or on purpose—implementing
    a nonidempotent GET if you really want to.^([16](ch09.xhtml#idm45983621554584))
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the reasons that idempotence is sometimes so tricky is because it relies
    on logic built into the core application, rather than at the REST or gRPC API
    layer. For example, if back in [Chapter 5](ch05.xhtml#chapter_5) we had wanted
    to make our key-value store consistent with traditional CRUD (create, read, update,
    and delete) operations (and therefore *not* idempotent) we might have done something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This CRUD-like service implementation may be entirely well-meaning, but if
    any of these methods have to be repeated the result would be an error. What’s
    more, there’s also a fair amount of logic involved in checking against the current
    state which wouldn’t be necessary in an equivalent idempotent implementation like
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This version is a *lot* simpler, in more than one way. First, we no longer need
    separate “create” and “update” operations, so we can combine these into a single
    `Set` function. Also, not having to check the current state with each operation
    reduces the logic in each method, a benefit that continues to pay dividends as
    the service increases in complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, if an operation has to be repeated, it’s no big deal. For both the
    `Set` and `Delete` functions, multiple identical calls will have the same result.
    They are idempotent.
  prefs: []
  type: TYPE_NORMAL
- en: What about scalar operations?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: “So,” you might say, “that’s all well and good for operations that are either
    *done* or *not done*, but what about more complex operations? Operations on scalar
    values, for example?”
  prefs: []
  type: TYPE_NORMAL
- en: 'That’s a fair question. After all, it’s one thing to PUT a thing in a place:
    it’s either been PUT, or it hasn’t. All you have to do is not return an error
    for re-PUTs. Fine.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But what about an operation like “add $500 to account 12345”? Such a request
    might carry a JSON payload that looks something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Repeated applications of this operation would lead to an extra $500 going to
    account 12345, and while the owner of the account might not mind so much, the
    bank probably would.
  prefs: []
  type: TYPE_NORMAL
- en: 'But consider what happens when we add a `transactionID` value to our JSON payload:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: It may require some more bookkeeping, but this approach provides a workable
    solution to our dilemma. By tracking `transactionID` values, the recipient can
    safely identify and reject duplicate transactions. Idempotence achieved!
  prefs: []
  type: TYPE_NORMAL
- en: Service Redundancy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Redundancy—the duplication of critical components or functions of a system with
    the intention of increasing reliability of the system—is often the first line
    of defense when it comes to increasing resilience in the face of failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve already discussed one particular kind of redundancy—messaging redundancy,
    also known as “retries”—in [“Play It Again: Retrying Requests”](#section_ch09_retries).
    In this section, however, we’ll consider the value of replicating critical system
    components so that if any one fails, one or more others are there to pick up the
    slack.'
  prefs: []
  type: TYPE_NORMAL
- en: In a public cloud, this would mean deploying your component to multiple server
    instances, ideally across multiple zones or even across multiple regions. In a
    container orchestration platform like Kubernetes, this may even just be a matter
    of setting your replica count to a value greater than one.
  prefs: []
  type: TYPE_NORMAL
- en: As interesting as this subject is, however, we won’t actually spend too much
    time on it. Service replication is an architectural subject that’s been thoroughly
    covered in many other sources.^([17](ch09.xhtml#idm45983621184232)) This is supposed
    to be a Go book, after all. But still, we’d be remiss to have an entire chapter
    about resilience and not even mention it.
  prefs: []
  type: TYPE_NORMAL
- en: Designing for Redundancy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The effort involved in designing a system so that its functions can be replicated
    across multiple instances can yield significant dividends. But exactly how much?
    Well…a lot. You can feel free to take a look at the following box if you’re interested
    in the math, but if you don’t, you can just trust me on this one.
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Very often, the amount of load that a service is subjected to varies over time.
    The textbook example is the user-facing web service where load increases during
    the day and decreases at night. If such a service is built to handle the peak
    load, it’s wasting time and money at night. If it’s built only to handle the nighttime
    load, it will be overburdened in the daytime.
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling is a technique that builds on the idea of load balancing by automatically
    adding or removing resources—be they cloud server instances or Kubernetes pods—to
    dynamically adjust capacity to meet current demand. This ensures that your service
    can meet a variety of traffic patterns, anticipated or otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: As an added bonus, applying autoscaling to your cluster can save money by right-sizing
    resources according to service requirements.
  prefs: []
  type: TYPE_NORMAL
- en: All major cloud providers provide a mechanism for scaling server instances,
    and most of their managed services implicitly or explicitly support autoscaling.
    Container orchestration platforms like Kubernetes also include support for autoscaling,
    both for the number of pods (horizontal autoscaling) and their CPU and memory
    limits (vertical autoscaling).
  prefs: []
  type: TYPE_NORMAL
- en: 'Autoscaling mechanics vary considerably between cloud providers and orchestration
    platforms, so a detailed discussion of how to gather metrics and configure things
    like predictive autoscaling is beyond the scope of this book. However, some key
    points to remember:'
  prefs: []
  type: TYPE_NORMAL
- en: Set reasonable maximums, so that unusually large spikes in demand (or, heaven
    forbid, cascade failures) don’t completely blow your budget. The throttling and
    load shedding techniques that we discussed in [“Preventing Overload”](#section_ch09_preventing_overload)
    are also useful here.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize startup times. If you’re using server instances, bake machine images
    beforehand to minimize configuration time at startup. This is less of an issue
    on Kubernetes, but container images should still be kept small and startup times
    reasonably short.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No matter how fast your startup, scaling takes a nonzero amount of time. Your
    service should have *some* wiggle room without having to scale.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As we discussed in [“Scaling Postponed: Efficiency”](ch07.xhtml#section_ch07_efficiency),
    the best kind of scaling is the kind that never needs to happen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Healthy Health Checks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [“Service Redundancy”](#section_ch09_redundancy), we briefly discussed the
    value of redundancy—the duplication of critical components or functions of a system
    with the intention of increasing overall system reliability—and its value for
    improving the resilience of a system.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple service instances means having a load-balancing mechanism—a service
    mesh or dedicated load balancer—but what happens when a service instance goes
    bad? Certainly, we don’t want the load balancer to continue sending traffic its
    way. So what do we do?
  prefs: []
  type: TYPE_NORMAL
- en: Enter the *health check*. In its simplest and most common form, a health check
    is implemented as an API endpoint that clients—load balancers, as well as monitoring
    services, service registries, etc.—can use to ask a service instance if it’s alive
    and healthy.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a service might provide an HTTP endpoint (`/health` and `/healthz`
    are common naming choices) that returns a `200 OK` if the replica is healthy,
    and a `503 Service Unavailable` when it’s not. More sophisticated implementations
    can even return different status codes for different states: HashiCorp’s Consul
    service registry interprets any `2XX` status as a success, a `429 Too Many Requests`
    as a warning, and anything else as a failure.'
  prefs: []
  type: TYPE_NORMAL
- en: Having an endpoint that can tell a client when a service instance is healthy
    (or not) sounds great and all, but it invites the question of what, exactly, does
    it mean for an instance to be “healthy”?
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Health checks are like bloom filters. A failing health check means a service
    isn’t up, but a health check passing means the service is *probably* “healthy.”
    (Credit: Cindy Sridharan^([20](ch09.xhtml#idm45983621034232)))'
  prefs: []
  type: TYPE_NORMAL
- en: What Does It Mean for an Instance to Be “Healthy”?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We use the word “healthy” in the context of services and service instances,
    but what exactly do we mean when we say that? Well, as is so often the case, there’s
    a simple answer and a complex answer. Probably a lot of answers in between, too.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start with the simple answer. Reusing an existing definition, an instance
    is considered “healthy” when it’s “available.” That is, when it’s able to provide
    correct service.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, it isn’t always so clear cut. What if the instance itself is
    functioning as intended, but a downstream dependency is malfunctioning? Should
    a health check even make that distinction? If so, should the load balancer behave
    differently in each case? Should an instance be reaped and replaced if it’s not
    the one at fault, particularly if all service replicas are affected?
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, there aren’t any easy answers to these questions, so instead
    of answers, I’ll offer the next best thing: a discussion of the three most common
    approaches to health checking and their associated advantages and disadvantages.
    Your own implementations will depend on the needs of your service and your load-balancing
    behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: The Three Types of Health Checks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When a service instance fails, it’s usually because of one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A local failure like an application error or resource—CPU, memory, database
    connections, etc.—depletion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A remote failure in some dependency—a database or other downstream service—that
    affects the functioning of the service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These two broad categories of failures give rise to three (yes, three) health
    checking strategies, each with its own fun little pros and cons.
  prefs: []
  type: TYPE_NORMAL
- en: '*Liveness checks* do little more than return a “success” signal. They make
    no additional attempt to determine the status of the service, and say nothing
    about the service except that it’s listening and reachable. But, then again, sometimes
    this is enough. We’ll talk more about liveness checks in [“Liveness checks”](#section_ch09_check_liveness).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Shallow health checks* go further than liveness checks by verifying that the
    service instance is likely to be able to function. These health checks only test
    local resources, so they’re unlikely to fail on many instances simultaneously,
    but they can’t say for certain whether a particular request service instance will
    be successful. We’ll wade into shallow health checks in [“Shallow health checks”](#section_ch09_check_shallow).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Deep health checks* provide a much better understanding of instance health,
    since they actually inspect the ability of a service instance to perform its function,
    which also exercises downstream resources like databases. While thorough, they
    can be expensive, and are susceptible to false positives. We’ll dig into deep
    health checks in [“Deep health checks”](#section_ch09_check_deep).'
  prefs: []
  type: TYPE_NORMAL
- en: Liveness checks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A liveness endpoint always returns a “success” value, no matter what. While
    this might seem trivial to the point of uselessness—after all, what is the value
    of a health check that doesn’t say anything about health—liveness probes actually
    can provide some useful information by confirming:'
  prefs: []
  type: TYPE_NORMAL
- en: That the service instance is listening and accepting new connections on the
    expected port
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That the instance is reachable over the network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That any firewall, security group, or other configurations are correctly defined
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This simplicity comes with a predictable cost, of course. The absence of any
    active health checking logic makes liveness checks of limited use when it comes
    to evaluating whether a service instance can actually perform its function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Liveness probes are also dead easy to implement. Using the `net/http` package,
    we can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The previous snippet shows how little work can go into a liveness check. In
    it, we create and register a `/healthz` endpoint that does nothing but return
    a `200 OK` (and the text `OK`, just to be thorough).
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you’re using the `gorilla/mux` package, any registered middleware (like the
    load shedding function from [“Load shedding”](#section_ch09_load_shedding)) can
    affect your health checks!
  prefs: []
  type: TYPE_NORMAL
- en: Shallow health checks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Shallow health checks go further than liveness checks by verifying that the
    service instance is *likely* to be able to function, but stop short of investigating
    in any way that might exercise a database or other downstream dependency.
  prefs: []
  type: TYPE_NORMAL
- en: 'Shallow health checks can evaluate any number of conditions that could adversely
    affect the service, including (but certainly not limited to):'
  prefs: []
  type: TYPE_NORMAL
- en: The availability of key local resources (memory, CPU, database connections)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to read or write local data, which checks disk space, permissions,
    and for hardware malfunctions such as disk failure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The presence of support processes, like monitoring or updater processes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shallow health checks are more definitive than liveness checks, and their specificity
    means that any failures are unlikely to affect the entire fleet at once.^([21](ch09.xhtml#idm45983620923448))
    However, shallow checks are prone to false positives: if your service is down
    because of some issue involving an external resource, a shallow check will miss
    it. What you gain in specificity, you also sacrifice in sensitivity.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A shallow health check might look something like the following example, which
    tests the service’s ability to read and write to and from local disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This simultaneously checks for available disk space, write permissions, and
    malfunctioning hardware, which can be a very useful thing to test, particularly
    if the service needs to write to an on-disk cache or other transient files.
  prefs: []
  type: TYPE_NORMAL
- en: An observant reader might notice that it writes to the default directory to
    use for temporary files. On Linux, this is `/tmp`, which is actually a RAM drive.
    This might be a useful thing to test as well, but if you want to test for the
    ability to write to disk on Linux you’ll need to specify a different directory,
    or this becomes a very different test.
  prefs: []
  type: TYPE_NORMAL
- en: Deep health checks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep health checks directly inspect the ability of a service to interact with
    its adjacent systems. This provides much better understanding of instance health
    by potentially identifying issues with dependencies, like invalid credentials,
    the loss of connectivity to data stores, or other unexpected networking issues.
  prefs: []
  type: TYPE_NORMAL
- en: However, while thorough, deep health checks can be quite expensive. They can
    take a long time and place a burden on dependencies, particularly if you’re running
    too many of them, or running them too often.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Don’t try to test *every* dependency in your health checks: focus on the ones
    that are required for the service to operate.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When testing multiple downstream dependencies, evaluate them concurrently if
    possible.
  prefs: []
  type: TYPE_NORMAL
- en: What’s more, because the failure of a dependency will be reported as a failure
    of the instance, deep checks are especially susceptible to false positives. Combined
    with the lower specificity compared to a shallow check—issues with dependencies
    will be felt by the entire fleet—and you have the potential for a cascading failure.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re using deep health checks, you should take advantage of strategies
    like circuit breaking (which we covered in [“Circuit Breaking”](#image_ch09_circuit_breaking))
    where you can, and your load balancer should “fail open” (which we’ll discuss
    in [“Failing Open”](#section_ch09_failing_open)) whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we have a trivial example of a possible deep health check that evaluates
    a database by calling a hypothetical service’s `GetUser` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Ideally, a dependency test should execute an actual system function, but also
    be lightweight to the greatest reasonable degree. In this example, the `GetUser`
    function triggers a database query that satisfies both of these criteria.^([22](ch09.xhtml#idm45983620664920))
  prefs: []
  type: TYPE_NORMAL
- en: “Real” queries are generally preferable to just pinging the database for two
    reasons. First, they’re a more representative test of what the service is doing.
    Second, they allow the leveraging of end-to-end query time as a measure of database
    health. The previous example actually does this—albeit in a very binary fashion—by
    using `Context` to set a hard timeout value, but you could choose to include more
    sophisticated logic instead.
  prefs: []
  type: TYPE_NORMAL
- en: Failing Open
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What if all of your instances simultaneously decide that they’re unhealthy?
    If you’re using deep health checks, this can actually happen quite easily (and,
    perhaps, regularly). Depending on how your load balancer is configured, you might
    find yourself with zero instances serving traffic, possibly causing failures rippling
    across your system.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, some load balancers handle this quite cleverly by “failing open.”
    If a load balancer that fails open has *no* healthy targets—that is, if *all*
    of its targets’ health checks are failing—it will route traffic to all of its
    targets.
  prefs: []
  type: TYPE_NORMAL
- en: This is slightly counterintuitive behavior, but it makes deep health checks
    somewhat safer to use by allowing traffic to continue to flow even when a downstream
    dependency may be having a bad day.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This was an interesting chapter to write. There’s quite a lot to say about resilience,
    and so much crucial supporting operational background. I had to make some tough
    calls about what would make it in and what wouldn’t. At about 37 pages, this chapter
    still turned out a fair bit longer than I intended, but I’m quite satisfied with
    the outcome. It’s a reasonable compromise between too little information and too
    much, and between operational background and actual Go implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We reviewed what it means for a system to fail, and how complex systems fail
    (that is, one component at a time). This led naturally to discussing a particularly
    nefarious, yet common, failure mode: cascading failures. In a cascade failure,
    a system’s own attempts to recover hasten its collapse. We covered common measures
    of preventing cascading failures on the server side: throttling and load shedding.'
  prefs: []
  type: TYPE_NORMAL
- en: Retries in the face of errors can contribute a lot to a service’s resilience,
    but as we saw in the DynamoDB case study, can also contribute to cascade failures
    when applied naively. We dug deep into measures that can be taken on the client
    side as well, including circuit breakers, timeouts, and especially exponential
    backoff algorithms. There were several pretty graphs involved. I spent a lot of
    time on the graphs.
  prefs: []
  type: TYPE_NORMAL
- en: All of this led to conversations about service redundancy, how it affects reliability
    (with a little math thrown in, for fun), and when and how to best leverage autoscaling.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you can’t talk about autoscaling without talking about resource “health.”
    We asked (and did our best to answer) what it means for an instance to be “healthy,”
    and how that translated into health checks. We covered the three kinds of health
    checks and weighed their pros and cons, paying particular attention to their relative
    sensitivity/specificity tradeoffs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Chapter 10](ch10.xhtml#chapter_10) we’ll take a break from the operational
    topics for a bit and wade into the subject of manageability: the art and science
    of changing the tires on a moving car.'
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch09.xhtml#idm45983623944264-marker)) Lamport, Leslie. *DEC SRC Bulletin
    Board*, 28 May 1987\. [*https://oreil.ly/nD85V*](https://oreil.ly/nD85V).
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch09.xhtml#idm45983623938904-marker)) Summary of the Amazon DynamoDB Service
    Disruption and Related Impacts in the US-East Region. Amazon AWS, September 2015\.
    [*https://oreil.ly/Y1P5S*](https://oreil.ly/Y1P5S).
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch09.xhtml#idm45983623929384-marker)) Cook, Richard I. “How Complex Systems
    Fail.” 1998\. [*https://oreil.ly/WyJ4Q*](https://oreil.ly/WyJ4Q).
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch09.xhtml#idm45983623919016-marker)) If you’re interested in a complete
    academic treatment, I highly recommend [*Reliability and Availability Engineering*](https://oreil.ly/tfKr1)
    by Kishor S. Trivedi and Andrea Bobbio (Cambridge University Press).
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch09.xhtml#idm45983623900600-marker)) Importantly, many faults are only
    evident in retrospect.
  prefs: []
  type: TYPE_NORMAL
- en: ^([6](ch09.xhtml#idm45983623894792-marker)) See? We eventually got there.
  prefs: []
  type: TYPE_NORMAL
- en: ^([7](ch09.xhtml#idm45983623892568-marker)) Go on, ask me how I know this.
  prefs: []
  type: TYPE_NORMAL
- en: ^([8](ch09.xhtml#idm45983623867528-marker)) Especially if the service is available
    on the open sewer that is the public internet.
  prefs: []
  type: TYPE_NORMAL
- en: ^([9](ch09.xhtml#idm45983623725192-marker)) Wikipedia contributors. “Token bucket.”
    *Wikipedia, The Free Encyclopedia*, 5 Jun. 2019\. [*https://oreil.ly/vkOov*](https://oreil.ly/vkOov).
  prefs: []
  type: TYPE_NORMAL
- en: ^([10](ch09.xhtml#idm45983622826936-marker)) The code used to simulate all data
    in this section is available in [the associated GitHub repository](https://oreil.ly/m61X7).
  prefs: []
  type: TYPE_NORMAL
- en: ^([11](ch09.xhtml#idm45983622584440-marker)) Doing that here felt redundant,
    but I’ll admit that I may have gotten a bit lazy.
  prefs: []
  type: TYPE_NORMAL
- en: ^([12](ch09.xhtml#idm45983622576120-marker)) And, technically, request-scoped
    values, but the correctness of this functionality is debatable.
  prefs: []
  type: TYPE_NORMAL
- en: ^([13](ch09.xhtml#idm45983621566664-marker)) Fielding, R., et al. “Hypertext
    Transfer Protocol — HTTP/1.1,” Proposed Standard, RFC 2068, June 1997\. [*https://oreil.ly/28rcs*](https://oreil.ly/28rcs).
  prefs: []
  type: TYPE_NORMAL
- en: ^([14](ch09.xhtml#idm45983621564248-marker)) Berners-Lee, T., et al. “Hypertext
    Transfer Protocol — HTTP/1.0,” Informational, RFC 1945, May 1996\. [*https://oreil.ly/zN7uo*](https://oreil.ly/zN7uo).
  prefs: []
  type: TYPE_NORMAL
- en: ^([15](ch09.xhtml#idm45983621558600-marker)) Fielding, Roy Thomas. “Architectural
    Styles and the Design of Network-Based Software Architectures.” *UC Irvine*, 2000,
    pp. 76–106\. [*https://oreil.ly/swjbd*](https://oreil.ly/swjbd).
  prefs: []
  type: TYPE_NORMAL
- en: ^([16](ch09.xhtml#idm45983621554584-marker)) You monster.
  prefs: []
  type: TYPE_NORMAL
- en: '^([17](ch09.xhtml#idm45983621184232-marker)) [*Building Secure and Reliable
    Systems: Best Practices for Designing, Implementing, and Maintaining Systems*](https://oreil.ly/YPKyr)
    by Heather Adkins—and a host of other authors—is one excellent example.'
  prefs: []
  type: TYPE_NORMAL
- en: ^([18](ch09.xhtml#idm45983621169368-marker)) Brace yourself. We’re going in.
  prefs: []
  type: TYPE_NORMAL
- en: ^([19](ch09.xhtml#idm45983621111896-marker)) This assumes that the failure rates
    of the components are absolutely independent, which is very unlikely in the real
    world. Treat as you would spherical cows in a vacuum.
  prefs: []
  type: TYPE_NORMAL
- en: ^([20](ch09.xhtml#idm45983621034232-marker)) Sridharan, Cindy (@copyconstruct).
    “Health checks are like bloom filters…” 5 Aug 2018, 3:21 AM. Tweet. [*https://oreil.ly/Qpw3d*](https://oreil.ly/Qpw3d).
  prefs: []
  type: TYPE_NORMAL
- en: ^([21](ch09.xhtml#idm45983620923448-marker)) Though I’ve seen it happen.
  prefs: []
  type: TYPE_NORMAL
- en: ^([22](ch09.xhtml#idm45983620664920-marker)) It’s an imaginary function, so
    let’s just agree that that’s true.
  prefs: []
  type: TYPE_NORMAL
