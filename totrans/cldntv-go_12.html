<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 9. Resilience"><div class="chapter" id="chapter_9">&#13;
<h1><span class="label">Chapter 9. </span>Resilience</h1>&#13;
&#13;
<blockquote>&#13;
<p>A distributed system is one in which the failure of a computer you didn’t even know about can render your own computer unusable.<sup><a data-type="noteref" id="idm45983623944264-marker" href="ch09.xhtml#idm45983623944264">1</a></sup></p>&#13;
<p data-type="attribution">Leslie Lamport, <cite>DEC SRC Bulletin Board (May 1987)</cite></p>&#13;
</blockquote>&#13;
&#13;
<p><a data-type="indexterm" data-primary="Amazon" id="idm45983623940552"/><a data-type="indexterm" data-primary="DynamoDB" id="idm45983623939848"/>Late one September night, at just after two in the morning, a portion of Amazon’s internal network quietly stopped working.<sup><a data-type="noteref" id="idm45983623938904-marker" href="ch09.xhtml#idm45983623938904">2</a></sup> This event was brief, and not particularly interesting, except that it happened to affect a sizable number of the servers that supported the DynamoDB service.</p>&#13;
&#13;
<p>Most days, this wouldn’t be such a big deal. Any affected servers would just try to reconnect to the cluster by retrieving their membership data from a dedicated metadata service. If that failed, they would temporarily take themselves offline and try again.</p>&#13;
&#13;
<p>But this time, when the network was restored, a small army of storage servers simultaneously requested their membership data from the metadata service, overwhelming it so that requests—even ones from previously unaffected servers—started to time out. Storage servers dutifully responded to the timeouts by taking themselves offline and retrying (again), further stressing the metadata service, causing even more servers to go offline, and so on. Within minutes, the outage had spread to the entire cluster. The service was effectively down, taking a number of dependent services down with it.</p>&#13;
&#13;
<p>To make matters worse, the sheer volume of retry attempts—a “retry storm”—put such a burden on the metadata service that it even became entirely unresponsive to requests to add capacity. The on-call engineers were forced to explicitly block requests to the metadata service just to relieve enough pressure to allow them to manually scale up.</p>&#13;
&#13;
<p>Finally, nearly five hours after the initial network hiccup that triggered the incident, normal operations resumed, putting an end to what must have been a long night for all involved.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect1" data-pdf-bookmark="Keeping on Ticking: Why Resilience Matters"><div class="sect1" id="idm45983623933592">&#13;
<h1>Keeping on Ticking: Why Resilience Matters</h1>&#13;
&#13;
<p><a data-type="indexterm" data-primary="resilience" data-secondary="importance of" id="idm45983623932184"/><a data-type="indexterm" data-primary="failures" data-secondary="causes of" id="idm45983623931208"/>So, what was the root cause of Amazon’s outage? Was it the network disruption? Was it the storage servers’ enthusiastic retry behavior? Was it the metadata service’s response time, or maybe its limited capacity?</p>&#13;
&#13;
<p>Clearly, what happened that early morning didn’t have a single root cause. Failures in complex systems never do.<sup><a data-type="noteref" id="idm45983623929384-marker" href="ch09.xhtml#idm45983623929384">3</a></sup> Rather, the system failed as complex systems do: with a failure in a subsystem, which triggered a latent fault in another subsystem causing <em>it</em> to fail, followed by another, and another, until eventually the entire system went down. What’s interesting, though, is that if any of the components in our story—the network, the storage servers, the metadata service—had been able to isolate and recover from failures elsewhere in the system, the overall system likely would have recovered without human intervention.</p>&#13;
&#13;
<p>Unfortunately, this is just one example of a common pattern. Complex systems fail in complex (and often surprising) ways, but they don’t fail all at once: they fail one subsystem at a time. For this reason, resilience patterns in complex systems take the form of bulwarks and safety valves that work to isolate failures at component boundaries. Frequently, a failure contained is a failure avoided.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="resilience" data-secondary="definition of" id="ch09_term1"/>This property, the measure of a system’s ability to withstand and recover from errors and failures, is its <em>resilience</em>. A system can be considered <em>resilient</em> if it can continue operating correctly—possibly at a reduced level—rather than failing completely when one of its subsystems fails.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45983623922936">&#13;
<h5>Resilience Is Not Reliability</h5>&#13;
<p><a data-type="indexterm" data-primary="resilience" data-secondary="reliability and" id="idm45983623921768"/><a data-type="indexterm" data-primary="reliability" id="idm45983623920792"/>The terms <em>resilience</em> and <em>reliability</em> describe closely related concepts, and are often confused. But they aren’t quite the same thing.<sup><a data-type="noteref" id="idm45983623919016-marker" href="ch09.xhtml#idm45983623919016">4</a></sup></p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The <em>resilience</em> of a system is the degree to which it can continue to operate correctly in the face of errors and faults. Resilience, along with the other four cloud native properties, is just one factor that contributes to reliability.</p>&#13;
</li>&#13;
<li>&#13;
<p>The <em>reliability</em> of a system is its ability to behave as expected for a given time interval. Reliability, in conjunction with attributes like availability and maintainability, contributes to a system’s overall dependability.</p>&#13;
</li>&#13;
</ul>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect1" data-pdf-bookmark="What Does It Mean for a System to Fail?"><div class="sect1" id="idm45983623913752">&#13;
<h1>What Does It Mean for a System to Fail?</h1>&#13;
<blockquote>&#13;
<p>For want of a nail the shoe was lost,<br/>&#13;
for want of a shoe the horse was lost;<br/>&#13;
for want of a horse the rider was lost;<br/>&#13;
all for want of care about a horse-shoe nail.</p>&#13;
<p data-type="attribution">Benjamin Franklin, <cite>The Way to Wealth (1758)</cite></p>&#13;
</blockquote>&#13;
&#13;
<p><a data-type="indexterm" data-primary="failures" data-secondary="definition of" id="ch09_term2"/>If we want to know what it means for a system to fail, we first have to ask what a “system” is.</p>&#13;
&#13;
<p>This is important. Bear with me.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="system" id="idm45983623907256"/><a data-type="indexterm" data-primary="subsystem" id="idm45983623906552"/>By definition, a <em>system</em> is a set of components that work together to accomplish an overall goal. So far, so good. But here’s the important part: each component of a system—a <em>subsystem</em>—is also a complete system unto itself, that in turn is composed of still smaller subsystems, and so on, and so on.</p>&#13;
&#13;
<p>Take a car, for example. Its engine is one of dozens of subsystems, but it—like all the others—is also a very complex system with a number of subsystems of its own, including a cooling subsystem, which includes a thermostat, which includes a temperature switch, and so on. That’s just some of thousands of components and subcomponents and sub-subcomponents. It’s enough to make the mind spin: so many things that can fail. But what happens when they do?</p>&#13;
&#13;
<p>As we mentioned earlier—and discussed in some depth in <a data-type="xref" href="ch06.xhtml#chapter_6">Chapter 6</a>—failures of complex systems don’t just happen all at once. They unravel in predictable steps:</p>&#13;
<ol>&#13;
<li>&#13;
<p>All systems contain <em>faults</em>, which we lovingly refer to as “bugs” in the software world. A tendency for a temperature switch in a car engine to stick would be a fault. So would the metadata service’s limited capacity and the storage server’s retry behavior in the DynamoDB case study.<sup><a data-type="noteref" id="idm45983623900600-marker" href="ch09.xhtml#idm45983623900600">5</a></sup> Under the right conditions, a fault can be exercised to produce an <em>error</em>.<a data-type="indexterm" data-primary="faults" id="idm45983623899528"/><a data-type="indexterm" data-primary="errors" id="idm45983623898792"/></p>&#13;
</li>&#13;
<li>&#13;
<p>An <em>error</em> is any discrepancy between the system’s intended and actual behavior. Many errors can be caught and handled appropriately, but if they’re not they can—singly or in accumulation—give rise to a <em>failure</em>. A stuck temperature switch in a car engine’s thermostat is an error.</p>&#13;
</li>&#13;
<li>&#13;
<p>Finally, a system can be said to be experiencing a <em>failure</em> when it’s no longer able to provide correct service.<sup><a data-type="noteref" id="idm45983623894792-marker" href="ch09.xhtml#idm45983623894792">6</a></sup> A temperature switch that no longer responds to high temperatures can be said to have failed. A failure at the subsystem level becomes a fault at the system level.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>This last bit bears repeating: <em>a failure at the subsystem level becomes a fault at the system level.</em> A stuck temperature switch causes a thermostat to fail, preventing coolant from flowing through the radiator, raising the temperature of the engine, causing it to stall and the car to stop.<sup><a data-type="noteref" id="idm45983623892568-marker" href="ch09.xhtml#idm45983623892568">7</a></sup></p>&#13;
&#13;
<p>That’s how systems fail. It starts with the failure of one component—one subsystem—which causes an error in one or more components that interact with it, and ones that interact with that, and so on, propagating upward until the entire system fails.</p>&#13;
&#13;
<p>This isn’t just academic. Knowing how complex systems fail—one component at a time—makes the means of resisting failures clearer: if a fault can be contained before it propagates all the way to the system level, the system may be able to recover (or at least fail on its own terms).<a data-type="indexterm" data-primary="resilience" data-secondary="definition of" data-startref="ch09_term1" id="idm45983623890616"/><a data-type="indexterm" data-primary="failures" data-secondary="definition of" data-startref="ch09_term2" id="idm45983623889368"/></p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="Building for Resilience"><div class="sect2" id="idm45983623888024">&#13;
<h2>Building for Resilience</h2>&#13;
&#13;
<p><a data-type="indexterm" data-primary="resilience" data-secondary="building" id="ch09_term3"/>In a perfect world it would be possible to rid a system of every possible fault, but this isn’t realistic, and it’s wasteful and unproductive to try. By instead assuming that all components are destined to fail eventually—which they absolutely are—and designing them to respond gracefully to errors when they do occur, you can produce a system that’s functionally healthy even when some of its components are not.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="redundancy" id="idm45983623884792"/>There are lots of ways to increase the resiliency of a system. Redundancy, such as deploying multiple components of the same type, is probably the most common approach. Specialized logic like circuit breakers and request throttles can be used to isolate specific kinds of errors, preventing them from propagating. Faulty components can even be reaped—or intentionally allowed to fail—to benefit the health of the larger system.</p>&#13;
&#13;
<p>Resilience is a particularly rich subject. We’ll explore several of these approaches—and more—over the remainder of the chapter.<a data-type="indexterm" data-primary="resilience" data-secondary="building" data-startref="ch09_term3" id="idm45983623882984"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect1" data-pdf-bookmark="Cascading Failures"><div class="sect1" id="section_ch09_cascading_failures">&#13;
<h1>Cascading Failures</h1>&#13;
&#13;
<p><a data-type="indexterm" data-primary="failures" data-secondary="types of" data-seealso="cascading failures" id="idm45983623879704"/><a data-type="indexterm" data-primary="cascading failures" id="ch09_term4"/>The reason the DynamoDB case study is so appropriate is that it demonstrates so many different ways that things that can go wrong at scale.</p>&#13;
&#13;
<p>Take, for example, how the failure of a group of storage servers caused requests to the metadata service to time out, which in turn caused more storage servers to fail, which increased the pressure on the metadata service, and so on. This is an excellent example of a particular—and particularly common—failure mode known as a <em>cascading failure</em>. Once a cascading failure has begun, it tends to spread very quickly, often on the order of a few minutes.</p>&#13;
&#13;
<p>The mechanisms of cascading failures can vary a bit, but one thing they share is some kind of positive feedback mechanism. One part of a system experiences a local failure—a reduction in capacity, an increase in latency, etc.—that causes other components to attempt to compensate for the failed component in a way that exacerbates the problem, eventually leading to the failure of the entire system.</p>&#13;
&#13;
<p>The classic cause of cascading failures is overload, illustrated in <a data-type="xref" href="#image_ch09_cascading_failures">Figure 9-1</a>. This occurs when one or more nodes in a set fails, causing the load to be catastrophically redistributed to the survivors. The increase in load overloads the remaining nodes, causing them to fail from resource exhaustion, taking the entire system down.</p>&#13;
&#13;
<figure><div id="image_ch09_cascading_failures" class="figure">&#13;
<img src="Images/cngo_0901.png" alt="cngo 0901" width="867" height="434"/>&#13;
<h6><span class="label">Figure 9-1. </span>Server overload is a common cause of cascade failures; each server handles 600 requests per second, so when server B fails, server A is overloaded and also fails</h6>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before less_space">The nature of positive feedback often makes it very difficult to scale your way out of a cascading failure by adding more capacity. New nodes can be overwhelmed as quickly as they come online, often contributing the feedback that took the system down in the first place. Sometimes, the only fix is to take your entire service down—perhaps by explicitly blocking the problematic traffic—in order to recover, and then slowly reintroduce load.</p>&#13;
&#13;
<p>But how do you prevent cascading failures in the first place? This will be the subject of the next section (and, to some extent, most of this chapter).</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="Preventing Overload"><div class="sect2" id="section_ch09_preventing_overload">&#13;
<h2>Preventing Overload</h2>&#13;
&#13;
<p>Every service, however well-designed and implemented, has its functional limitations. This is particularly evident in services intended to handle and respond to client requests.<sup><a data-type="noteref" id="idm45983623867528-marker" href="ch09.xhtml#idm45983623867528">8</a></sup> For any such service there exists some request frequency, a threshold beyond which bad things will start to happen. So, how do we keep a large number of requests from accidentally (or intentionally!) bringing our service down?</p>&#13;
&#13;
<p>Ultimately, a service that finds itself in such a situation has no choice but to reject—partially or entirely—some number of requests. There are two main strategies for doing this:</p>&#13;
<dl>&#13;
<dt><a data-type="indexterm" data-primary="throttling" id="ch09_term5"/>Throttling</dt>&#13;
<dd>&#13;
<p>Throttling is a relatively straightforward strategy that kicks in when requests come in faster than some predetermined frequency, typically, by just refusing to handle them. This is often used as a preventative measure by ensuring that no particular user consumes more resources than they would reasonably require.</p>&#13;
</dd>&#13;
<dt><a data-type="indexterm" data-primary="load shedding" id="idm45983623733480"/>Load shedding</dt>&#13;
<dd>&#13;
<p>Load shedding is a little more adaptive. Services using this strategy intentionally drop (“shed”) some proportion of load as they approach overload conditions by either refusing requests or falling back into a degraded mode.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>These strategies aren’t mutually exclusive; a service may choose to employ either or both of them, according to its needs.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="Throttling"><div class="sect3" id="idm45983623730728">&#13;
<h3>Throttling</h3>&#13;
&#13;
<p>As we discussed in <a data-type="xref" href="ch04.xhtml#chapter_4">Chapter 4</a>, a throttle pattern works a lot like the throttle in a car, except that instead of limiting the amount of fuel entering an engine, it limits the number of requests that a user (human or otherwise) can make to a service in a set period of time.</p>&#13;
&#13;
<p>The general-purpose throttle example that we provided in <a data-type="xref" href="ch04.xhtml#section_ch04_throttle">“Throttle”</a> was relatively simple, and effectively global, at least as written. However, throttles are also frequently applied on a per-user basis to provide something like a usage quota, so that no one caller can consume too much of a service’s resources.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="token bucket" id="idm45983623726136"/>In the following, we demonstrate a throttle implementation that, while still using a token bucket,<sup><a data-type="noteref" id="idm45983623725192-marker" href="ch09.xhtml#idm45983623725192">9</a></sup> is otherwise quite different in several ways.</p>&#13;
&#13;
<p>First, instead of having a single bucket that’s used to gate all incoming requests, the following implementation throttles on a per-user basis, returning a function that accepts a “key” parameter, that’s meant to represent a username or some other unique identifier.</p>&#13;
&#13;
<p>Second, rather than attempting to “replay” a cached value when imposing a throttle limit, the returned function returns a Boolean that indicates when a throttle has been imposed. Note that the throttle doesn’t return an <code>error</code> when it’s activated: throttling isn’t an error condition, so we don’t treat it as one.</p>&#13;
&#13;
<p>Finally, and perhaps most interestingly, it doesn’t actually use a timer (a <code>time.Ticker</code>) to explicitly add tokens to buckets on some regular cadence. Rather, it refills buckets on demand, based on the time elapsed between requests. This strategy means that we don’t have to dedicate background processes to filling buckets until they’re actually used, which will scale much more effectively:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="c1">// Effector is the function that you want to subject to throttling.</code>&#13;
<code class="kd">type</code> <code class="nx">Effector</code> <code class="kd">func</code><code class="p">(</code><code class="nx">context</code><code class="p">.</code><code class="nx">Context</code><code class="p">)</code> <code class="p">(</code><code class="kt">string</code><code class="p">,</code> <code class="kt">error</code><code class="p">)</code>&#13;
&#13;
<code class="c1">// Throttled wraps an Effector. It accepts the same parameters, plus a</code>&#13;
<code class="c1">// "UID" string that represents a caller identity. It returns the same,</code>&#13;
<code class="c1">// plus a bool that's true if the call is not throttled.</code>&#13;
<code class="kd">type</code> <code class="nx">Throttled</code> <code class="kd">func</code><code class="p">(</code><code class="nx">context</code><code class="p">.</code><code class="nx">Context</code><code class="p">,</code> <code class="kt">string</code><code class="p">)</code> <code class="p">(</code><code class="kt">bool</code><code class="p">,</code> <code class="kt">string</code><code class="p">,</code> <code class="kt">error</code><code class="p">)</code>&#13;
&#13;
<code class="c1">// A bucket tracks the requests associated with a UID.</code>&#13;
<code class="kd">type</code> <code class="nx">bucket</code> <code class="kd">struct</code> <code class="p">{</code>&#13;
    <code class="nx">tokens</code> <code class="kt">uint</code>&#13;
    <code class="nx">time</code>   <code class="nx">time</code><code class="p">.</code><code class="nx">Time</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="c1">// Throttle accepts an Effector function, and returns a Throttled</code>&#13;
<code class="c1">// function with a per-UID token bucket with a capacity of max</code>&#13;
<code class="c1">// that refills at a rate of refill tokens every d.</code>&#13;
<code class="kd">func</code> <code class="nx">Throttle</code><code class="p">(</code><code class="nx">e</code> <code class="nx">Effector</code><code class="p">,</code> <code class="nx">max</code> <code class="kt">uint</code><code class="p">,</code> <code class="nx">refill</code> <code class="kt">uint</code><code class="p">,</code> <code class="nx">d</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Duration</code><code class="p">)</code> <code class="nx">Throttled</code> <code class="p">{</code>&#13;
    <code class="c1">// buckets maps UIDs to specific buckets</code>&#13;
    <code class="nx">buckets</code> <code class="o">:=</code> <code class="kd">map</code><code class="p">[</code><code class="kt">string</code><code class="p">]</code><code class="o">*</code><code class="nx">bucket</code><code class="p">{}</code>&#13;
&#13;
    <code class="k">return</code> <code class="kd">func</code><code class="p">(</code><code class="nx">ctx</code> <code class="nx">context</code><code class="p">.</code><code class="nx">Context</code><code class="p">,</code> <code class="nx">uid</code> <code class="kt">string</code><code class="p">)</code> <code class="p">(</code><code class="kt">bool</code><code class="p">,</code> <code class="kt">string</code><code class="p">,</code> <code class="kt">error</code><code class="p">)</code> <code class="p">{</code>&#13;
        <code class="nx">b</code> <code class="o">:=</code> <code class="nx">buckets</code><code class="p">[</code><code class="nx">uid</code><code class="p">]</code>&#13;
&#13;
        <code class="c1">// This is a new entry! It passes. Assumes that capacity &gt;= 1.</code>&#13;
        <code class="k">if</code> <code class="nx">b</code> <code class="o">==</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
            <code class="nx">buckets</code><code class="p">[</code><code class="nx">uid</code><code class="p">]</code> <code class="p">=</code> <code class="o">&amp;</code><code class="nx">bucket</code><code class="p">{</code><code class="nx">tokens</code><code class="p">:</code> <code class="nx">max</code> <code class="o">-</code> <code class="mi">1</code><code class="p">,</code> <code class="nx">time</code><code class="p">:</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Now</code><code class="p">()}</code>&#13;
&#13;
            <code class="nx">str</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">e</code><code class="p">(</code><code class="nx">ctx</code><code class="p">)</code>&#13;
            <code class="k">return</code> <code class="kc">true</code><code class="p">,</code> <code class="nx">str</code><code class="p">,</code> <code class="nx">err</code>&#13;
        <code class="p">}</code>&#13;
&#13;
        <code class="c1">// Calculate how many tokens we now have based on the time</code>&#13;
        <code class="c1">// passed since the previous request.</code>&#13;
        <code class="nx">refillInterval</code> <code class="o">:=</code> <code class="nb">uint</code><code class="p">(</code><code class="nx">time</code><code class="p">.</code><code class="nx">Since</code><code class="p">(</code><code class="nx">b</code><code class="p">.</code><code class="nx">time</code><code class="p">)</code> <code class="o">/</code> <code class="nx">d</code><code class="p">)</code>&#13;
        <code class="nx">tokensAdded</code> <code class="o">:=</code> <code class="nx">refill</code> <code class="o">*</code> <code class="nx">refillInterval</code>&#13;
        <code class="nx">currentTokens</code> <code class="o">:=</code> <code class="nx">b</code><code class="p">.</code><code class="nx">tokens</code> <code class="o">+</code> <code class="nx">tokensAdded</code>&#13;
&#13;
        <code class="c1">// We don't have enough tokens. Return false.</code>&#13;
        <code class="k">if</code> <code class="nx">currentTokens</code> <code class="p">&lt;</code> <code class="mi">1</code> <code class="p">{</code>&#13;
            <code class="k">return</code> <code class="kc">false</code><code class="p">,</code> <code class="s">""</code><code class="p">,</code> <code class="kc">nil</code>&#13;
        <code class="p">}</code>&#13;
&#13;
        <code class="c1">// If we've refilled our bucket, we can restart the clock.</code>&#13;
        <code class="c1">// Otherwise, we figure out when the most recent tokens were added.</code>&#13;
        <code class="k">if</code> <code class="nx">currentTokens</code> <code class="p">&gt;</code> <code class="nx">max</code> <code class="p">{</code>&#13;
            <code class="nx">b</code><code class="p">.</code><code class="nx">time</code> <code class="p">=</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Now</code><code class="p">()</code>&#13;
            <code class="nx">b</code><code class="p">.</code><code class="nx">tokens</code> <code class="p">=</code> <code class="nx">max</code> <code class="o">-</code> <code class="mi">1</code>&#13;
        <code class="p">}</code> <code class="k">else</code> <code class="p">{</code>&#13;
            <code class="nx">deltaTokens</code> <code class="o">:=</code> <code class="nx">currentTokens</code> <code class="o">-</code> <code class="nx">b</code><code class="p">.</code><code class="nx">tokens</code>&#13;
            <code class="nx">deltaRefills</code> <code class="o">:=</code> <code class="nx">deltaTokens</code> <code class="o">/</code> <code class="nx">refill</code>&#13;
            <code class="nx">deltaTime</code> <code class="o">:=</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Duration</code><code class="p">(</code><code class="nx">deltaRefills</code><code class="p">)</code> <code class="o">*</code> <code class="nx">d</code>&#13;
&#13;
            <code class="nx">b</code><code class="p">.</code><code class="nx">time</code> <code class="p">=</code> <code class="nx">b</code><code class="p">.</code><code class="nx">time</code><code class="p">.</code><code class="nx">Add</code><code class="p">(</code><code class="nx">deltaTime</code><code class="p">)</code>&#13;
            <code class="nx">b</code><code class="p">.</code><code class="nx">tokens</code> <code class="p">=</code> <code class="nx">currentTokens</code> <code class="o">-</code> <code class="mi">1</code>&#13;
        <code class="p">}</code>&#13;
&#13;
        <code class="nx">str</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">e</code><code class="p">(</code><code class="nx">ctx</code><code class="p">)</code>&#13;
&#13;
        <code class="k">return</code> <code class="kc">true</code><code class="p">,</code> <code class="nx">str</code><code class="p">,</code> <code class="nx">err</code>&#13;
    <code class="p">}</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>Like the example in <a data-type="xref" href="ch04.xhtml#section_ch04_throttle">“Throttle”</a>, this <code>Throttle</code> function accepts a function literal that conforms to the <code>Effector</code> contract, plus some values that define the size and refill rate of the underlying token bucket.</p>&#13;
&#13;
<p>Instead of returning another <code>Effector</code>, however, it returns a <code>Throttled</code> function, which in addition to wrapping the effector with the throttling logic adds a “key” input parameter, which represents a unique user identifier, and a Boolean return value, which indicates whether the function has been throttled (and therefore not executed).</p>&#13;
&#13;
<p>As interesting as you may (or may not) find the <code>Throttle</code> code, it’s still not production ready. First of all, it’s not entirely safe for concurrent use. A production implementation will probably want to lock on the <code>record</code> values, and possibly the <code>bucket</code> map. Second, there’s no way to purge old records. In production, we’d probably want to use something like an LRU cache, like the one we described in <a data-type="xref" href="ch07.xhtml#section_ch07_lru_cache">“Efficient Caching Using an LRU Cache”</a>, instead.</p>&#13;
&#13;
<p>In the following, we show a toy example of how <code>Throttle</code> might be used in a RESTful web service:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">var</code> <code class="nx">throttled</code> <code class="p">=</code> <code class="nx">Throttle</code><code class="p">(</code><code class="nx">getHostname</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Second</code><code class="p">)</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">getHostname</code><code class="p">(</code><code class="nx">ctx</code> <code class="nx">context</code><code class="p">.</code><code class="nx">Context</code><code class="p">)</code> <code class="p">(</code><code class="kt">string</code><code class="p">,</code> <code class="kt">error</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="k">if</code> <code class="nx">ctx</code><code class="p">.</code><code class="nx">Err</code><code class="p">()</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="k">return</code> <code class="s">""</code><code class="p">,</code> <code class="nx">ctx</code><code class="p">.</code><code class="nx">Err</code><code class="p">()</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="k">return</code> <code class="nx">os</code><code class="p">.</code><code class="nx">Hostname</code><code class="p">()</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">throttledHandler</code><code class="p">(</code><code class="nx">w</code> <code class="nx">http</code><code class="p">.</code><code class="nx">ResponseWriter</code><code class="p">,</code> <code class="nx">r</code> <code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Request</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="nx">ok</code><code class="p">,</code> <code class="nx">hostname</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">throttled</code><code class="p">(</code><code class="nx">r</code><code class="p">.</code><code class="nx">Context</code><code class="p">(),</code> <code class="nx">r</code><code class="p">.</code><code class="nx">RemoteAddr</code><code class="p">)</code>&#13;
&#13;
    <code class="k">if</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="nx">http</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code> <code class="nx">err</code><code class="p">.</code><code class="nx">Error</code><code class="p">(),</code> <code class="nx">http</code><code class="p">.</code><code class="nx">StatusInternalServerError</code><code class="p">)</code>&#13;
        <code class="k">return</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="k">if</code> <code class="p">!</code><code class="nx">ok</code> <code class="p">{</code>&#13;
        <code class="nx">http</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code> <code class="s">"Too many requests"</code><code class="p">,</code> <code class="nx">http</code><code class="p">.</code><code class="nx">StatusTooManyRequests</code><code class="p">)</code>&#13;
        <code class="k">return</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="nx">w</code><code class="p">.</code><code class="nx">WriteHeader</code><code class="p">(</code><code class="nx">http</code><code class="p">.</code><code class="nx">StatusOK</code><code class="p">)</code>&#13;
    <code class="nx">w</code><code class="p">.</code><code class="nx">Write</code><code class="p">([]</code><code class="nb">byte</code><code class="p">(</code><code class="nx">hostname</code><code class="p">))</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">main</code><code class="p">()</code> <code class="p">{</code>&#13;
    <code class="nx">r</code> <code class="o">:=</code> <code class="nx">mux</code><code class="p">.</code><code class="nx">NewRouter</code><code class="p">()</code>&#13;
    <code class="nx">r</code><code class="p">.</code><code class="nx">HandleFunc</code><code class="p">(</code><code class="s">"/hostname"</code><code class="p">,</code> <code class="nx">throttledHandler</code><code class="p">)</code>&#13;
    <code class="nx">log</code><code class="p">.</code><code class="nx">Fatal</code><code class="p">(</code><code class="nx">http</code><code class="p">.</code><code class="nx">ListenAndServe</code><code class="p">(</code><code class="s">":8080"</code><code class="p">,</code> <code class="nx">r</code><code class="p">))</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>The previous code creates a small web service with a single (somewhat contrived) endpoint at <code>/hostname</code> that returns the service’s hostname. When the program is run, the <code>throttled</code> var is created by wrapping the <code>getHostname</code> function—which provides the actual service logic—by passing it to <code>Throttle</code>, which we defined previously.</p>&#13;
&#13;
<p>When the router receives a request for the <code>/hostname</code> endpoint, the request is forwarded to the <code>throttledHandler</code> function, which performs the calls to <code>throttled</code>, receiving a <code>bool</code> indicating throttling status, the hostname <code>string</code>, and an <code>error</code> value. A defined error causes us to return a <code>500 Internal Server Error</code>, and a throttled request gets a <code>429 Too Many Requests</code>. If all else goes well, we return the hostname and a status <code>200 OK</code>.</p>&#13;
&#13;
<p>Note that the bucket values are stored locally, so this implementation can’t really be considered production-ready either. If you want this to scale out, you might want to store the record values in an external cache of some kind so that multiple service replicas can share them.<a data-type="indexterm" data-primary="throttling" data-startref="ch09_term5" id="idm45983623359848"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="Load shedding"><div class="sect3" id="section_ch09_load_shedding">&#13;
<h3>Load shedding</h3>&#13;
&#13;
<p>It’s an unavoidable fact of life that, as load on a server increases beyond what it can handle, something eventually has to give.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="load shedding" id="ch09_term6"/><em>Load shedding</em> is a technique used to predict when a server is approaching that saturation point and then mitigating the saturation by dropping some proportion of traffic in a controlled fashion. Ideally, this will prevent the server from overloading and failing health checks, serving with high latency, or just collapsing in a graceless, uncontrolled failure.</p>&#13;
&#13;
<p>Unlike quota-based throttling, load shedding is reactive, typically engaging in response to depletion of a resource like CPU, memory, or request-queue depth.</p>&#13;
&#13;
<p>Perhaps the most straightforward form of load shedding is a per-task throttling that drops requests when one or more resources exceed a particular threshold. For example, if your service provides a RESTful endpoint, you might choose to to return an HTTP 503 (service unavailable). The <code>gorilla/mux</code> web toolkit, which we found very effective in <a data-type="xref" href="ch05.xhtml#chapter_5">Chapter 5</a> in the section <a data-type="xref" href="ch05.xhtml#section_ch05_building_with_gorilla">“Building an HTTP Server with gorilla/mux”</a>, makes this fairly straightforward by <a href="https://oreil.ly/GTxes">supporting “middleware” handler functions</a> that are called on every request:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">const</code> <code class="nx">MaxQueueDepth</code> <code class="p">=</code> <code class="mi">1000</code>&#13;
&#13;
<code class="c1">// Middleware function, which will be called for each request.</code>&#13;
<code class="c1">// If queue depth is exceeded, it returns HTTP 503 (service unavailable).</code>&#13;
<code class="kd">func</code> <code class="nx">loadSheddingMiddleware</code><code class="p">(</code><code class="nx">next</code> <code class="nx">http</code><code class="p">.</code><code class="nx">Handler</code><code class="p">)</code> <code class="nx">http</code><code class="p">.</code><code class="nx">Handler</code> <code class="p">{</code>&#13;
    <code class="k">return</code> <code class="nx">http</code><code class="p">.</code><code class="nx">HandlerFunc</code><code class="p">(</code><code class="kd">func</code><code class="p">(</code><code class="nx">w</code> <code class="nx">http</code><code class="p">.</code><code class="nx">ResponseWriter</code><code class="p">,</code> <code class="nx">r</code> <code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Request</code><code class="p">)</code> <code class="p">{</code>&#13;
        <code class="c1">// CurrentQueueDepth is fictional and for example purposes only.</code>&#13;
        <code class="k">if</code> <code class="nx">CurrentQueueDepth</code><code class="p">()</code> <code class="p">&gt;</code> <code class="nx">MaxQueueDepth</code> <code class="p">{</code>&#13;
            <code class="nx">log</code><code class="p">.</code><code class="nx">Println</code><code class="p">(</code><code class="s">"load shedding engaged"</code><code class="p">)</code>&#13;
&#13;
            <code class="nx">http</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code>&#13;
                <code class="nx">err</code><code class="p">.</code><code class="nx">Error</code><code class="p">(),</code>&#13;
                <code class="nx">http</code><code class="p">.</code><code class="nx">StatusServiceUnavailable</code><code class="p">)</code>&#13;
            <code class="k">return</code>&#13;
        <code class="p">}</code>&#13;
&#13;
        <code class="nx">next</code><code class="p">.</code><code class="nx">ServeHTTP</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code> <code class="nx">r</code><code class="p">)</code>&#13;
    <code class="p">})</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">main</code><code class="p">()</code> <code class="p">{</code>&#13;
    <code class="nx">r</code> <code class="o">:=</code> <code class="nx">mux</code><code class="p">.</code><code class="nx">NewRouter</code><code class="p">()</code>&#13;
&#13;
    <code class="c1">// Register middleware</code>&#13;
    <code class="nx">r</code><code class="p">.</code><code class="nx">Use</code><code class="p">(</code><code class="nx">loadSheddingMiddleware</code><code class="p">)</code>&#13;
&#13;
    <code class="nx">log</code><code class="p">.</code><code class="nx">Fatal</code><code class="p">(</code><code class="nx">http</code><code class="p">.</code><code class="nx">ListenAndServe</code><code class="p">(</code><code class="s">":8080"</code><code class="p">,</code> <code class="nx">r</code><code class="p">))</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>Gorilla Mux middlewares are called on every request, each taking a request, doing something with it, and passing it down to another middleware or the final handler. This makes them perfect for implementing general request logging, header manipulation, <code>ResponseWriter</code> hijacking, or in our case, resource-reactive load shedding.</p>&#13;
&#13;
<p>Our middleware uses the fictional <code>CurrentQueueDepth()</code> (your actual function will depend on your implementation) to check the current queue depth, and rejects requests with an HTTP 503 (service unavailable) if the value is too high. More sophisticated implementations might even be smarter about choosing which work is dropped by prioritizing particularly important requests.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="Graceful service degradation"><div class="sect3" id="idm45983622933992">&#13;
<h3>Graceful service degradation</h3>&#13;
&#13;
<p><a data-type="indexterm" data-primary="graceful degradation" id="idm45983622932888"/>Resource-sensitive load shedding works well, but in some applications it’s possible to act a little more gracefully by significantly decreasing the quality of responses when the service is approaching overload. Such <em>graceful degradation</em> takes the concept of load shedding one step further by strategically reducing the amount of work needed to satisfy each request instead of just rejecting requests.</p>&#13;
&#13;
<p>There are as many ways of doing this as there are services, and not every service can be degraded in a reasonable manner, but common approaches include falling back on cached data or less expensive—if less precise—algorithms.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect1" data-pdf-bookmark="Play It Again: Retrying Requests"><div class="sect1" id="section_ch09_retries">&#13;
<h1>Play It Again: Retrying Requests</h1>&#13;
&#13;
<p><a data-type="indexterm" data-primary="retries" data-seealso="messaging redundancy, retry storm" id="ch09_term8"/>When a request receives an error response, or doesn’t receive a response at all, it should just try again, right? Well, kinda. Retrying makes sense, but it’s a lot more nuanced than that.</p>&#13;
&#13;
<p>Take this snippet for example, a version of which I’ve found in a production system:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="nx">res</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">SendRequest</code><code class="p">()</code>&#13;
<code class="k">for</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
    <code class="nx">res</code><code class="p">,</code> <code class="nx">err</code> <code class="p">=</code> <code class="nx">SendRequest</code><code class="p">()</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>It seems seductively straightforward, doesn’t it? It <em>will</em> repeat failed requests, but that’s also <em>exactly</em> what it will do. So when this logic was deployed to a few hundred servers and the service to which it was issuing requests went down, the entire system went with it. A review of the service metrics, shown in <a data-type="xref" href="#image_ch09_retry_storm">Figure 9-2</a>, revealed this.</p>&#13;
&#13;
<figure><div id="image_ch09_retry_storm" class="figure">&#13;
<img src="Images/cngo_0902.png" alt="cngo 0902" width="2354" height="1376"/>&#13;
<h6><span class="label">Figure 9-2. </span>The anatomy of a “retry storm”</h6>&#13;
</div></figure>&#13;
&#13;
<p>It seems that when the downstream service failed, our service—every single instance of it—entered its retry loop, making <em>thousands</em> of requests per second and bringing the network to its knees so severely that we were forced to essentially restart the entire system.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="retry storm" id="idm45983623254296"/>This is actually a very common kind of cascading failure known as a <em>retry storm</em>. In a retry storm, well-meaning logic intended to add resilience to a component, acts against the larger system. Very often, even when the conditions that caused the downstream service to go down are resolved, it can’t come back up because it’s instantly brought under too much load.</p>&#13;
&#13;
<p>But, retries are a good thing, right?</p>&#13;
&#13;
<p>Yes, but whenever you implement retry logic, you should always include a <em>backoff algorithm</em>, which we’ll conveniently discuss in the next section.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="Backoff Algorithms"><div class="sect2" id="section_ch09_backoff_algorithms">&#13;
<h2>Backoff Algorithms</h2>&#13;
&#13;
<p>When a request to a downstream service fails for any reason, “best” practice is to retry the request. But how long should you wait? If you wait too long, important work may be delayed. Too little and you risk overwhelming the target, the network, or both.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="backoff algorithms" id="ch09_term7"/>The common solution is to implement a backoff algorithm that introduces a delay between retries to reduce the frequency of attempts to a safe and acceptable rate.</p>&#13;
&#13;
<p>There are a variety of backoff algorithms available, the simplest of which is to include a short, fixed-duration pause between retries, as follows:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="nx">res</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">SendRequest</code><code class="p">()</code>&#13;
<code class="k">for</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
    <code class="nx">time</code><code class="p">.</code><code class="nx">Sleep</code><code class="p">(</code><code class="mi">2</code> <code class="o">*</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Second</code><code class="p">)</code>&#13;
    <code class="nx">res</code><code class="p">,</code> <code class="nx">err</code> <code class="p">=</code> <code class="nx">SendRequest</code><code class="p">()</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>In the previous snippet, <code>SendRequest</code> is used to issue a request, returning string and error values. However, if <code>err</code> isn’t <code>nil</code>, the code enters a loop, sleeping for two seconds before retrying, repeating indefinitely until it receives a nonerror response.</p>&#13;
&#13;
<p>In <a data-type="xref" href="#image_ch09_backoffs_1">Figure 9-3</a>, we illustrate the number of requests generated by 1,000 simulated instances using this method.<sup><a data-type="noteref" id="idm45983622826936-marker" href="ch09.xhtml#idm45983622826936">10</a></sup> As you can see, while the fixed-delay approach might reduce the request count compared to having no backoff at all, the overall number of requests is still quite consistently high.</p>&#13;
&#13;
<figure><div id="image_ch09_backoffs_1" class="figure">&#13;
<img src="Images/cngo_0903.png" alt="cngo 0903" width="2514" height="1354"/>&#13;
<h6><span class="label">Figure 9-3. </span>Requests/second of 1,000 simulated instances using a two-second retry delay</h6>&#13;
</div></figure>&#13;
&#13;
<p>A fixed-duration backoff delay might work fine if you have a very small number of retrying instances, but it doesn’t scale very well, since a sufficient number of requestors can still overwhelm the network.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="exponential backoff" id="idm45983622822536"/>However, we can’t always assume that any given service will have a small enough number of instances not to overwhelm the network with retries, or that our service will even be the only one retrying. For this reason, many backoff algorithms &#13;
<span class="keep-together">implement</span> an <em>exponential backoff</em>, in which the durations of the delays between retries roughly doubles with each attempt up to some fixed maximum.</p>&#13;
&#13;
<p>A very common (but flawed, as you’ll soon see) exponential backoff implementation might look something like the following:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="nx">res</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">SendRequest</code><code class="p">()</code>&#13;
<code class="nx">base</code><code class="p">,</code> <code class="nx">cap</code> <code class="o">:=</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Second</code><code class="p">,</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Minute</code>&#13;
&#13;
<code class="k">for</code> <code class="nx">backoff</code> <code class="o">:=</code> <code class="nx">base</code><code class="p">;</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code><code class="p">;</code> <code class="nx">backoff</code> <code class="o">&lt;&lt;=</code> <code class="mi">1</code> <code class="p">{</code>&#13;
    <code class="k">if</code> <code class="nx">backoff</code> <code class="p">&gt;</code> <code class="nx">cap</code> <code class="p">{</code>&#13;
        <code class="nx">backoff</code> <code class="p">=</code> <code class="nx">cap</code>&#13;
    <code class="p">}</code>&#13;
    <code class="nx">time</code><code class="p">.</code><code class="nx">Sleep</code><code class="p">(</code><code class="nx">backoff</code><code class="p">)</code>&#13;
    <code class="nx">res</code><code class="p">,</code> <code class="nx">err</code> <code class="p">=</code> <code class="nx">SendRequest</code><code class="p">()</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>In this snippet, we specify a starting duration, <code>base</code>, and a fixed maximum duration, <code>cap</code>. In the loop, the value of <code>backoff</code> starts at <code>base</code> and doubles each iteration to a maximum value of <code>cap</code>.</p>&#13;
&#13;
<p>You would think that this logic would help to mitigate the network load and retry request burden on downstream services. Simulating this implementation for 1,000 nodes, however, tells another story, illustrated in <a data-type="xref" href="#image_ch09_backoffs_2">Figure 9-4</a>.</p>&#13;
&#13;
<figure><div id="image_ch09_backoffs_2" class="figure">&#13;
<img src="Images/cngo_0904.png" alt="cngo 0904" width="2514" height="1354"/>&#13;
<h6><span class="label">Figure 9-4. </span>Requests/second of 1,000 simulated instances using an exponential backoff</h6>&#13;
</div></figure>&#13;
&#13;
<p>It would seem that having 1,000 nodes with exactly the same retry schedule still isn’t optimal, since the retries are now clustering, possibly generating enough load in the process to cause problems. So, in practice, pure exponential backoff doesn’t necessarily help as much we’d like.</p>&#13;
&#13;
<p class="pagebreak-before less_space"><a data-type="indexterm" data-primary="jitter" id="ch09_term9"/>It would seem that we need some way to spread the spikes out so that the retries occur at a roughly constant rate. The solution is to include an element of randomness, called <em>jitter</em>. Adding jitter to our previous backoff function results in something like the snippet here:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="nx">res</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">SendRequest</code><code class="p">()</code>&#13;
<code class="nx">base</code><code class="p">,</code> <code class="nx">cap</code> <code class="o">:=</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Second</code><code class="p">,</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Minute</code>&#13;
&#13;
<code class="k">for</code> <code class="nx">backoff</code> <code class="o">:=</code> <code class="nx">base</code><code class="p">;</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code><code class="p">;</code> <code class="nx">backoff</code> <code class="o">&lt;&lt;=</code> <code class="mi">1</code> <code class="p">{</code>&#13;
    <code class="k">if</code> <code class="nx">backoff</code> <code class="p">&gt;</code> <code class="nx">cap</code> <code class="p">{</code>&#13;
        <code class="nx">backoff</code> <code class="p">=</code> <code class="nx">cap</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="nx">jitter</code> <code class="o">:=</code> <code class="nx">rand</code><code class="p">.</code><code class="nx">Int63n</code><code class="p">(</code><code class="nb">int64</code><code class="p">(</code><code class="nx">backoff</code> <code class="o">*</code> <code class="mi">3</code><code class="p">))</code>&#13;
    <code class="nx">sleep</code> <code class="o">:=</code> <code class="nx">base</code> <code class="o">+</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Duration</code><code class="p">(</code><code class="nx">jitter</code><code class="p">)</code>&#13;
    <code class="nx">time</code><code class="p">.</code><code class="nx">Sleep</code><code class="p">(</code><code class="nx">sleep</code><code class="p">)</code>&#13;
    <code class="nx">res</code><code class="p">,</code> <code class="nx">err</code> <code class="p">=</code> <code class="nx">SendRequest</code><code class="p">()</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>Simulating running this code on 1,000 nodes produces the pattern presented in <a data-type="xref" href="#image_ch09_backoffs_3">Figure 9-5</a>.</p>&#13;
&#13;
<figure><div id="image_ch09_backoffs_3" class="figure">&#13;
<img src="Images/cngo_0905.png" alt="cngo 0905" width="2514" height="1354"/>&#13;
<h6><span class="label">Figure 9-5. </span>Requests/second of 1,000 simulated instances using an exponential backoff with jitter</h6>&#13;
</div></figure>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>The <code>rand</code> package’s top-level functions produce a deterministic sequence of values each time the program is run. If you don’t use the <code>rand.Seed</code> function to provide a new seed value, they behave as if seeded by <code>rand.Seed(1)</code> and always produce the same “random” sequence of numbers.</p>&#13;
</div>&#13;
&#13;
<p>When we use exponential backoff with jitter, the number of retries decreases over a short interval—so as not to overstress services that are trying to come up—and spreads them out over time so that they occur at an approximately constant rate.</p>&#13;
&#13;
<p>Who would have thought there was more to retrying requests than retrying requests?<a data-type="indexterm" data-primary="backoff algorithms" data-seealso="backoff, exponential backoff" data-startref="ch09_term7" id="idm45983622605464"/><a data-type="indexterm" data-primary="retries" data-startref="ch09_term8" id="idm45983622604248"/><a data-type="indexterm" data-primary="jitter" data-startref="ch09_term9" id="idm45983622603304"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="Circuit Breaking"><div class="sect2" id="image_ch09_circuit_breaking">&#13;
<h2>Circuit Breaking</h2>&#13;
&#13;
<p><a data-type="indexterm" data-primary="patterns" data-secondary="circuit breaker pattern" id="idm45983622601064"/><a data-type="indexterm" data-primary="circuit breaker pattern" id="idm45983622600088"/>We first introduced the Circuit Breaker pattern in <a data-type="xref" href="ch04.xhtml#chapter_4">Chapter 4</a> as a function that degrades potentially failing method calls as a way to prevent larger or cascading failures. That definition still holds, and because we’re not going to extend or change it much, we won’t dig into it in <em>too</em> much detail here.</p>&#13;
&#13;
<p>To review, the Circuit Breaker pattern tracks the number of consecutive failed requests made to a downstream component. If the failure count passes a certain threshold, the circuit is “opened,” and all attempts to issue additional requests fail immediately (or return some defined fallback). After a waiting period, the circuit automatically “closes,” resuming its normal state and allowing requests to be made normally.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Not all resilience patterns are defensive.</p>&#13;
&#13;
<p>Sometimes it pays to be a good neighbor.</p>&#13;
</div>&#13;
&#13;
<p>A properly applied Circuit Breaker pattern can make the difference between system recovery and cascading failure. In addition to the obvious benefits of not wasting resources or clogging the network with doomed requests, a circuit breaker (particularly one with a backoff function) can give a malfunctioning service enough room to recover, allowing it to come back up and restore correct service.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="sidebar_ch09_circuit_breaker_vs_throttle">&#13;
<h5>What’s the Difference Between Circuit Breaker and Throttle?</h5>&#13;
<p>At a quick glance, the Circuit Breaker pattern might seem to resemble a Throttle—after all they’re both resilience patterns that rate requests—but they really are two quite different things:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><em>Circuit Breaker</em> is generally applied only to <em>outgoing</em> requests. It usually doesn’t care one bit about the request rate: it’s only concerned with the number of failed requests, and only if they’re consecutive.</p>&#13;
</li>&#13;
<li>&#13;
<p><em>Throttle</em> works like the throttle in a car by limiting a number of requests—regardless of success or failure—to some maximum rate. It’s <em>typically</em> applied to incoming traffic, but there’s no rule that says it has to be.<a data-type="indexterm" data-primary="patterns" data-secondary="throttle pattern" id="idm45983622588616"/><a data-type="indexterm" data-primary="throttle pattern" id="idm45983622587640"/></p>&#13;
</li>&#13;
</ul>&#13;
</div></aside>&#13;
&#13;
<p>The Circuit Breaker pattern was covered in some detail in <a data-type="xref" href="ch04.xhtml#chapter_4">Chapter 4</a>, so that’s all we’re going to say about it here. Take a look at <a data-type="xref" href="ch04.xhtml#section_ch04_circuit_breaker">“Circuit Breaker”</a> for more background and code examples. The addition of jitter to the example’s backoff function is left as an exercise for the reader.<sup><a data-type="noteref" id="idm45983622584440-marker" href="ch09.xhtml#idm45983622584440">11</a></sup></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="Timeouts"><div class="sect2" id="idm45983622583784">&#13;
<h2>Timeouts</h2>&#13;
&#13;
<p><a data-type="indexterm" data-primary="timeouts" id="idm45983622582376"/>The importance of timeouts isn’t always appreciated. However, the ability for a client to recognize when a request is unlikely to be satisfied allows the client to release resources that it—and any upstream requestors it might be acting on behalf of—might otherwise hold on to. This holds just as true for a service, which may find itself holding onto requests until long after a client has given up.</p>&#13;
&#13;
<p>For example, imagine a basic service that queries a database. If that database should suddenly slow so that queries take a few seconds to complete, requests to the service—each holding onto a database connection—could accumulate, eventually depleting the connection pool. If the database is shared, it could even cause other services to fail, resulting in a cascading failure.</p>&#13;
&#13;
<p>If the service had timed out instead of holding on to the database, it could have degraded service instead of failing outright.</p>&#13;
&#13;
<p>In other words, if you think you’re going to fail, fail fast.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="Using Context for service-side timeouts"><div class="sect3" id="idm45983622579240">&#13;
<h3>Using Context for service-side timeouts</h3>&#13;
&#13;
<p>We first introduced <code>context.Context</code> back in <a data-type="xref" href="ch04.xhtml#chapter_4">Chapter 4</a> as Go’s idiomatic means of carrying deadlines and cancellation signals between processes.<sup><a data-type="noteref" id="idm45983622576120-marker" href="ch09.xhtml#idm45983622576120">12</a></sup> If you’d like a refresher, or just want to put yourself in the right frame of mind before continuing, go ahead and take a look at <a data-type="xref" href="ch04.xhtml#section_ch04_context">“The Context Package”</a>.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="context timeouts" id="idm45983622574120"/>You might also recall that later in the same chapter, in <a data-type="xref" href="ch04.xhtml#section_ch04_timeout">“Timeout”</a>, we covered the <em>Timeout</em> pattern, which uses <code>Context</code> to not only allow a process to stop waiting for an answer once it’s clear that a result may not be coming, but to also notify other functions with derived <code>Context</code>s to stop working and release any resources that they might also be holding on to.</p>&#13;
&#13;
<p>This ability to cancel not just local functions, but subfunctions, is so powerful that it’s generally considered good form for functions to accept a <code>Context</code> value if they have the potential to run longer than a caller might want to wait, which is almost always true if the call traverses a network.</p>&#13;
&#13;
<p>For this reason, there are many excellent samples of <code>Context</code>-accepting functions scattered throughout Go’s standard library. Many of these can be found in the <code>sql</code> package, which includes <code>Context</code>-accepting versions of many of its functions. For example, the <code>DB</code> struct’s <code>QueryRow</code> method has an equivalent <code>QueryRowContext</code> that accepts a <code>Context</code> value.</p>&#13;
&#13;
<p>A function that uses this technique to provide the username of a user based on an ID value might look something like the following:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">func</code> <code class="nx">UserName</code><code class="p">(</code><code class="nx">ctx</code> <code class="nx">context</code><code class="p">.</code><code class="nx">Context</code><code class="p">,</code> <code class="nx">id</code> <code class="kt">int</code><code class="p">)</code> <code class="p">(</code><code class="kt">string</code><code class="p">,</code> <code class="kt">error</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="kd">const</code> <code class="nx">query</code> <code class="p">=</code> <code class="s">"SELECT username FROM users WHERE id=?"</code>&#13;
&#13;
    <code class="nx">dctx</code><code class="p">,</code> <code class="nx">cancel</code> <code class="o">:=</code> <code class="nx">context</code><code class="p">.</code><code class="nx">WithTimeout</code><code class="p">(</code><code class="nx">ctx</code><code class="p">,</code> <code class="mi">15</code><code class="o">*</code><code class="nx">time</code><code class="p">.</code><code class="nx">Second</code><code class="p">)</code>&#13;
    <code class="k">defer</code> <code class="nx">cancel</code><code class="p">()</code>&#13;
&#13;
    <code class="kd">var</code> <code class="nx">username</code> <code class="kt">string</code>&#13;
    <code class="nx">err</code> <code class="o">:=</code> <code class="nx">db</code><code class="p">.</code><code class="nx">QueryRowContext</code><code class="p">(</code><code class="nx">dctx</code><code class="p">,</code> <code class="nx">query</code><code class="p">,</code> <code class="nx">id</code><code class="p">).</code><code class="nx">Scan</code><code class="p">(</code><code class="o">&amp;</code><code class="nx">username</code><code class="p">)</code>&#13;
&#13;
    <code class="k">return</code> <code class="nx">username</code><code class="p">,</code> <code class="nx">err</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>The <code>UserName</code> function accepts a <code>context.Context</code> and an <code>id</code> integer, but it also creates its own derived <code>Context</code> with a rather long timeout. This approach provides a default timeout that automatically releases any open connections after 15 seconds—longer than many clients are likely to be willing to wait—while also being responsive to cancellation signals from the caller.</p>&#13;
&#13;
<p>The responsiveness to outside cancellation signals can be quite useful. The <code>http</code> framework provides yet another excellent example of this, as demonstrated in the following <code>UserGetHandler</code> HTTP handler function:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">func</code> <code class="nx">UserGetHandler</code><code class="p">(</code><code class="nx">w</code> <code class="nx">http</code><code class="p">.</code><code class="nx">ResponseWriter</code><code class="p">,</code> <code class="nx">r</code> <code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Request</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="nx">vars</code> <code class="o">:=</code> <code class="nx">mux</code><code class="p">.</code><code class="nx">Vars</code><code class="p">(</code><code class="nx">r</code><code class="p">)</code>&#13;
    <code class="nx">id</code> <code class="o">:=</code> <code class="nx">vars</code><code class="p">[</code><code class="s">"id"</code><code class="p">]</code>&#13;
&#13;
    <code class="c1">// Get the request's context. This context is canceled when</code>&#13;
    <code class="c1">// the client's connection closes, the request is canceled</code>&#13;
    <code class="c1">// (with HTTP/2), or when the ServeHTTP method returns.</code>&#13;
    <code class="nx">rctx</code> <code class="o">:=</code> <code class="nx">r</code><code class="p">.</code><code class="nx">Context</code><code class="p">()</code>&#13;
&#13;
    <code class="nx">ctx</code><code class="p">,</code> <code class="nx">cancel</code> <code class="o">:=</code> <code class="nx">context</code><code class="p">.</code><code class="nx">WithTimeout</code><code class="p">(</code><code class="nx">rctx</code><code class="p">,</code> <code class="mi">10</code><code class="o">*</code><code class="nx">time</code><code class="p">.</code><code class="nx">Second</code><code class="p">)</code>&#13;
    <code class="k">defer</code> <code class="nx">cancel</code><code class="p">()</code>&#13;
&#13;
    <code class="nx">username</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">UserName</code><code class="p">(</code><code class="nx">ctx</code><code class="p">,</code> <code class="nx">id</code><code class="p">)</code>&#13;
&#13;
    <code class="k">switch</code> <code class="p">{</code>&#13;
    <code class="k">case</code> <code class="nx">errors</code><code class="p">.</code><code class="nx">Is</code><code class="p">(</code><code class="nx">err</code><code class="p">,</code> <code class="nx">sql</code><code class="p">.</code><code class="nx">ErrNoRows</code><code class="p">):</code>&#13;
        <code class="nx">http</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code> <code class="s">"no such user"</code><code class="p">,</code> <code class="nx">http</code><code class="p">.</code><code class="nx">StatusNotFound</code><code class="p">)</code>&#13;
    <code class="k">case</code> <code class="nx">errors</code><code class="p">.</code><code class="nx">Is</code><code class="p">(</code><code class="nx">err</code><code class="p">,</code> <code class="nx">context</code><code class="p">.</code><code class="nx">DeadlineExceeded</code><code class="p">):</code>&#13;
        <code class="nx">http</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code> <code class="s">"database timeout"</code><code class="p">,</code> <code class="nx">http</code><code class="p">.</code><code class="nx">StatusGatewayTimeout</code><code class="p">)</code>&#13;
    <code class="k">case</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code><code class="p">:</code>&#13;
        <code class="nx">http</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code> <code class="nx">err</code><code class="p">.</code><code class="nx">Error</code><code class="p">(),</code> <code class="nx">http</code><code class="p">.</code><code class="nx">StatusInternalServerError</code><code class="p">)</code>&#13;
    <code class="k">default</code><code class="p">:</code>&#13;
        <code class="nx">w</code><code class="p">.</code><code class="nx">Write</code><code class="p">([]</code><code class="nb">byte</code><code class="p">(</code><code class="nx">username</code><code class="p">))</code>&#13;
    <code class="p">}</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>In <code>UserGetHandler</code>, the first thing we do is retrieve the request’s <code>Context</code> via its &#13;
<span class="keep-together"><code>Context</code></span> method. Conveniently, this <code>Context</code> is canceled when the client’s connection closes, when the request is canceled (with HTTP/2), or when the <code>ServeHTTP</code> method returns.</p>&#13;
&#13;
<p>From this we create a derived context, applying our own explicit timeout, which will cancel the <code>Context</code> after 10 seconds, no matter what.</p>&#13;
&#13;
<p>Because the derived context is passed to the <code>UserName</code> function, we are able to draw a direct causative line between closing the HTTP request and closing the database connection: if the request’s <code>Context</code> closes, all derived <code>Context</code>s close as well, ultimately ensuring that all open resources are released as well in a loosely coupled manner.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="Timing out HTTP/REST client calls"><div class="sect3" id="idm45983622578616">&#13;
<h3>Timing out HTTP/REST client calls</h3>&#13;
&#13;
<p>Back in <a data-type="xref" href="ch08.xhtml#sidebar_ch08_convenience_functions">“A Possible Pitfall of Convenience Functions”</a>, we presented one of the pitfalls of the <code>http</code> “convenience functions” like <code>http.Get</code> and <code>http.Post</code>: that they use the default timeout. Unfortunately, the default timeout value is <code>0</code>, which Go interprets as “no timeout.”</p>&#13;
&#13;
<p>The mechanism we presented at the time for setting timeouts for client methods was to create a custom <code>Client</code> value with a nonzero <code>Timeout</code> value, as follows:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">var</code> <code class="nx">client</code> <code class="p">=</code> <code class="o">&amp;</code><code class="nx">http</code><code class="p">.</code><code class="nx">Client</code><code class="p">{</code>&#13;
    <code class="nx">Timeout</code><code class="p">:</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Second</code> <code class="o">*</code> <code class="mi">10</code><code class="p">,</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="nx">response</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">client</code><code class="p">.</code><code class="nx">Get</code><code class="p">(</code><code class="nx">url</code><code class="p">)</code></pre>&#13;
&#13;
<p>This works perfectly fine, and in fact, will cancel a request in exactly the same way as if its <code>Context</code> is canceled. But what if you want to use an existing or derived <code>Context</code> value? For that you’ll need access to the underlying <code>Context</code>, which you can get by using <code>http.NewRequestWithContext</code>, the <code>Context</code>-accepting equivalent of <code>http.NewRequest</code>, which allows a programmer to specify a <code>Context</code> that controls the entire lifetime of the request and its response.</p>&#13;
&#13;
<p>This isn’t as much of a divergence as it might seem. In fact, looking at the source code for the <code>Get</code> method on the <code>http.Client</code> shows that under the covers, it’s just using <code>NewRequest</code>:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">func</code> <code class="p">(</code><code class="nx">c</code> <code class="o">*</code><code class="nx">Client</code><code class="p">)</code> <code class="nx">Get</code><code class="p">(</code><code class="nx">url</code> <code class="kt">string</code><code class="p">)</code> <code class="p">(</code><code class="nx">resp</code> <code class="o">*</code><code class="nx">Response</code><code class="p">,</code> <code class="nx">err</code> <code class="kt">error</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="nx">req</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">NewRequest</code><code class="p">(</code><code class="s">"GET"</code><code class="p">,</code> <code class="nx">url</code><code class="p">,</code> <code class="kc">nil</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="k">return</code> <code class="kc">nil</code><code class="p">,</code> <code class="nx">err</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="k">return</code> <code class="nx">c</code><code class="p">.</code><code class="nx">Do</code><code class="p">(</code><code class="nx">req</code><code class="p">)</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>As you can see, the standard <code>Get</code> method calls <code>NewRequest</code> to create a <code>*Request</code> value, passing it the method name and URL (the last parameter accepts an optional <code>io.Reader</code> for the request body, which we don’t need here). A call to the <code>Do</code> function executes the request proper.</p>&#13;
&#13;
<p>Not counting an error check and the return, the entire method consists of just one call. It would seem that if we wanted to implement similar functionality that also accepts a <code>Context</code> value, we could do so without much hassle.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="GetContext function" id="idm45983622146776"/>One way to do this might be to implement a <code>GetContext</code> function that accepts a &#13;
<span class="keep-together"><code>Context</code></span> value:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">type</code> <code class="nx">ClientContext</code> <code class="kd">struct</code> <code class="p">{</code>&#13;
    <code class="nx">http</code><code class="p">.</code><code class="nx">Client</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="kd">func</code> <code class="p">(</code><code class="nx">c</code> <code class="o">*</code><code class="nx">ClientContext</code><code class="p">)</code> <code class="nx">GetContext</code><code class="p">(</code><code class="nx">ctx</code> <code class="nx">context</code><code class="p">.</code><code class="nx">Context</code><code class="p">,</code> <code class="nx">url</code> <code class="kt">string</code><code class="p">)</code>&#13;
        <code class="p">(</code><code class="nx">resp</code> <code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Response</code><code class="p">,</code> <code class="nx">err</code> <code class="kt">error</code><code class="p">)</code> <code class="p">{</code>&#13;
&#13;
    <code class="nx">req</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">http</code><code class="p">.</code><code class="nx">NewRequestWithContext</code><code class="p">(</code><code class="nx">ctx</code><code class="p">,</code> <code class="s">"GET"</code><code class="p">,</code> <code class="nx">url</code><code class="p">,</code> <code class="kc">nil</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="k">return</code> <code class="kc">nil</code><code class="p">,</code> <code class="nx">err</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="k">return</code> <code class="nx">c</code><code class="p">.</code><code class="nx">Do</code><code class="p">(</code><code class="nx">req</code><code class="p">)</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>Our new <code>GetContext</code> function is functionally identical to the canonical <code>Get</code>, except that it also accepts a <code>Context</code> value, which it uses to call <code>http.NewRequestWithContext</code> instead of <code>http.NewRequest</code>.</p>&#13;
&#13;
<p>Using our new <code>ClientContext</code> would be very similar to using a standard <code>http.Client</code> value, except instead of calling <code>client.Get</code> we’d call <code>client.GetContext</code> (and pass along a <code>Context</code> value, of course):</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">func</code> <code class="nx">main</code><code class="p">()</code> <code class="p">{</code>&#13;
    <code class="nx">client</code> <code class="o">:=</code> <code class="o">&amp;</code><code class="nx">ClientContext</code><code class="p">{}</code>&#13;
    <code class="nx">ctx</code><code class="p">,</code> <code class="nx">cancel</code> <code class="o">:=</code> <code class="nx">context</code><code class="p">.</code><code class="nx">WithTimeout</code><code class="p">(</code><code class="nx">context</code><code class="p">.</code><code class="nx">Background</code><code class="p">(),</code> <code class="mi">5</code><code class="o">*</code><code class="nx">time</code><code class="p">.</code><code class="nx">Second</code><code class="p">)</code>&#13;
    <code class="k">defer</code> <code class="nx">cancel</code><code class="p">()</code>&#13;
&#13;
    <code class="nx">response</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">client</code><code class="p">.</code><code class="nx">GetContext</code><code class="p">(</code><code class="nx">ctx</code><code class="p">,</code> <code class="s">"http://www.example.com"</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="nx">log</code><code class="p">.</code><code class="nx">Fatal</code><code class="p">(</code><code class="nx">err</code><code class="p">)</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="nx">bytes</code><code class="p">,</code> <code class="nx">_</code> <code class="o">:=</code> <code class="nx">ioutil</code><code class="p">.</code><code class="nx">ReadAll</code><code class="p">(</code><code class="nx">response</code><code class="p">.</code><code class="nx">Body</code><code class="p">)</code>&#13;
    <code class="nx">fmt</code><code class="p">.</code><code class="nx">Println</code><code class="p">(</code><code class="nb">string</code><code class="p">(</code><code class="nx">bytes</code><code class="p">))</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>But does it work? It’s not a <em>proper</em> test with a testing library, but we can manually kick the tires by setting the deadline to <code>0</code> and running it:</p>&#13;
&#13;
<pre data-type="programlisting">$ go run .&#13;
2020/08/25 14:03:16 Get "http://www.example.com": context deadline exceeded&#13;
exit status 1</pre>&#13;
&#13;
<p>And it would seem that it does! Excellent.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="Timing out gRPC client calls"><div class="sect3" id="idm45983622268056">&#13;
<h3>Timing out gRPC client calls</h3>&#13;
&#13;
<p><a data-type="indexterm" data-primary="gRPC" id="idm45983621852696"/><a data-type="indexterm" data-primary="timeouts" id="ch09_term11"/>Just like <code>http.Client</code>, gRPC clients default to “no timeout,” but also allow timeouts to be explicitly set.</p>&#13;
&#13;
<p>As we saw in <a data-type="xref" href="ch08.xhtml#section_ch08_impl_grpc_client">“Implementing the gRPC client”</a>, gRPC clients typically use the <code>grpc.Dial</code> function to establish a connection to a client, and that a list of <code>grpc.DialOption</code> values—constructed via functions like <code>grpc.WithInsecure</code> and <code>grpc.WithBlock</code>—can be passed to it to configure how that connection is set up.</p>&#13;
&#13;
<p>Among these options is <code>grpc.WithTimeout</code>, which can be used to configure a client dialing timeout:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="nx">opts</code> <code class="o">:=</code> <code class="p">[]</code><code class="nx">grpc</code><code class="p">.</code><code class="nx">DialOption</code><code class="p">{</code>&#13;
    <code class="nx">grpc</code><code class="p">.</code><code class="nx">WithInsecure</code><code class="p">(),</code>&#13;
    <code class="nx">grpc</code><code class="p">.</code><code class="nx">WithBlock</code><code class="p">(),</code>&#13;
    <code class="nx">grpc</code><code class="p">.</code><code class="nx">WithTimeout</code><code class="p">(</code><code class="mi">5</code> <code class="o">*</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Second</code><code class="p">),</code>&#13;
<code class="p">}</code>&#13;
<code class="nx">conn</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">grpc</code><code class="p">.</code><code class="nx">Dial</code><code class="p">(</code><code class="nx">serverAddr</code><code class="p">,</code> <code class="nx">opts</code><code class="o">...</code><code class="p">)</code></pre>&#13;
&#13;
<p>However, while <code>grpc.WithTimeout</code> might seem convenient on the face of it, it’s actually been deprecated for some time, largely because its mechanism is inconsistent (and redundant) with the preferred <code>Context</code> timeout method. We show it here for the sake of completion.</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>The <code>grpc.WithTimeout</code> option is deprecated and will eventually be removed. Use <code>grpc.DialContext</code> and <code>context.WithTimeout</code> instead.</p>&#13;
</div>&#13;
&#13;
<p>Instead, the preferred method of setting a gRPC dialing timeout is the very convenient (for us) <code>grpc.DialContext</code> function, which allows us to use (or reuse) a <code>context.Context</code> value. This is actually doubly useful, because gRPC service methods accept a <code>Context</code> value anyway, so there really isn’t even any additional work to be done:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">func</code> <code class="nx">TimeoutKeyValueGet</code><code class="p">()</code> <code class="o">*</code><code class="nx">pb</code><code class="p">.</code><code class="nx">Response</code> <code class="p">{</code>&#13;
    <code class="c1">// Use context to set a 5-second timeout.</code>&#13;
    <code class="nx">ctx</code><code class="p">,</code> <code class="nx">cancel</code> <code class="o">:=</code> <code class="nx">context</code><code class="p">.</code><code class="nx">WithTimeout</code><code class="p">(</code><code class="nx">context</code><code class="p">.</code><code class="nx">Background</code><code class="p">(),</code> <code class="mi">5</code> <code class="o">*</code> <code class="nx">time</code><code class="p">.</code><code class="nx">Second</code><code class="p">)</code>&#13;
    <code class="k">defer</code> <code class="nx">cancel</code><code class="p">()</code>&#13;
&#13;
    <code class="c1">// We can still set other options as desired.</code>&#13;
    <code class="nx">opts</code> <code class="o">:=</code> <code class="p">[]</code><code class="nx">grpc</code><code class="p">.</code><code class="nx">DialOption</code><code class="p">{</code><code class="nx">grpc</code><code class="p">.</code><code class="nx">WithInsecure</code><code class="p">(),</code> <code class="nx">grpc</code><code class="p">.</code><code class="nx">WithBlock</code><code class="p">()}</code>&#13;
&#13;
    <code class="nx">conn</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">grpc</code><code class="p">.</code><code class="nx">DialContext</code><code class="p">(</code><code class="nx">ctx</code><code class="p">,</code> <code class="nx">serverAddr</code><code class="p">,</code> <code class="nx">opts</code><code class="o">...</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="nx">grpclog</code><code class="p">.</code><code class="nx">Fatalf</code><code class="p">(</code><code class="nx">err</code><code class="p">)</code>&#13;
    <code class="p">}</code>&#13;
    <code class="k">defer</code> <code class="nx">conn</code><code class="p">.</code><code class="nx">Close</code><code class="p">()</code>&#13;
&#13;
    <code class="nx">client</code> <code class="o">:=</code> <code class="nx">pb</code><code class="p">.</code><code class="nx">NewKeyValueClient</code><code class="p">(</code><code class="nx">conn</code><code class="p">)</code>&#13;
&#13;
    <code class="c1">// We can reuse the same Context in the client calls.</code>&#13;
    <code class="nx">response</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">client</code><code class="p">.</code><code class="nx">Get</code><code class="p">(</code><code class="nx">ctx</code><code class="p">,</code> <code class="o">&amp;</code><code class="nx">pb</code><code class="p">.</code><code class="nx">GetRequest</code><code class="p">{</code><code class="nx">Key</code><code class="p">:</code> <code class="nx">key</code><code class="p">})</code>&#13;
    <code class="k">if</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="nx">grpclog</code><code class="p">.</code><code class="nx">Fatalf</code><code class="p">(</code><code class="nx">err</code><code class="p">)</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="k">return</code> <code class="nx">response</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>As advertised, <code>TimeoutKeyValueGet</code> uses <code>grpc.DialContext</code>—to which we pass a <code>context.Context</code> value with a 5-second timeout—instead of <code>grpc.Dial</code>. The <code>opts</code> list is otherwise identical except, obviously, that it no longer includes <code>grpc.WithTimeout</code>.</p>&#13;
&#13;
<p>Note the <code>client.Get</code> method call. As we mentioned previously, gRPC service methods accept a <code>Context</code> parameter, so we simply reuse the existing one. Importantly, &#13;
<span class="keep-together">reusing</span> the same <code>Context</code> value will constrain both operations under the same timeout calculation—a <code>Context</code> will time out regardless of how it’s used—so be sure to take that into consideration when planning your timeout values.<a data-type="indexterm" data-primary="timeouts" data-startref="ch09_term11" id="idm45983621578744"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="Idempotence"><div class="sect2" id="section_ch09_idempotence">&#13;
<h2>Idempotence</h2>&#13;
&#13;
<p><a data-type="indexterm" data-primary="idempotence" id="ch09_term12"/>As we discussed at the top of <a data-type="xref" href="ch04.xhtml#chapter_4">Chapter 4</a>, cloud native applications by definition exist in and are subject to all of the idiosyncrasies of a networked world. It’s a plain fact of life that networks—all networks—are unreliable, and messages sent across them don’t always arrive at their destination on time (or at all).</p>&#13;
&#13;
<p>What’s more, if you send a message but don’t get a response, you have no way to know what happened. Did the message get lost on its way to the recipient? Did the recipient get the message, and the response get lost? Maybe everything is working fine, but the round trip is just taking a little longer than usual?</p>&#13;
&#13;
<p>In such a situation, the only option is to send the message again. But it’s not enough to cross your fingers and hope for the best. It’s important to plan for this inevitability by making it safe to resend messages by designing the functions for <em>idempotence</em>.</p>&#13;
&#13;
<p>You might recall that we briefly introduced the concept of idempotence in <a data-type="xref" href="ch05.xhtml#section_ch05_idempotence">“What Is Idempotence and Why Does It Matter?”</a>, in which we defined an idempotent operation as one that has the same effect after multiple applications as a single application. As the designers of HTTP understood, it also happens to be an important property of any cloud native API that guarantees that any communication can be safely repeated (see <a data-type="xref" href="#sidebar_ch09_origins_of_idempotence">“The Origins of Idempotence on the Web”</a> for a bit on that history).</p>&#13;
&#13;
<p>The actual means of achieving idempotence will vary from service to service, but there are some consistent patterns that we’ll review in the remainder of this section.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="sidebar_ch09_origins_of_idempotence">&#13;
<h5>The Origins of Idempotence on the Web</h5>&#13;
<p><a data-type="indexterm" data-primary="HTTP/1.1 standard" id="idm45983621567656"/>The concepts of idempotence and safety, at least in the context of networked services, were first defined way back in 1997 in the HTTP/1.1 standard.<sup><a data-type="noteref" id="idm45983621566664-marker" href="ch09.xhtml#idm45983621566664">13</a></sup></p>&#13;
&#13;
<p>An interesting aside: that ground-breaking proposal, as well as the HTTP/1.0 “informational draft” that preceded it the year before,<sup><a data-type="noteref" id="idm45983621564248-marker" href="ch09.xhtml#idm45983621564248">14</a></sup> were authored by two greats.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="Berners-Lee, Timothy John" id="idm45983621562008"/>The primary author of the original HTTP/1.0 draft (and the last author of the proposed HTTP/1.1 standard) was Sir Timothy John Berners-Lee, who is credited for inventing the World Wide Web, the first web browser, and the fundamental protocols and algorithms allowing the Web to scale—for which he was awarded with an ACM Turing Award, a knighthood, and various honorary degrees.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="Fielding, Roy" id="idm45983621560456"/><a data-type="indexterm" data-primary="REST" id="idm45983621559752"/>The primary author of the proposed HTTP/1.1 standard (and the second author of the original HTTP/1.0 draft) was Roy Fielding, then a graduate student at the University of California Irvine. Despite being one of the original authors of the World Wide Web, Fielding is perhaps known for his doctoral dissertation, in which he invented REST.<sup><a data-type="noteref" id="idm45983621558600-marker" href="ch09.xhtml#idm45983621558600">15</a></sup></p>&#13;
</div></aside>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="How do I make my service idempotent?"><div class="sect3" id="idm45983621556248">&#13;
<h3>How do I make my service idempotent?</h3>&#13;
&#13;
<p>Idempotence isn’t baked into the logic of any particular framework. Even in HTTP—and by extension, REST—idempotence is a matter of convention and isn’t explicitly enforced. There’s nothing stopping you from—by oversight or on purpose—implementing a nonidempotent GET if you really want to.<sup><a data-type="noteref" id="idm45983621554584-marker" href="ch09.xhtml#idm45983621554584">16</a></sup></p>&#13;
&#13;
<p>One of the reasons that idempotence is sometimes so tricky is because it relies on logic built into the core application, rather than at the REST or gRPC API layer. For example, if back in <a data-type="xref" href="ch05.xhtml#chapter_5">Chapter 5</a> we had wanted to make our key-value store consistent with traditional CRUD (create, read, update, and delete) operations (and therefore <em>not</em> idempotent) we might have done something like this:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">var</code> <code class="nx">store</code> <code class="p">=</code> <code class="nb">make</code><code class="p">(</code><code class="kd">map</code><code class="p">[</code><code class="kt">string</code><code class="p">]</code><code class="kt">string</code><code class="p">)</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">Create</code><code class="p">(</code><code class="nx">key</code><code class="p">,</code> <code class="nx">value</code> <code class="kt">string</code><code class="p">)</code> <code class="kt">error</code> <code class="p">{</code>&#13;
    <code class="k">if</code> <code class="nx">_</code><code class="p">,</code> <code class="nx">ok</code> <code class="o">:=</code> <code class="nx">store</code><code class="p">[</code><code class="nx">key</code><code class="p">];</code> <code class="nx">ok</code> <code class="p">{</code>&#13;
        <code class="k">return</code> <code class="nx">errors</code><code class="p">.</code><code class="nx">New</code><code class="p">(</code><code class="s">"duplicate key"</code><code class="p">)</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="nx">store</code><code class="p">[</code><code class="nx">key</code><code class="p">]</code> <code class="p">=</code> <code class="nx">value</code>&#13;
    <code class="k">return</code> <code class="kc">nil</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">Update</code><code class="p">(</code><code class="nx">key</code><code class="p">,</code> <code class="nx">value</code> <code class="kt">string</code><code class="p">)</code> <code class="kt">error</code> <code class="p">{</code>&#13;
    <code class="k">if</code> <code class="nx">_</code><code class="p">,</code> <code class="nx">ok</code> <code class="o">:=</code> <code class="nx">store</code><code class="p">[</code><code class="nx">key</code><code class="p">];</code> <code class="p">!</code><code class="nx">ok</code> <code class="p">{</code>&#13;
        <code class="k">return</code> <code class="nx">errors</code><code class="p">.</code><code class="nx">New</code><code class="p">(</code><code class="s">"no such key"</code><code class="p">)</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="nx">store</code><code class="p">[</code><code class="nx">key</code><code class="p">]</code> <code class="p">=</code> <code class="nx">value</code>&#13;
    <code class="k">return</code> <code class="kc">nil</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">Delete</code><code class="p">(</code><code class="nx">key</code> <code class="kt">string</code><code class="p">)</code> <code class="kt">error</code> <code class="p">{</code>&#13;
    <code class="k">if</code> <code class="nx">_</code><code class="p">,</code> <code class="nx">ok</code> <code class="o">:=</code> <code class="nx">store</code><code class="p">[</code><code class="nx">key</code><code class="p">];</code> <code class="nx">ok</code> <code class="p">{</code>&#13;
        <code class="k">return</code> <code class="nx">errors</code><code class="p">.</code><code class="nx">New</code><code class="p">(</code><code class="s">"no such key"</code><code class="p">)</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="nb">delete</code><code class="p">(</code><code class="nx">store</code><code class="p">,</code> <code class="nx">key</code><code class="p">)</code>&#13;
    <code class="k">return</code> <code class="kc">nil</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>This CRUD-like service implementation may be entirely well-meaning, but if any of these methods have to be repeated the result would be an error. What’s more, there’s also a fair amount of logic involved in checking against the current state which wouldn’t be necessary in an equivalent idempotent implementation like the &#13;
<span class="keep-together">following</span>:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">var</code> <code class="nx">store</code> <code class="p">=</code> <code class="nb">make</code><code class="p">(</code><code class="kd">map</code><code class="p">[</code><code class="kt">string</code><code class="p">]</code><code class="kt">string</code><code class="p">)</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">Set</code><code class="p">(</code><code class="nx">key</code><code class="p">,</code> <code class="nx">value</code> <code class="kt">string</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="nx">store</code><code class="p">[</code><code class="nx">key</code><code class="p">]</code> <code class="p">=</code> <code class="nx">value</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">Delete</code><code class="p">(</code><code class="nx">key</code> <code class="kt">string</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="nb">delete</code><code class="p">(</code><code class="nx">store</code><code class="p">,</code> <code class="nx">key</code><code class="p">)</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>This version is a <em>lot</em> simpler, in more than one way. First, we no longer need separate “create” and “update” operations, so we can combine these into a single <code>Set</code> function. Also, not having to check the current state with each operation reduces the logic in each method, a benefit that continues to pay dividends as the service increases in complexity.</p>&#13;
&#13;
<p>Finally, if an operation has to be repeated, it’s no big deal. For both the <code>Set</code> &#13;
<span class="keep-together">and <code>Delete</code> functions,</span> multiple identical calls will have the same result. They are &#13;
<span class="keep-together">idempotent</span>.<a data-type="indexterm" data-primary="idempotence" data-startref="ch09_term12" id="idm45983621387944"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="What about scalar operations?"><div class="sect3" id="idm45983621386808">&#13;
<h3>What about scalar operations?</h3>&#13;
&#13;
<p><a data-type="indexterm" data-primary="scalar operations" id="idm45983621385432"/><a data-type="indexterm" data-primary="scalar values" id="idm45983621384728"/>“So,” you might say, “that’s all well and good for operations that are either <em>done</em> or <em>not done</em>, but what about more complex operations? Operations on scalar values, for example?”</p>&#13;
&#13;
<p>That’s a fair question. After all, it’s one thing to PUT a thing in a place: it’s either been PUT, or it hasn’t. All you have to do is not return an error for re-PUTs. Fine.</p>&#13;
&#13;
<p>But what about an operation like “add $500 to account 12345”? Such a request might carry a JSON payload that looks something like the following:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="json"><code class="p">{</code>&#13;
    <code class="nt">"credit"</code><code class="p">:{</code>&#13;
        <code class="nt">"accountID"</code><code class="p">:</code> <code class="mi">12345</code><code class="p">,</code>&#13;
        <code class="nt">"amount"</code><code class="p">:</code> <code class="mi">500</code>&#13;
    <code class="p">}</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>Repeated applications of this operation would lead to an extra $500 going to account 12345, and while the owner of the account might not mind so much, the bank probably would.</p>&#13;
&#13;
<p>But consider what happens when we add a <code>transactionID</code> value to our JSON &#13;
<span class="keep-together">payload</span>:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="json"><code class="p">{</code>&#13;
    <code class="nt">"credit"</code><code class="p">:{</code>&#13;
        <code class="nt">"accountID"</code><code class="p">:</code> <code class="mi">12345</code><code class="p">,</code>&#13;
        <code class="nt">"amount"</code><code class="p">:</code> <code class="mi">500</code><code class="p">,</code>&#13;
        <code class="nt">"transactionID"</code><code class="p">:</code> <code class="mi">789</code>&#13;
    <code class="p">}</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>It may require some more bookkeeping, but this approach provides a workable solution to our dilemma. By tracking <code>transactionID</code> values, the recipient can safely identify and reject duplicate transactions. Idempotence achieved!</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect1" data-pdf-bookmark="Service Redundancy"><div class="sect1" id="section_ch09_redundancy">&#13;
<h1>Service Redundancy</h1>&#13;
&#13;
<p><a data-type="indexterm" data-primary="reliability" data-seealso="redundancy" id="idm45983621191016"/><a data-type="indexterm" data-primary="redundancy" data-seealso="messaging redundancy" id="ch09_term13"/>Redundancy—the duplication of critical components or functions of a system with the intention of increasing reliability of the system—is often the first line of defense when it comes to increasing resilience in the face of failure.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="messaging redundancy" id="idm45983621188184"/><a data-type="indexterm" data-primary="retries" id="idm45983621187480"/>We’ve already discussed one particular kind of redundancy—messaging redundancy, also known as “retries”—in <a data-type="xref" href="#section_ch09_retries">“Play It Again: Retrying Requests”</a>. In this section, however, we’ll consider the value of replicating critical system components so that if any one fails, one or more others are there to pick up the slack.</p>&#13;
&#13;
<p>In a public cloud, this would mean deploying your component to multiple server instances, ideally across multiple zones or even across multiple regions. In a container orchestration platform like Kubernetes, this may even just be a matter of setting your replica count to a value greater than one.</p>&#13;
&#13;
<p>As interesting as this subject is, however, we won’t actually spend too much time on it. Service replication is an architectural subject that’s been thoroughly covered in many other sources.<sup><a data-type="noteref" id="idm45983621184232-marker" href="ch09.xhtml#idm45983621184232">17</a></sup> This is supposed to be a Go book, after all. But still, we’d be remiss to have an entire chapter about resilience and not even mention it.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45983621182408">&#13;
<h5>A Word of Caution: Fault Masking</h5>&#13;
<p><a data-type="indexterm" data-primary="fault masking" id="ch09_term14"/><em>Fault masking</em> occurs when a system fault is invisibly compensated for without being explicitly detected.</p>&#13;
&#13;
<p>For example, imagine a system with three service nodes, all performing a share of the tasks. If one node goes bad and the other nodes can compensate, you might never notice anything wrong. The fault has been masked.</p>&#13;
&#13;
<p>Fault masking can conceal possibly progressive faults, and may eventually—and quietly—result in a loss of protective redundancy, often with a sudden and catastrophic outcome.</p>&#13;
&#13;
<p>To prevent fault masking, it’s important to include service health checks—which we’ll discuss in <a data-type="xref" href="#section_ch09_health_checks">“Healthy Health Checks”</a>—that accurately report the health of a service instance.<a data-type="indexterm" data-primary="fault masking" data-startref="ch09_term14" id="idm45983621177048"/></p>&#13;
</div></aside>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="Designing for Redundancy"><div class="sect2" id="idm45983621175976">&#13;
<h2>Designing for Redundancy</h2>&#13;
&#13;
<p>The effort involved in designing a system so that its functions can be replicated across multiple instances can yield significant dividends. But exactly how much? Well…a lot. You can feel free to take a look at the following box if you’re interested in the math, but if you don’t, you can just trust me on this one.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="sidebar_ch09_availability_by_the_numbers">&#13;
<h5>Reliability by the Numbers</h5>&#13;
<p>Imagine, if you will, a service with “two-nines”—or 99%—of availability. Any given request to this system it has a theoretical probability of success of 0.99, which is denoted <math alttext="upper A Subscript s">&#13;
  <msub><mi>A</mi> <mi>s</mi> </msub>&#13;
</math>. This actually isn’t very good, but that’s the point.</p>&#13;
&#13;
<p>What kind of availability can you get if two of these identical instances are arranged in parallel, so that both have to be down to interrupt service?<sup><a data-type="noteref" id="idm45983621169368-marker" href="ch09.xhtml#idm45983621169368">18</a></sup> This kind of arrangement can be diagrammed as shown here:</p>&#13;
&#13;
<figure><div class="figure">&#13;
<img src="Images/cngo_09in01.png" alt="cngo 09in01" width="392" height="201"/>&#13;
<h6/>&#13;
</div></figure>&#13;
&#13;
<p>What’s the resulting system availability? What we really want to know is: what’s the probability that both instances will be <em>unavailable</em>? To answer this, we take the product of each component’s probability of failure:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper U Subscript s Baseline equals left-parenthesis 1 minus upper A 1 right-parenthesis times left-parenthesis 1 minus upper A 2 right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <msub><mi>U</mi> <mi>s</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <mfenced separators="" open="(" close=")">&#13;
      <mn>1</mn>&#13;
      <mo>-</mo>&#13;
      <msub><mi>A</mi> <mn>1</mn> </msub>&#13;
    </mfenced>&#13;
    <mo>×</mo>&#13;
    <mfenced separators="" open="(" close=")">&#13;
      <mn>1</mn>&#13;
      <mo>-</mo>&#13;
      <msub><mi>A</mi> <mn>2</mn> </msub>&#13;
    </mfenced>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>This method generalizes to any number of components arranged in parallel, so that the availability of any <math alttext="upper N">&#13;
  <mi>N</mi>&#13;
</math> components is equal to one minus the product of their unavailabilities:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper A Subscript s Baseline equals 1 minus product Underscript 1 Overscript upper N Endscripts left-parenthesis 1 minus upper A Subscript i Baseline right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <msub><mi>A</mi> <mi>s</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
    <mo>-</mo>&#13;
    <munderover><mo>∏</mo> <mrow><mn>1</mn></mrow> <mi>N</mi> </munderover>&#13;
    <mfenced separators="" open="(" close=")">&#13;
      <mn>1</mn>&#13;
      <mo>-</mo>&#13;
      <msub><mi>A</mi> <mi>i</mi> </msub>&#13;
    </mfenced>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>When all <math alttext="upper A Subscript i">&#13;
  <msub><mi>A</mi> <mi>i</mi> </msub>&#13;
</math> are equal, then this can be simplified to:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper A Subscript s Baseline equals 1 minus left-parenthesis 1 minus upper A Subscript i Baseline right-parenthesis Superscript upper N" display="block">&#13;
  <mrow>&#13;
    <msub><mi>A</mi> <mi>s</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
    <mo>-</mo>&#13;
    <msup><mfenced separators="" open="(" close=")"><mn>1</mn><mo>-</mo><msub><mi>A</mi> <mi>i</mi> </msub></mfenced> <mi>N</mi> </msup>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>So what about our example? Well, with two components, each with a 99% availability, we get the following:<sup><a data-type="noteref" id="idm45983621111896-marker" href="ch09.xhtml#idm45983621111896">19</a></sup></p>&#13;
<div data-type="equation">&#13;
<math alttext="upper A Subscript s Baseline equals 1 minus left-parenthesis 1 minus 0.99 right-parenthesis squared equals 0.9999" display="block">&#13;
  <mrow>&#13;
    <msub><mi>A</mi> <mi>s</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
    <mo>-</mo>&#13;
    <msup><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mn>0</mn><mo>.</mo><mn>99</mn><mo>)</mo></mrow> <mn>2</mn> </msup>&#13;
    <mo>=</mo>&#13;
    <mn>0</mn>&#13;
    <mo>.</mo>&#13;
    <mn>9999</mn>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>99.99%. Four nines. That’s an improvement of two orders of magnitude, which isn’t half bad. But what if we added a third replica? Extending this out a little, we get some interesting results, summarized in the following table:</p>&#13;
<table>&#13;
&#13;
<thead>&#13;
<tr>&#13;
<th>Components</th>&#13;
<th>Availability</th>&#13;
<th>Downtime per year</th>&#13;
<th>Downtime per month</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p><strong>One component</strong></p></td>&#13;
<td><p>&#13;
99% (“2-nines”)</p></td>&#13;
<td><p>&#13;
3.65 days</p></td>&#13;
<td><p>&#13;
7.31 hours</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><strong>Two parallel components</strong></p></td>&#13;
<td><p>&#13;
99.99% (“4-nines”)</p></td>&#13;
<td><p>&#13;
52.60 minutes</p></td>&#13;
<td><p>&#13;
4.38 minutes</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><strong>Three parallel components</strong></p></td>&#13;
<td><p>&#13;
99.9999% (“6-nines”)</p></td>&#13;
<td><p>&#13;
31.56 seconds</p></td>&#13;
<td><p>&#13;
2.63 seconds</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Incredibly, three parallel instances, each of which isn’t exactly awesome on its own, can provide a very impressive 6-nines of availability! This is why cloud providers advise customers to deploy their applications with three replicas.</p>&#13;
&#13;
<p>But what if the components are arranged serially, like a load balancer in front of our components? This might look something like the following:</p>&#13;
&#13;
<figure><div class="figure">&#13;
<img src="Images/cngo_09in02.png" alt="cngo 09in02" width="373" height="84"/>&#13;
<h6/>&#13;
</div></figure>&#13;
&#13;
<p>In this kind of arrangement, if either component is unavailable, the entire system is unavailable. Its availability is the product of the availabilities of its components:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper A Subscript s Baseline equals product Underscript 1 Overscript upper N Endscripts upper A Subscript i" display="block">&#13;
  <mrow>&#13;
    <msub><mi>A</mi> <mi>s</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <munderover><mo>∏</mo> <mrow><mn>1</mn></mrow> <mi>N</mi> </munderover>&#13;
    <msub><mi>A</mi> <mi>i</mi> </msub>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>When all <math alttext="upper A Subscript i">&#13;
  <msub><mi>A</mi> <mi>i</mi> </msub>&#13;
</math> are equal, then this can be simplified to:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper A Subscript s Baseline equals upper A Superscript upper N" display="block">&#13;
  <mrow>&#13;
    <msub><mi>A</mi> <mi>s</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <msup><mi>A</mi> <mi>N</mi> </msup>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>So what if we slapped a dodgy load balancer instance in front of our fancy 99.9999% available set of service replicas? As it turns out, the result isn’t so good:</p>&#13;
<div data-type="equation">&#13;
<math alttext="0.99 times 0.999999 equals 0.98999901" display="block">&#13;
  <mrow>&#13;
    <mn>0</mn>&#13;
    <mo>.</mo>&#13;
    <mn>99</mn>&#13;
    <mo>×</mo>&#13;
    <mn>0</mn>&#13;
    <mo>.</mo>&#13;
    <mn>999999</mn>&#13;
    <mo>=</mo>&#13;
    <mn>0</mn>&#13;
    <mo>.</mo>&#13;
    <mn>98999901</mn>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>That’s even lower than the load balancer by itself! This is important, because as it turns out:</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>The total reliability of a sequential system cannot be higher than the reliability of any one of its sequences of subsystems.<a data-type="indexterm" data-primary="redundancy" data-startref="ch09_term13" id="idm45983621060872"/></p>&#13;
</div>&#13;
</div></aside>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="Autoscaling"><div class="sect2" id="section_ch09_autoscaling">&#13;
<h2>Autoscaling</h2>&#13;
&#13;
<p><a data-type="indexterm" data-primary="autoscaling" id="ch09_term15"/>Very often, the amount of load that a service is subjected to varies over time. The textbook example is the user-facing web service where load increases during the day and decreases at night. If such a service is built to handle the peak load, it’s wasting time and money at night. If it’s built only to handle the nighttime load, it will be overburdened in the daytime.</p>&#13;
&#13;
<p>Autoscaling is a technique that builds on the idea of load balancing by automatically adding or removing resources—be they cloud server instances or Kubernetes pods—to dynamically adjust capacity to meet current demand. This ensures that your service can meet a variety of traffic patterns, anticipated or otherwise.</p>&#13;
&#13;
<p>As an added bonus, applying autoscaling to your cluster can save money by right-sizing resources according to service requirements.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="Kubernetes" data-secondary="features of" id="idm45983621055912"/>All major cloud providers provide a mechanism for scaling server instances, and most of their managed services implicitly or explicitly support autoscaling. Container orchestration platforms like Kubernetes also include support for autoscaling, both for the number of pods (horizontal autoscaling) and their CPU and memory limits (vertical autoscaling).</p>&#13;
&#13;
<p>Autoscaling mechanics vary considerably between cloud providers and orchestration platforms, so a detailed discussion of how to gather metrics and configure things like predictive autoscaling is beyond the scope of this book. However, some key points to remember:</p>&#13;
&#13;
<ul class="pagebreak-before less_space">&#13;
<li>&#13;
<p>Set reasonable maximums, so that unusually large spikes in demand (or, heaven forbid, cascade failures) don’t completely blow your budget. The throttling and load shedding techniques that we discussed in <a data-type="xref" href="#section_ch09_preventing_overload">“Preventing Overload”</a> are also useful here.</p>&#13;
</li>&#13;
<li>&#13;
<p>Minimize startup times. If you’re using server instances, bake machine images beforehand to minimize configuration time at startup. This is less of an issue on Kubernetes, but container images should still be kept small and startup times reasonably short.</p>&#13;
</li>&#13;
<li>&#13;
<p>No matter how fast your startup, scaling takes a nonzero amount of time. Your service should have <em>some</em> wiggle room without having to scale.</p>&#13;
</li>&#13;
<li>&#13;
<p>As we discussed in <a data-type="xref" href="ch07.xhtml#section_ch07_efficiency">“Scaling Postponed: Efficiency”</a>, the best kind of scaling is the kind that never needs to happen.<a data-type="indexterm" data-primary="autoscaling" data-startref="ch09_term15" id="idm45983621047000"/></p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect1" data-pdf-bookmark="Healthy Health Checks"><div class="sect1" id="section_ch09_health_checks">&#13;
<h1>Healthy Health Checks</h1>&#13;
&#13;
<p>In <a data-type="xref" href="#section_ch09_redundancy">“Service Redundancy”</a>, we briefly discussed the value of redundancy—the duplication of critical components or functions of a system with the intention of increasing overall system reliability—and its value for improving the resilience of a system.</p>&#13;
&#13;
<p>Multiple service instances means having a load-balancing mechanism—a service mesh or dedicated load balancer—but what happens when a service instance goes bad? Certainly, we don’t want the load balancer to continue sending traffic its way. So what do we do?</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="health checks" id="ch09_term16"/>Enter the <em>health check</em>. In its simplest and most common form, a health check is implemented as an API endpoint that clients—load balancers, as well as monitoring services, service registries, etc.—can use to ask a service instance if it’s alive and healthy.</p>&#13;
&#13;
<p>For example, a service might provide an HTTP endpoint (<code>/health</code> and <code>/healthz</code> are common naming choices) that returns a <code>200 OK</code> if the replica is healthy, and a <code>503 Service Unavailable</code> when it’s not. More sophisticated implementations can even return different status codes for different states: HashiCorp’s Consul service registry interprets any <code>2XX</code> status as a success, a <code>429 Too Many Requests</code> as a warning, and anything else as a failure.</p>&#13;
&#13;
<p>Having an endpoint that can tell a client when a service instance is healthy (or not) sounds great and all, but it invites the question of what, exactly, does it mean for an instance to be “healthy”?</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Health checks are like bloom filters. A failing health check means a service isn’t up, but a health check passing means the service is <em>probably</em> “healthy.” (Credit: Cindy Sridharan<sup><a data-type="noteref" id="idm45983621034232-marker" href="ch09.xhtml#idm45983621034232">20</a></sup>)</p>&#13;
</div>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="What Does It Mean for an Instance to Be “Healthy”?"><div class="sect2" id="idm45983621031944">&#13;
<h2>What Does It Mean for an Instance to Be “Healthy”?</h2>&#13;
&#13;
<p>We use the word “healthy” in the context of services and service instances, but what exactly do we mean when we say that? Well, as is so often the case, there’s a simple answer and a complex answer. Probably a lot of answers in between, too.</p>&#13;
&#13;
<p>We’ll start with the simple answer. Reusing an existing definition, an instance is considered “healthy” when it’s “available.” That is, when it’s able to provide correct &#13;
<span class="keep-together">service</span>.</p>&#13;
&#13;
<p>Unfortunately, it isn’t always so clear cut. What if the instance itself is functioning as intended, but a downstream dependency is malfunctioning? Should a health check even make that distinction? If so, should the load balancer behave differently in each case? Should an instance be reaped and replaced if it’s not the one at fault, particularly if all service replicas are affected?</p>&#13;
&#13;
<p>Unfortunately, there aren’t any easy answers to these questions, so instead of answers, I’ll offer the next best thing: a discussion of the three most common approaches to health checking and their associated advantages and disadvantages. Your own implementations will depend on the needs of your service and your load-balancing behavior.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="The Three Types of Health Checks"><div class="sect2" id="idm45983621027096">&#13;
<h2>The Three Types of Health Checks</h2>&#13;
&#13;
<p>When a service instance fails, it’s usually because of one of the following:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>A local failure like an application error or resource—CPU, memory, database connections, etc.—depletion.</p>&#13;
</li>&#13;
<li>&#13;
<p>A remote failure in some dependency—a database or other downstream service—that affects the functioning of the service.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>These two broad categories of failures give rise to three (yes, three) health checking strategies, each with its own fun little pros and cons.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="health checks" data-secondary="liveness checks" id="ch09_term17_2"/><a data-type="indexterm" data-primary="liveness checks" id="ch09_term17"/><em>Liveness checks</em> do little more than return a “success” signal. They make no additional attempt to determine the status of the service, and say nothing about the service except that it’s listening and reachable. But, then again, sometimes this is enough. We’ll talk more about liveness checks in <a data-type="xref" href="#section_ch09_check_liveness">“Liveness checks”</a>.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="health checks" data-secondary="shallow health checks" id="idm45983621018136"/><a data-type="indexterm" data-primary="shallow health checks" id="idm45983621017160"/><em>Shallow health checks</em> go further than liveness checks by verifying that the service instance is likely to be able to function. These health checks only test local resources, so they’re unlikely to fail on many instances simultaneously, but they can’t say for certain whether a particular request service instance will be successful. We’ll wade into shallow health checks in <a data-type="xref" href="#section_ch09_check_shallow">“Shallow health checks”</a>.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="health checks" data-secondary="deep health checks" id="idm45983621014600"/><a data-type="indexterm" data-primary="deep health checks" id="idm45983621013624"/><em>Deep health checks</em> provide a much better understanding of instance health, since they actually inspect the ability of a service instance to perform its function, which also exercises downstream resources like databases. While thorough, they can be expensive, and are susceptible to false positives. We’ll dig into deep health checks in <a data-type="xref" href="#section_ch09_check_deep">“Deep health checks”</a>.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="Liveness checks"><div class="sect3" id="section_ch09_check_liveness">&#13;
<h3>Liveness checks</h3>&#13;
&#13;
<p>A liveness endpoint always returns a “success” value, no matter what. While this might seem trivial to the point of uselessness—after all, what is the value of a health check that doesn’t say anything about health—liveness probes actually can provide some useful information by confirming:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>That the service instance is listening and accepting new connections on the expected port</p>&#13;
</li>&#13;
<li>&#13;
<p>That the instance is reachable over the network</p>&#13;
</li>&#13;
<li>&#13;
<p>That any firewall, security group, or other configurations are correctly defined</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>This simplicity comes with a predictable cost, of course. The absence of any active health checking logic makes liveness checks of limited use when it comes to evaluating whether a service instance can actually perform its function.</p>&#13;
&#13;
<p>Liveness probes are also dead easy to implement. Using the <code>net/http</code> package, we can do the following:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">func</code> <code class="nx">healthLivenessHandler</code><code class="p">(</code><code class="nx">w</code> <code class="nx">http</code><code class="p">.</code><code class="nx">ResponseWriter</code><code class="p">,</code> <code class="nx">r</code> <code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Request</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="nx">w</code><code class="p">.</code><code class="nx">WriteHeader</code><code class="p">(</code><code class="nx">http</code><code class="p">.</code><code class="nx">StatusOK</code><code class="p">)</code>&#13;
    <code class="nx">w</code><code class="p">.</code><code class="nx">Write</code><code class="p">([]</code><code class="nb">byte</code><code class="p">(</code><code class="s">"OK"</code><code class="p">))</code>&#13;
<code class="p">})</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">main</code><code class="p">()</code> <code class="p">{</code>&#13;
    <code class="nx">r</code> <code class="o">:=</code> <code class="nx">mux</code><code class="p">.</code><code class="nx">NewRouter</code><code class="p">()</code>&#13;
    <code class="nx">http</code><code class="p">.</code><code class="nx">HandleFunc</code><code class="p">(</code><code class="s">"/healthz"</code><code class="p">,</code> <code class="nx">healthLivenessHandler</code><code class="p">)</code>&#13;
    <code class="nx">log</code><code class="p">.</code><code class="nx">Fatal</code><code class="p">(</code><code class="nx">http</code><code class="p">.</code><code class="nx">ListenAndServe</code><code class="p">(</code><code class="s">":8080"</code><code class="p">,</code> <code class="nx">r</code><code class="p">))</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>The previous snippet shows how little work can go into a liveness check. In it, we create and register a <code>/healthz</code> endpoint that does nothing but return a <code>200 OK</code> (and the text <code>OK</code>, just to be thorough).</p>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>If you’re using the <code>gorilla/mux</code> package, any registered middleware (like the load shedding function from <a data-type="xref" href="#section_ch09_load_shedding">“Load shedding”</a>) can affect your health checks!<a data-type="indexterm" data-primary="health checks" data-secondary="liveness checks" data-startref="ch09_term17_2" id="idm45983620934984"/><a data-type="indexterm" data-primary="liveness checks" data-startref="ch09_term17" id="idm45983620933768"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="Shallow health checks"><div class="sect3" id="section_ch09_check_shallow">&#13;
<h3>Shallow health checks</h3>&#13;
&#13;
<p><a data-type="indexterm" data-primary="health checks" data-secondary="shallow health checks" id="ch09_term18_2"/><a data-type="indexterm" data-primary="shallow health checks" id="ch09_term18"/>Shallow health checks go further than liveness checks by verifying that the service instance is <em>likely</em> to be able to function, but stop short of investigating in any way that might exercise a database or other downstream dependency.</p>&#13;
&#13;
<p>Shallow health checks can evaluate any number of conditions that could adversely affect the service, including (but certainly not limited to):</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>The availability of key local resources (memory, CPU, database connections)</p>&#13;
</li>&#13;
<li>&#13;
<p>The ability to read or write local data, which checks disk space, permissions, and for hardware malfunctions such as disk failure</p>&#13;
</li>&#13;
<li>&#13;
<p>The presence of support processes, like monitoring or updater processes</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Shallow health checks are more definitive than liveness checks, and their specificity means that any failures are unlikely to affect the entire fleet at once.<sup><a data-type="noteref" id="idm45983620923448-marker" href="ch09.xhtml#idm45983620923448">21</a></sup> However, shallow checks are prone to false positives: if your service is down because of some issue involving an external resource, a shallow check will miss it. What you gain in specificity, you also sacrifice in sensitivity.</p>&#13;
&#13;
<p>A shallow health check might look something like the following example, which tests the service’s ability to read and write to and from local disk:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">func</code> <code class="nx">healthShallowHandler</code><code class="p">(</code><code class="nx">w</code> <code class="nx">http</code><code class="p">.</code><code class="nx">ResponseWriter</code><code class="p">,</code> <code class="nx">r</code> <code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Request</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="c1">// Create our test file.</code>&#13;
    <code class="c1">// This will create a filename like /tmp/shallow-123456</code>&#13;
    <code class="nx">tmpFile</code><code class="p">,</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">ioutil</code><code class="p">.</code><code class="nx">TempFile</code><code class="p">(</code><code class="nx">os</code><code class="p">.</code><code class="nx">TempDir</code><code class="p">(),</code> <code class="s">"shallow-"</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="nx">http</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code> <code class="nx">err</code><code class="p">.</code><code class="nx">Error</code><code class="p">(),</code> <code class="nx">http</code><code class="p">.</code><code class="nx">StatusServiceUnavailable</code><code class="p">)</code>&#13;
        <code class="k">return</code>&#13;
    <code class="p">}</code>&#13;
    <code class="k">defer</code> <code class="nx">os</code><code class="p">.</code><code class="nx">Remove</code><code class="p">(</code><code class="nx">tmpFile</code><code class="p">.</code><code class="nx">Name</code><code class="p">())</code>&#13;
&#13;
    <code class="c1">// Make sure that we can write to the file.</code>&#13;
    <code class="nx">text</code> <code class="o">:=</code> <code class="p">[]</code><code class="nb">byte</code><code class="p">(</code><code class="s">"Check."</code><code class="p">)</code>&#13;
    <code class="k">if</code> <code class="nx">_</code><code class="p">,</code> <code class="nx">err</code> <code class="p">=</code> <code class="nx">tmpFile</code><code class="p">.</code><code class="nx">Write</code><code class="p">(</code><code class="nx">text</code><code class="p">);</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="nx">http</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code> <code class="nx">err</code><code class="p">.</code><code class="nx">Error</code><code class="p">(),</code> <code class="nx">http</code><code class="p">.</code><code class="nx">StatusServiceUnavailable</code><code class="p">)</code>&#13;
        <code class="k">return</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="c1">// Make sure that we can close the file.</code>&#13;
    <code class="k">if</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">tmpFile</code><code class="p">.</code><code class="nx">Close</code><code class="p">();</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="nx">http</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code> <code class="nx">err</code><code class="p">.</code><code class="nx">Error</code><code class="p">(),</code> <code class="nx">http</code><code class="p">.</code><code class="nx">StatusServiceUnavailable</code><code class="p">)</code>&#13;
        <code class="k">return</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="nx">w</code><code class="p">.</code><code class="nx">WriteHeader</code><code class="p">(</code><code class="nx">http</code><code class="p">.</code><code class="nx">StatusOK</code><code class="p">)</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">main</code><code class="p">()</code> <code class="p">{</code>&#13;
    <code class="nx">r</code> <code class="o">:=</code> <code class="nx">mux</code><code class="p">.</code><code class="nx">NewRouter</code><code class="p">()</code>&#13;
    <code class="nx">http</code><code class="p">.</code><code class="nx">HandleFunc</code><code class="p">(</code><code class="s">"/healthz"</code><code class="p">,</code> <code class="nx">healthShallowHandler</code><code class="p">)</code>&#13;
    <code class="nx">log</code><code class="p">.</code><code class="nx">Fatal</code><code class="p">(</code><code class="nx">http</code><code class="p">.</code><code class="nx">ListenAndServe</code><code class="p">(</code><code class="s">":8080"</code><code class="p">,</code> <code class="nx">r</code><code class="p">))</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>This simultaneously checks for available disk space, write permissions, and malfunctioning hardware, which can be a very useful thing to test, particularly if the service needs to write to an on-disk cache or other transient files.</p>&#13;
&#13;
<p>An observant reader might notice that it writes to the default directory to use for temporary files. On Linux, this is <code>/tmp</code>, which is actually a RAM drive. This might be a useful thing to test as well, but if you want to test for the ability to write to disk on Linux you’ll need to specify a different directory, or this becomes a very different test.<a data-type="indexterm" data-primary="health checks" data-secondary="shallow health checks" data-startref="ch09_term18_2" id="idm45983620918040"/>&#13;
<a data-type="indexterm" data-primary="shallow health checks" data-startref="ch09_term18" id="idm45983620681144"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect3" data-pdf-bookmark="Deep health checks"><div class="sect3" id="section_ch09_check_deep">&#13;
<h3>Deep health checks</h3>&#13;
&#13;
<p><a data-type="indexterm" data-primary="health checks" data-secondary="deep health checks" id="ch09_term19_2"/><a data-type="indexterm" data-primary="deep health checks" id="ch09_term19"/>Deep health checks directly inspect the ability of a service to interact with its adjacent systems. This provides much better understanding of instance health by potentially identifying issues with dependencies, like invalid credentials, the loss of connectivity to data stores, or other unexpected networking issues.</p>&#13;
&#13;
<p><a data-type="indexterm" data-primary="dependencies" data-seealso="deep health checks" id="idm45983620675816"/>However, while thorough, deep health checks can be quite expensive. They can take a long time and place a burden on dependencies, particularly if you’re running too many of them, or running them too often.</p>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>Don’t try to test <em>every</em> dependency in your health checks: focus on the ones that are required for the service to operate.</p>&#13;
</div>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>When testing multiple downstream dependencies, evaluate them concurrently if possible.</p>&#13;
</div>&#13;
&#13;
<p>What’s more, because the failure of a dependency will be reported as a failure of the instance, deep checks are especially susceptible to false positives. Combined with the lower specificity compared to a shallow check—issues with dependencies will be felt by the entire fleet—and you have the potential for a cascading failure.</p>&#13;
&#13;
<p>If you’re using deep health checks, you should take advantage of strategies like circuit breaking (which we covered in <a data-type="xref" href="#image_ch09_circuit_breaking">“Circuit Breaking”</a>) where you can, and your load balancer should “fail open” (which we’ll discuss in <a data-type="xref" href="#section_ch09_failing_open">“Failing Open”</a>) whenever possible.</p>&#13;
&#13;
<p>Here we have a trivial example of a possible deep health check that evaluates a database by calling a hypothetical service’s <code>GetUser</code> function:</p>&#13;
&#13;
<pre data-type="programlisting" data-code-language="go"><code class="kd">func</code> <code class="nx">healthDeepHandler</code><code class="p">(</code><code class="nx">w</code> <code class="nx">http</code><code class="p">.</code><code class="nx">ResponseWriter</code><code class="p">,</code> <code class="nx">r</code> <code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Request</code><code class="p">)</code> <code class="p">{</code>&#13;
    <code class="c1">// Retrieve the context from the request and add a 5-second timeout</code>&#13;
    <code class="nx">ctx</code><code class="p">,</code> <code class="nx">cancel</code> <code class="o">:=</code> <code class="nx">context</code><code class="p">.</code><code class="nx">WithTimeout</code><code class="p">(</code><code class="nx">r</code><code class="p">.</code><code class="nx">Context</code><code class="p">(),</code> <code class="mi">5</code><code class="o">*</code><code class="nx">time</code><code class="p">.</code><code class="nx">Second</code><code class="p">)</code>&#13;
    <code class="k">defer</code> <code class="nx">cancel</code><code class="p">()</code>&#13;
&#13;
    <code class="c1">// service.GetUser is a hypothetical method on a service interface</code>&#13;
    <code class="c1">// that executes a database query</code>&#13;
    <code class="k">if</code> <code class="nx">err</code> <code class="o">:=</code> <code class="nx">service</code><code class="p">.</code><code class="nx">GetUser</code><code class="p">(</code><code class="nx">ctx</code><code class="p">,</code> <code class="mi">0</code><code class="p">);</code> <code class="nx">err</code> <code class="o">!=</code> <code class="kc">nil</code> <code class="p">{</code>&#13;
        <code class="nx">http</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code> <code class="nx">err</code><code class="p">.</code><code class="nx">Error</code><code class="p">(),</code> <code class="nx">http</code><code class="p">.</code><code class="nx">StatusServiceUnavailable</code><code class="p">)</code>&#13;
        <code class="k">return</code>&#13;
    <code class="p">}</code>&#13;
&#13;
    <code class="nx">w</code><code class="p">.</code><code class="nx">WriteHeader</code><code class="p">(</code><code class="nx">http</code><code class="p">.</code><code class="nx">StatusOK</code><code class="p">)</code>&#13;
<code class="p">}</code>&#13;
&#13;
<code class="kd">func</code> <code class="nx">main</code><code class="p">()</code> <code class="p">{</code>&#13;
    <code class="nx">r</code> <code class="o">:=</code> <code class="nx">mux</code><code class="p">.</code><code class="nx">NewRouter</code><code class="p">()</code>&#13;
    <code class="nx">http</code><code class="p">.</code><code class="nx">HandleFunc</code><code class="p">(</code><code class="s">"/healthz"</code><code class="p">,</code> <code class="nx">healthDeepHandler</code><code class="p">)</code>&#13;
    <code class="nx">log</code><code class="p">.</code><code class="nx">Fatal</code><code class="p">(</code><code class="nx">http</code><code class="p">.</code><code class="nx">ListenAndServe</code><code class="p">(</code><code class="s">":8080"</code><code class="p">,</code> <code class="nx">r</code><code class="p">))</code>&#13;
<code class="p">}</code></pre>&#13;
&#13;
<p>Ideally, a dependency test should execute an actual system function, but also be lightweight to the greatest reasonable degree. In this example, the <code>GetUser</code> function triggers a database query that satisfies both of these criteria.<sup><a data-type="noteref" id="idm45983620664920-marker" href="ch09.xhtml#idm45983620664920">22</a></sup></p>&#13;
&#13;
<p>“Real” queries are generally preferable to just pinging the database for two reasons. First, they’re a more representative test of what the service is doing. Second, they allow the leveraging of end-to-end query time as a measure of database health. The previous example actually does this—albeit in a very binary fashion—by using &#13;
<span class="keep-together"><code>Context</code></span> to set a hard timeout value, but you could choose to include more sophisticated logic instead.<a data-type="indexterm" data-primary="health checks" data-secondary="deep health checks" data-startref="ch09_term19_2" id="idm45983620475640"/><a data-type="indexterm" data-primary="deep health checks" data-startref="ch09_term19" id="idm45983620474424"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect2" data-pdf-bookmark="Failing Open"><div class="sect2" id="section_ch09_failing_open">&#13;
<h2>Failing Open</h2>&#13;
&#13;
<p>What if all of your instances simultaneously decide that they’re unhealthy? If you’re using deep health checks, this can actually happen quite easily (and, perhaps, regularly). Depending on how your load balancer is configured, you might find yourself with zero instances serving traffic, possibly causing failures rippling across your &#13;
<span class="keep-together">system</span>.</p>&#13;
&#13;
<p>Fortunately, some load balancers handle this quite cleverly by “failing open.” If a load balancer that fails open has <em>no</em> healthy targets—that is, if <em>all</em> of its targets’ health checks are failing—it will route traffic to all of its targets.</p>&#13;
&#13;
<p>This is slightly counterintuitive behavior, but it makes deep health checks somewhat safer to use by allowing traffic to continue to flow even when a downstream dependency may be having a bad day.<a data-type="indexterm" data-primary="health checks" data-startref="ch09_term16" id="idm45983620468776"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="idm45983621045000">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>This was an interesting chapter to write. There’s quite a lot to say about resilience, and so much crucial supporting operational background. I had to make some tough calls about what would make it in and what wouldn’t. At about 37 pages, this chapter still turned out a fair bit longer than I intended, but I’m quite satisfied with the outcome. It’s a reasonable compromise between too little information and too much, and between operational background and actual Go implementations.</p>&#13;
&#13;
<p>We reviewed what it means for a system to fail, and how complex systems fail (that is, one component at a time). This led naturally to discussing a particularly nefarious, yet common, failure mode: cascading failures. In a cascade failure, a system’s own attempts to recover hasten its collapse. We covered common measures of preventing cascading failures on the server side: throttling and load shedding.</p>&#13;
&#13;
<p>Retries in the face of errors can contribute a lot to a service’s resilience, but as we saw in the DynamoDB case study, can also contribute to cascade failures when applied naively. We dug deep into measures that can be taken on the client side as well, including circuit breakers, timeouts, and especially exponential backoff algorithms. There were several pretty graphs involved. I spent a lot of time on the graphs.</p>&#13;
&#13;
<p>All of this led to conversations about service redundancy, how it affects reliability (with a little math thrown in, for fun), and when and how to best leverage &#13;
<span class="keep-together">autoscaling</span>.</p>&#13;
&#13;
<p>Of course, you can’t talk about autoscaling without talking about resource “health.” We asked (and did our best to answer) what it means for an instance to be “healthy,” and how that translated into health checks. We covered the three kinds of health checks and weighed their pros and cons, paying particular attention to their relative sensitivity/specificity tradeoffs.</p>&#13;
&#13;
<p>In <a data-type="xref" href="ch10.xhtml#chapter_10">Chapter 10</a> we’ll take a break from the operational topics for a bit and wade into the subject of manageability: the art and science of changing the tires on a moving car.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45983623944264"><sup><a href="ch09.xhtml#idm45983623944264-marker">1</a></sup> Lamport, Leslie. <em>DEC SRC Bulletin Board</em>, 28 May 1987. <a href="https://oreil.ly/nD85V"><em class="hyperlink">https://oreil.ly/nD85V</em></a>.</p><p data-type="footnote" id="idm45983623938904"><sup><a href="ch09.xhtml#idm45983623938904-marker">2</a></sup> Summary of the Amazon DynamoDB Service Disruption and Related Impacts in the US-East Region. Amazon AWS, September 2015. <a href="https://oreil.ly/Y1P5S"><em class="hyperlink">https://oreil.ly/Y1P5S</em></a>.</p><p data-type="footnote" id="idm45983623929384"><sup><a href="ch09.xhtml#idm45983623929384-marker">3</a></sup> Cook, Richard I. “How Complex Systems Fail.” 1998. <a href="https://oreil.ly/WyJ4Q"><em class="hyperlink">https://oreil.ly/WyJ4Q</em></a>.</p><p data-type="footnote" id="idm45983623919016"><sup><a href="ch09.xhtml#idm45983623919016-marker">4</a></sup> If you’re interested in a complete academic treatment, I highly recommend <a href="https://oreil.ly/tfKr1"><em>Reliability and Availability Engineering</em></a> by Kishor S. Trivedi and Andrea Bobbio (Cambridge University Press).</p><p data-type="footnote" id="idm45983623900600"><sup><a href="ch09.xhtml#idm45983623900600-marker">5</a></sup> Importantly, many faults are only evident in retrospect.</p><p data-type="footnote" id="idm45983623894792"><sup><a href="ch09.xhtml#idm45983623894792-marker">6</a></sup> See? We eventually got there.</p><p data-type="footnote" id="idm45983623892568"><sup><a href="ch09.xhtml#idm45983623892568-marker">7</a></sup> Go on, ask me how I know this.</p><p data-type="footnote" id="idm45983623867528"><sup><a href="ch09.xhtml#idm45983623867528-marker">8</a></sup> Especially if the service is available on the open sewer that is the public internet.</p><p data-type="footnote" id="idm45983623725192"><sup><a href="ch09.xhtml#idm45983623725192-marker">9</a></sup> Wikipedia contributors. “Token bucket.” <em>Wikipedia, The Free Encyclopedia</em>, 5 Jun. 2019. <a href="https://oreil.ly/vkOov"><em class="hyperlink">https://oreil.ly/vkOov</em></a>.</p><p data-type="footnote" id="idm45983622826936"><sup><a href="ch09.xhtml#idm45983622826936-marker">10</a></sup> The code used to simulate all data in this section is available in <a href="https://oreil.ly/m61X7">the associated GitHub repository</a>.</p><p data-type="footnote" id="idm45983622584440"><sup><a href="ch09.xhtml#idm45983622584440-marker">11</a></sup> Doing that here felt redundant, but I’ll admit that I may have gotten a bit lazy.</p><p data-type="footnote" id="idm45983622576120"><sup><a href="ch09.xhtml#idm45983622576120-marker">12</a></sup> And, technically, request-scoped values, but the correctness of this functionality is debatable.</p><p data-type="footnote" id="idm45983621566664"><sup><a href="ch09.xhtml#idm45983621566664-marker">13</a></sup> Fielding, R., et al. “Hypertext Transfer Protocol — HTTP/1.1,” Proposed Standard, RFC 2068, June 1997. <a href="https://oreil.ly/28rcs"><em class="hyperlink">https://oreil.ly/28rcs</em></a>.</p><p data-type="footnote" id="idm45983621564248"><sup><a href="ch09.xhtml#idm45983621564248-marker">14</a></sup> Berners-Lee, T., et al. “Hypertext Transfer Protocol — HTTP/1.0,” Informational, RFC 1945, May 1996. <a href="https://oreil.ly/zN7uo"><em class="hyperlink">https://oreil.ly/zN7uo</em></a>.</p><p data-type="footnote" id="idm45983621558600"><sup><a href="ch09.xhtml#idm45983621558600-marker">15</a></sup> Fielding, Roy Thomas. “Architectural Styles and the Design of Network-Based Software Architectures.” <em>UC Irvine</em>, 2000, pp. 76–106. <a href="https://oreil.ly/swjbd"><em class="hyperlink">https://oreil.ly/swjbd</em></a>.</p><p data-type="footnote" id="idm45983621554584"><sup><a href="ch09.xhtml#idm45983621554584-marker">16</a></sup> You monster.</p><p data-type="footnote" id="idm45983621184232"><sup><a href="ch09.xhtml#idm45983621184232-marker">17</a></sup> <a href="https://oreil.ly/YPKyr"><em>Building Secure and Reliable Systems: Best Practices for Designing, Implementing, and Maintaining Systems</em></a> by Heather Adkins—and a host of other authors—is one excellent example.</p><p data-type="footnote" id="idm45983621169368"><sup><a href="ch09.xhtml#idm45983621169368-marker">18</a></sup> Brace yourself. We’re going in.</p><p data-type="footnote" id="idm45983621111896"><sup><a href="ch09.xhtml#idm45983621111896-marker">19</a></sup> This assumes that the failure rates of the components are absolutely independent, which is very unlikely in the real world. Treat as you would spherical cows in a vacuum.</p><p data-type="footnote" id="idm45983621034232"><sup><a href="ch09.xhtml#idm45983621034232-marker">20</a></sup> Sridharan, Cindy (@copyconstruct). “Health checks are like bloom filters…” 5 Aug 2018, 3:21 AM. Tweet. <a href="https://oreil.ly/Qpw3d"><em class="hyperlink">https://oreil.ly/Qpw3d</em></a>.</p><p data-type="footnote" id="idm45983620923448"><sup><a href="ch09.xhtml#idm45983620923448-marker">21</a></sup> Though I’ve seen it happen.</p><p data-type="footnote" id="idm45983620664920"><sup><a href="ch09.xhtml#idm45983620664920-marker">22</a></sup> It’s an imaginary function, so let’s just agree that that’s true.</p></div></div></section></div></body></html>