<html><head></head><body><section data-pdf-bookmark="Chapter 11. Optimization Patterns" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch-opt2">&#13;
<h1><span class="label">Chapter 11. </span>Optimization Patterns</h1>&#13;
&#13;
&#13;
<p><a data-primary="optimization patterns" data-type="indexterm" id="ix_ch11-asciidoc0"/>With all we’ve learned from the past 10 chapters, it’s time to go through various patterns and common pitfalls I found when developing efficient code in Go. As I mentioned in <a data-type="xref" href="ch10.html#ch-opt">Chapter 10</a>, the optimization suggestion doesn’t generalize well. However, given you should know at this point how to assess code changes effectively, there is no harm in stating some common patterns that improve efficiency in certain cases.</p>&#13;
<div data-type="tip"><h1>Be a Mindful Go Developer</h1>&#13;
<p>Remember that most optimization ideas you will see here are highly deliberate. This means we have to have a good reason to add them as they take the developer’s time to get right and maintain in the future. Even if you learn about some common optimization, ensure it improves efficiency for your specific workload.</p>&#13;
&#13;
<p>Don’t use this chapter as a strict manual but as a list of potential options you did not think about. Nevertheless, always stick to the observability, benchmarking, and profiling tools we learned in previous chapters to ensure the optimizations you do are pragmatic, follow <a href="https://oreil.ly/G9OLQ">YAGNI</a>, and are needed.</p>&#13;
</div>&#13;
&#13;
<p>We will start with <a data-type="xref" href="#ch-opt-patterns">“Common Patterns”</a>, where I describe some high-level optimization patterns we could see from optimization examples in <a data-type="xref" href="ch10.html#ch-opt">Chapter 10</a>. Then I will introduce you to the <a data-type="xref" href="#ch-hw-rrr">“The Three Rs Optimization Method”</a>, &#13;
<span class="keep-together">an excellent</span> memory optimization framework from the Go (and Prometheus) &#13;
<span class="keep-together">community.</span></p>&#13;
&#13;
<p>Finally, in <a data-type="xref" href="#ch-basic-leaks">“Don’t Leak Resources”</a>, &#13;
<span class="keep-together"><a data-type="xref" href="#ch-basic-prealloc">“Pre-Allocate If You Can”</a>,</span> <a data-type="xref" href="#ch-basic-subslice">“Overusing Memory with Arrays”</a>, and <a data-type="xref" href="#ch-basic-pool">“Memory Reuse and Pooling”</a>, we will go through a set of specific optimizations, tips, and gotchas I wish I’d known when I started my journey with making Go code more efficient. I have chosen the most common ones that are worth being aware of!</p>&#13;
&#13;
<p>Let’s start with common optimization patterns. Some of them I used in previous chapters.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Common Patterns" data-type="sect1"><div class="sect1" id="ch-opt-patterns">&#13;
<h1>Common Patterns</h1>&#13;
&#13;
<p><a data-primary="optimization patterns" data-secondary="common patterns" data-type="indexterm" id="ix_ch11-asciidoc1"/>How can you find optimizations? After benchmarking, profiling, and studying the code, the process requires us to figure out a better algorithm, data structure, or code that will be more efficient. Of course, this is easier said than done.</p>&#13;
&#13;
<p>Some practice and experience help, but we can outline a few patterns that repeat in our optimization journeys. Let’s now walk through four generic patterns we see in the programming community and literature: doing less work, and trading functionality for efficiency, trading space for time, and trading time for space.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Do Less Work" data-type="sect2"><div class="sect2" id="ch-basic-less-work">&#13;
<h2>Do Less Work</h2>&#13;
&#13;
<p><a data-primary="optimization patterns" data-secondary="avoiding unnecessary work" data-type="indexterm" id="ix_ch11-asciidoc2"/>The first thing we should focus on is avoiding unnecessary work. Especially in <a data-type="xref" href="ch10.html#ch-opt-latency-example">“Optimizing Latency”</a>, we improved the CPU time multiple times by removing a lot of unnecessary code. It might feel simplistic, but it’s a powerful pattern we often forget. If some portion of the code is critical and requires optimization, we can go through bottlenecks (e.g., lines of code with large contributions we see in Source view as we discussed in <a data-type="xref" href="ch09.html#ch-obs-profiling-res">“go tool pprof Reports”</a>) and check if we can:</p>&#13;
<dl>&#13;
<dt>Skip unnecessary logic</dt>&#13;
<dd>&#13;
<p>Can we remove this line? For example, in <a data-type="xref" href="ch10.html#ch-opt-latency-example">“Optimizing Latency”</a>, <code>strconv.ParseInt</code> had a lot of checks that weren’t needed in our implementation. We can use the assumptions and requirements we have to our advantage and trim down the functionality that isn’t strictly needed. This also includes potential resources we can clean early or any resource leaks (see <a data-type="xref" href="#ch-basic-leaks">“Don’t Leak Resources”</a>).</p>&#13;
<div data-type="warning" epub:type="warning"><h1>Generic Implementations</h1>&#13;
<p><a data-primary="generic implementations, drawbacks of" data-type="indexterm" id="idm45606820140816"/>It’s very tempting to approach programming problems with a generic solution. We are trained to see patterns, and programming languages offer many abstractions and object-oriented paradigms to reuse more code.</p>&#13;
&#13;
<p>As we could see in <a data-type="xref" href="ch10.html#ch-opt-latency-example">“Optimizing Latency”</a>, while the <code>bytes.Split</code> and <code>strconv.ParseInt</code> functions are well designed, safe to use, and richer in features, they might not always be suitable for critical paths. Being “generic” has many drawbacks, and efficiency is usually the first victim.</p>&#13;
</div>&#13;
</dd>&#13;
<dt>Do things once</dt>&#13;
<dd>&#13;
<p>Was it done already? Perhaps we already loop over the same array somewhere else, so we could do more things “in place,” as we did in <a data-type="xref" href="ch10.html#code-sum2">Example 10-3</a>.</p>&#13;
&#13;
<p>There might be cases where we validate some invariant even though it was validated before. Or we sort again “just in case,” but when we double-check the code, it was sorted already. For example, in the Thanos project, we can do a <a href="https://oreil.ly/LxjZq">k-way merge</a> instead of a naive merge and sort again when merging different metric streams because of the invariant that each stream gives metrics in lexicographic order.</p>&#13;
&#13;
<p>Another common example is reusing memory. For instance, we can create a small buffer once and reuse it, as in <a data-type="xref" href="ch10.html#code-sum6">Example 10-8</a>, instead of creating a new one every time we need it. We can also use caching or <a data-type="xref" href="#ch-basic-pool">“Memory Reuse and Pooling”</a>.</p>&#13;
</dd>&#13;
</dl>&#13;
<dl>&#13;
<dt>Leverage math to do less</dt>&#13;
<dd>&#13;
<p>Using math is an amazing way to reduce the work we have to do. For example, to calculate the number of samples retrieved through the Prometheus API, we don’t decode chunks and iterate over all samples to count them. Instead, we estimate the number of samples by dividing the size of the chunk by the average sample size.</p>&#13;
</dd>&#13;
<dt>Use the knowledge or precomputed information</dt>&#13;
<dd>&#13;
<p>Many APIs and functions are designed to be smart and automate certain work, even if it means doing more work. One example is pre-allocation possibilities, discussed in <a data-type="xref" href="#ch-basic-prealloc">“Pre-Allocate If You Can”</a>.</p>&#13;
&#13;
<p>In another, more complex example, the <a href="https://oreil.ly/YqDZ6"><code>minio-go</code></a> object storage client we use in <a href="https://oreil.ly/l8xHu">objstore</a> can upload an arbitrary <code>io.Reader</code> implementation. However, the implementation requires calculating the checksum before upload. Thus, if we don’t give the total expected size of the bytes available in a reader, <code>minio-go</code> will use additional CPU cycles and memory to buffer the whole, potentially gigabytes-large object. All this just to calculate a checksum that has to be sometimes sent up front. On the other hand, if we notice this and have the total size handy, providing this information through the API can dramatically improve upload efficiency.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>These elements seem like they focus on CPU time and latency, but we can use the same toward memory or any other resource usage. For example, consider a small example in <a data-type="xref" href="#code-emptystruct">Example 11-1</a> that shows what it means to do “less work” focused on lower memory usage.</p>&#13;
<div data-type="example" id="code-emptystruct">&#13;
<h5><span class="label">Example 11-1. </span>The function finding if the slice has a duplicated element optimized with an empty struct. Uses <a data-type="xref" href="ch02.html#ch-go-generics">“Generics”</a>.</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">HasDuplicates</code><code class="p">[</code><code class="nx">T</code><code class="w"> </code><code class="kt">comparable</code><code class="p">]</code><code class="p">(</code><code class="nx">slice</code><code class="w"> </code><code class="o">...</code><code class="nx">T</code><code class="p">)</code><code class="w"> </code><code class="kt">bool</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">dup</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="kd">map</code><code class="p">[</code><code class="nx">T</code><code class="p">]</code><code class="kt">any</code><code class="p">,</code><code class="w"> </code><code class="nb">len</code><code class="p">(</code><code class="nx">slice</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">s</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="k">range</code><code class="w"> </code><code class="nx">slice</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">if</code><code class="w"> </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">ok</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">dup</code><code class="p">[</code><code class="nx">s</code><code class="p">]</code><code class="p">;</code><code class="w"> </code><code class="nx">ok</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="k">return</code><code class="w"> </code><code class="kc">true</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">dup</code><code class="p">[</code><code class="nx">s</code><code class="p">]</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="s">"whatever, I don't use this value"</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="kc">false</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">HasDuplicates2</code><code class="p">[</code><code class="nx">T</code><code class="w"> </code><code class="kt">comparable</code><code class="p">]</code><code class="p">(</code><code class="nx">slice</code><code class="w"> </code><code class="o">...</code><code class="nx">T</code><code class="p">)</code><code class="w"> </code><code class="kt">bool</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">dup</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="kd">map</code><code class="p">[</code><code class="nx">T</code><code class="p">]</code><code class="kd">struct</code><code class="p">{</code><code class="p">}</code><code class="p">,</code><code class="w"> </code><code class="nb">len</code><code class="p">(</code><code class="nx">slice</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">s</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="k">range</code><code class="w"> </code><code class="nx">slice</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">if</code><code class="w"> </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">ok</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">dup</code><code class="p">[</code><code class="nx">s</code><code class="p">]</code><code class="p">;</code><code class="w"> </code><code class="nx">ok</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="k">return</code><code class="w"> </code><code class="kc">true</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">dup</code><code class="p">[</code><code class="nx">s</code><code class="p">]</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="kd">struct</code><code class="p">{</code><code class="p">}</code><code class="p">{</code><code class="p">}</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO1-1" id="co_optimization_patterns_CO1-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="kc">false</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO1-1" id="callout_optimization_patterns_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Since we don’t use the <code>map</code> value, we can use the <code>struct{}</code> statement, which uses no memory. Thanks to this, the <code>HasDuplicates2</code> on my machine is 22% faster and allocates 5 times less memory for a <code>float64</code> slice with 1 million elements. The same pattern can be used in places where we don’t care about value. For example, for channels we use to synchronize goroutines, we can use <code>make(chan struct{})</code> to avoid unnecessary space we don’t need.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>Usually, there is always room to reduce some effort in our programs. We can use profiling to our advantage to check all expensive parts and their relevance to our problem. Often we can remove or transform those into cheaper forms, gaining &#13;
<span class="keep-together">efficiency.</span></p>&#13;
<div data-type="warning" epub:type="warning"><h1>Be Strategic!</h1>&#13;
<p>Sometimes, doing less work now means more work or resource usage later. We can be strategic about this and ensure that our local benchmark doesn’t miss the important trade-off elsewhere. This problem is highlighted in <a data-type="xref" href="#ch-basic-pool">“Memory Reuse and Pooling”</a>, where the macrobenchmark results give opposite conclusions to the microbenchmark.<a data-startref="ix_ch11-asciidoc2" data-type="indexterm" id="idm45606819383840"/></p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Trading Functionality for Efficiency" data-type="sect2"><div class="sect2" id="ch-basic-less-work2">&#13;
<h2>Trading Functionality for Efficiency</h2>&#13;
&#13;
<p><a data-primary="optimization patterns" data-secondary="trading functionality for efficiency" data-type="indexterm" id="idm45606819381616"/>In some cases, we have to negotiate or remove certain functionality to improve efficiency. In <a data-type="xref" href="ch10.html#ch-opt-latency-example">“Optimizing Latency”</a>, we can improve the CPU time by removing support for negative integers in the file. Without this requirement, we can remove the check for negative sign in the <a data-type="xref" href="ch10.html#code-sum4">Example 10-5</a> <code>ParseInt</code> function! Perhaps this feature is not well used, and it can be traded for cheaper execution!</p>&#13;
&#13;
<p>This is also why accepting all the possible features in the project is often not very sustainable. In many cases, an extra API, extra parameter, or functionality might add a significant efficiency penalty for critical paths, which could be avoided if we just limit the functionality to a minimum.<sup><a data-type="noteref" href="ch11.html#idm45606819377840" id="idm45606819377840-marker">1</a></sup></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Trading Space for Time" data-type="sect2"><div class="sect2" id="ch-basic-less-work3">&#13;
<h2>Trading Space for Time</h2>&#13;
&#13;
<p><a data-primary="optimization patterns" data-secondary="trading space for time" data-type="indexterm" id="idm45606819374496"/>What else can we do if we limit our program’s work to a minimum by reducing unnecessary logic, features, and leaks? Generally, we can shift to systems, algorithms, or code that use less time but cost us more in terms of storage, like memory, disk, and so on. Let’s walk through some possible changes like this:<sup><a data-type="noteref" href="ch11.html#idm45606819373392" id="idm45606819373392-marker">2</a></sup></p>&#13;
<dl>&#13;
<dt>Precomputing result</dt>&#13;
<dd>&#13;
<p>Instead of computing the same expensive function, we could try to precompute it and store the result in some table lookup or variable.</p>&#13;
&#13;
<p>These days, it’s very common to see a compiler adapting optimization like this. The compiler trades compiler latency and program code space for faster execution. For example, statements like <code>10*1024*1024</code> or <code>20 * time.Seconds</code> can be precomputed by a compiler, so they don’t have to be computed at runtime.</p>&#13;
&#13;
<p>But there might be cases of more complex function statements that the &#13;
<span class="keep-together">compiler can’t</span> precompute for us. For example, we could use <code>regexp.Must​Com⁠pile("…​").MatchString(</code> in some condition, which is on a critical path. &#13;
<span class="keep-together">Perhaps</span> it will be efficient to create a variable <code>pattern := regexp.Must​Com⁠pile("…​")</code> and operate on <code>pattern.MatchString(</code> in that heavily used code instead. On top of that, some cryptographic encryption offer <a href="https://oreil.ly/2VBL4">precompute methods</a> that speed up execution.</p>&#13;
</dd>&#13;
</dl>&#13;
<dl class="less_space pagebreak-before">&#13;
<dt>Caching</dt>&#13;
<dd>&#13;
<p>When the computed results heavily depend on the input, precomputing it for one input that is only used from time to time is not very helpful. Instead, we can introduce caching as we did in <a data-type="xref" href="ch04.html#code-sum">Example 4-1</a>. Writing our caching solution is a nontrivial effort and should be done with care.<sup><a data-type="noteref" href="ch11.html#idm45606819974288" id="idm45606819974288-marker">3</a></sup> There are many <a href="https://oreil.ly/UAhqT">caching policies</a>, with the Least Recently Used (LRU) being the most popular in my experience. In <a data-type="xref" href="ch10.html#ch-opt-bonus">“Bonus: Thinking Out of the Box”</a>, I mentioned a few off-the-shelf solutions in open source that we can use.</p>&#13;
</dd>&#13;
<dt>Augmenting data structure</dt>&#13;
<dd>&#13;
<p>We can often change the data structure so certain information can be accessed more easily, or by adding more information to the structure. For example, we can store the size next to a file descriptor to know the file size instead of asking for it every time.</p>&#13;
&#13;
<p>In addition, we can maintain a map of elements next to the slice we already have in our structure, so we deduplicate or find elements easier (similar to the deduplication map I did in <a data-type="xref" href="#code-emptystruct">Example 11-1</a>).</p>&#13;
</dd>&#13;
<dt>Decompressing</dt>&#13;
<dd>&#13;
<p>Compression algorithms are great for saving disk or memory space. However, any compression—e.g., string interning, gzip, <a href="https://oreil.ly/OEx9B">zstd</a>, etc.—have some CPU (thus, time) overhead, so when time is money, we might want to get rid of compression. Be careful, though, as enabled compression can improve program latency, e.g., when used for messages across slow networks. Therefore, spending more CPU time to reduce message size so that we can send more with a smaller number of network packets can potentially be faster.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Ideally, the decision is deliberate. For example, perhaps we know that based on the RAERs, our program can still use more memory, but we are not meeting the latency goal. In such a case, we could check if there is anything we can add, cache, or store that would allow you to spend less time in our program.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Trading Time for Space" data-type="sect2"><div class="sect2" id="idm45606819965264">&#13;
<h2>Trading Time for Space</h2>&#13;
&#13;
<p><a data-primary="optimization patterns" data-secondary="trading time for space" data-type="indexterm" id="idm45606819964176"/>If we can spare some latency or extra CPU time but are low on memory during the execution, we can try the opposite rule to the previous one, trading space for time. The methods are usually exactly the opposite of those in <a data-type="xref" href="#ch-basic-less-work3">“Trading Space for Time”</a>: compressing and encoding more, removing extra fields from the struct, recomputing results, removing caches, etc.</p>&#13;
<div data-type="tip"><h1>Trading Space for Time or Time for Space Optimizations Is Not Always Intuitive</h1>&#13;
<p>Sometimes to save memory resource usage, we have to allocate more first!</p>&#13;
&#13;
<p>For example, in <a data-type="xref" href="#ch-basic-subslice">“Overusing Memory with Arrays”</a> and <a data-type="xref" href="#ch-basic-pool">“Memory Reuse and Pooling”</a>, I mention situations where allocating more memory or explicitly copying memory is better, despite looking like more work. So it can save us more memory space in the long run.</p>&#13;
</div>&#13;
&#13;
<p>To sum up, consider the four general rules as higher-level patterns of possible optimizations. Let me now introduce you to the “three Rs,” which helped me a lot to guide some of the optimizations in my efficiency development tasks.<a data-startref="ix_ch11-asciidoc1" data-type="indexterm" id="idm45606819958032"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="The Three Rs Optimization Method" data-type="sect1"><div class="sect1" id="ch-hw-rrr">&#13;
<h1>The Three Rs Optimization Method</h1>&#13;
&#13;
<p><a data-primary="optimization patterns" data-secondary="three Rs method" data-type="indexterm" id="ix_ch11-asciidoc3"/><a data-primary="three Rs optimization method" data-type="indexterm" id="ix_ch11-asciidoc4"/>The three Rs technique is an excellent method to reduce waste. It is generally applicable for all computer resources, but it is often used for <a href="https://oreil.ly/p6elc">ecology purposes</a> to reduce literal waste. Thanks to those three ingredients—reduce, reuse, and recycle—we can reduce the impact we have on the Earth’s environment and ensure sustainable living.</p>&#13;
&#13;
<p>At <a href="https://fosdem.org">FOSDEM</a> 2018, I saw <a href="https://oreil.ly/BLIiT">Bryan Boreham’s amazing talk</a>, where he described using this method to mitigate memory issues. Indeed, the three Rs method is especially effective against memory allocations, which is the most common source of memory efficiency and GC overhead problems. So, let’s explore each “R” component and how each can help.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Reduce Allocations" data-type="sect2"><div class="sect2" id="idm45606819356176">&#13;
<h2>Reduce Allocations</h2>&#13;
<blockquote><p>Attempting to directly affect the pace [e.g., using <code>GOGC</code> or <code>GOMEMLIMIT</code>] of [garbage] collection has nothing to do with being sympathetic with the collector. It’s really about getting more work done between each collection or during the collection. You affect that by reducing the amount or the number of allocations any piece of work adds to heap memory.</p><p data-type="attribution">William Kennedy, <a href="https://oreil.ly/DVdNm">“Garbage Collection in Go: Part I—Semantics”</a></p></blockquote>&#13;
&#13;
<p><a data-primary="three Rs optimization method" data-secondary="reducing allocations" data-type="indexterm" id="idm45606819352352"/>There <a data-primary="Kennedy, William" data-secondary="on GC" data-type="indexterm" id="idm45606819351376"/>is almost always room to reduce allocations—look for the waste! Some ways to reduce the number of objects our code puts on the heap are obvious (reasonable optimizations like the pre-allocations of slices we saw in <a data-type="xref" href="ch01.html#code-prea2">Example 1-4</a>).</p>&#13;
&#13;
<p class="less_space pagebreak-before">However, other optimizations require certain trade-offs—typically more CPU time or less readable code, for example:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p><a href="https://oreil.ly/qJu7u">String interning</a>, where we avoid operating on the <code>string</code> type by providing a dictionary and using a much smaller, pointer-free dictionary of integers representing the ID of the string.</p>&#13;
</li>&#13;
<li>&#13;
<p>Unsafe conversion <a href="https://oreil.ly/Y10YT">from <code>[]byte</code> to <code>string</code> (and vice versa) without copying memory</a>, which potentially saves allocations, but if done wrongly can keep more memory in a heap (discussed in <a data-type="xref" href="#code-overuse-mem">Example 11-15</a>).</p>&#13;
</li>&#13;
<li>&#13;
<p>Ensuring that a variable does not escape to the heap can also be considered an effort that reduces allocations.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>There are unlimited different ways we could reduce allocations. We already mentioned some earlier. For example, when doing less work, we typically can allocate less! Another tip is to look for reducing allocations on all optimization design levels (<a data-type="xref" href="ch03.html#ch-conq-opt-levels">“Optimization Design Levels”</a>), not only code. In most cases, the algorithm must change first so we can have big improvements in the space complexity before we move to the code level.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Reuse Memory" data-type="sect2"><div class="sect2" id="idm45606819341312">&#13;
<h2>Reuse Memory</h2>&#13;
&#13;
<p><a data-primary="three Rs optimization method" data-secondary="reusing memory" data-type="indexterm" id="idm45606819340304"/>Reusing is also an effective technique. As we learned in <a data-type="xref" href="ch05.html#ch-hw-garbage">“Garbage Collection”</a>, the Go runtime already reuses memory somehow. Still, there are ways to explicitly reuse objects like variables, slices, or maps for repeated operations instead of re-creating them in every loop. We will discuss some techniques in <a data-type="xref" href="#ch-basic-pool">“Memory Reuse and Pooling”</a>.</p>&#13;
&#13;
<p>Again, utilize all optimization design levels (see <a data-type="xref" href="ch03.html#ch-conq-opt-levels">“Optimization Design Levels”</a>). We can choose the designs of systems or algorithms that reuse memory; for example, see <a data-type="xref" href="ch10.html#ch-opt-mem-example-stream">“Moving to Streaming Algorithm”</a>. Another example of a “reuse” optimization on the system level is the TCP protocol. It offers to keep connections alive for reuse, which also helps with the network latency required to establish a new connection.</p>&#13;
<div data-type="warning" epub:type="warning"><h1>Be Careful When Reusing</h1>&#13;
<p>Treating this tip literally is tempting—many try to go as far as reusing every little thing, including variables. As we learned in <a data-type="xref" href="ch05.html#ch-hw-allocations">“Values, Pointers, and Memory Blocks”</a>, variables are boxes that require some memory, but usually it’s on the stack, so we should not be afraid to create more of them if needed. On the contrary, overusing variables can lead to hard-to-find bugs when <a href="https://oreil.ly/9Dfvb">we shadow variables</a>.</p>&#13;
&#13;
<p>Reusing complex structures can also be very dangerous for two reasons:<sup><a data-type="noteref" href="ch11.html#idm45606819332528" id="idm45606819332528-marker">4</a></sup></p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>It is often not easy to reset the state of a complex structure before using it a second time (instead of allocating a new one, which creates a deterministic, empty structure).</p>&#13;
</li>&#13;
<li>&#13;
<p>We cannot concurrently use those structures, which can limit further optimizations or surprise us and cause data races.</p>&#13;
</li>&#13;
</ul>&#13;
</div>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Recycle" data-type="sect2"><div class="sect2" id="idm45606819328976">&#13;
<h2>Recycle</h2>&#13;
&#13;
<p><a data-primary="garbage collection (GC)" data-secondary="recycling and" data-type="indexterm" id="ix_ch11-asciidoc5"/><a data-primary="three Rs optimization method" data-secondary="recycling" data-type="indexterm" id="ix_ch11-asciidoc6"/>Recycling is a minimum of what we must have in our programs if we use any memory. Fortunately, we don’t need anything extra in our Go code, as it’s the built-in GC’s responsibility to recycle unused memory to the OS, unless we utilize advanced utilities like <a data-type="xref" href="ch05.html#ch-hw-memory-mmap">“mmap Syscall”</a> or other off-heap memory techniques.</p>&#13;
&#13;
<p>However, if we can’t “reduce” or “reuse” more memory, we can sometimes optimize our code or GC configuration, so the recycling is more efficient for the garbage collection. Let’s go through some ways to improve recycling:</p>&#13;
<dl>&#13;
<dt>Optimize the structure of the allocated object</dt>&#13;
<dd>&#13;
<p>If we can’t reduce the number of allocations, maybe we can reduce the number of pointers in our objects! However, avoiding pointers is not always possible, given popular structures like <a href="https://oreil.ly/3ZmWi"><code>time</code></a>, <a href="https://oreil.ly/CIoPc"><code>string</code></a>, or <a href="https://oreil.ly/Ow484">slices</a>, which contain pointers. Especially <code>string</code> doesn’t look like it, but it is just a special <code>[]byte</code>, which means it has a pointer to a byte array. In extreme cases, in certain conditions, it might be worth changing <a href="https://oreil.ly/0zi89"><code>[]string</code> into <code>offsets []int</code> and <code>bytes []byte</code></a> to make it a pointer-free structure!</p>&#13;
&#13;
<p>Another widespread example where it’s easy to get very pointer-rich structures is when implementing data structures that are supposed to be marshaled &#13;
<span class="keep-together">and unmarshaled</span> to different byte formats like JSON, YAML, or &#13;
<span class="keep-together"><a href="https://oreil.ly/yZVuB">protobuf</a>.</span> It is tempting to use pointers for nested structures to allow optionality of the field (the ability to differentiate if the field was set or not). Some code generation engines like <a href="https://oreil.ly/SeNub">Go protobuf generator</a> put all fields as pointers by default. This is fine for smaller Go programs, but if we use a lot of objects (which is common, especially if we use them for messages over the network), we might consider trying to remove pointers from those data structures (many generators and marshalers offer that option).</p>&#13;
<div data-type="tip">&#13;
<p>Reducing the number of pointers in our structures is better for GC and can make our data structure more L-cache friendly, decreasing the program latency. It also increases the chances that the compiler will put the data structure on the stack instead of the heap!</p>&#13;
&#13;
<p>The main downside, however, is more overhead when you pass that struct by value (copy overhead mentioned in <a data-type="xref" href="ch05.html#ch-hw-allocations">“Values, Pointers, and Memory Blocks”</a>).</p>&#13;
</div>&#13;
</dd>&#13;
<dt>GC tuning</dt>&#13;
<dd>&#13;
<p>I mentioned in <a data-type="xref" href="ch05.html#ch-hw-garbage">“Garbage Collection”</a> about two tuning options for Go GC: <code>GOGC</code> and <code>GOMEMLIMIT</code>.</p>&#13;
&#13;
<p><a data-primary="GOGC option" data-type="indexterm" id="idm45606819308752"/>Adjusting the <code>GOGC</code> option from the default 100% value might sometimes positively affect your program efficiency. Moving the next GC collection to happen sooner or later (depending on  need) might be beneficial. Unfortunately, it requires lots of benchmarking to find the right number. It also does not guarantee that this tuning will work well for all possible states of your applications. On top of that, this technique has poor sustainability if you change the critical path in your code a lot. Every change requires another tuning session. This is why some bigger companies like Google and <a href="https://oreil.ly/8YMRi">Uber</a> invest in automated tools that adjust <code>GOGC</code> automatically in runtime!</p>&#13;
&#13;
<p><a data-primary="GOMEMLIMIT option" data-type="indexterm" id="idm45606819306368"/>The <code>GOMEMLIMIT</code> is another option you can adjust on top of the <code>GOGC</code>. It’s a relatively new option for GC to run more frequently when the heap is close to or above the desired soft memory limit.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45606819304736">&#13;
<h5>Using Kubernetes? Use GOMEMLIMIT &#13;
<span class="keep-together">Together with Pod Memory Limits</span></h5>&#13;
<p><a data-primary="Kubernetes with GOMEMLIMIT option" data-type="indexterm" id="idm45606819303232"/>Some orchestration systems like Kubernetes allow setting <a href="https://oreil.ly/4zpkg">hard resource limits</a> on the workloads. For incompressible resources like memory, when the workload requires more memory as a limit, the system will typically OOM the process.</p>&#13;
&#13;
<p>The <code>GOMEMLIMIT</code> option is designed to help if the GC memory overhead is causing those OOMs (GC reacted to memory spikes). The <a href="https://oreil.ly/zq6bb">official guide</a> also suggests that we should leave an additional 5–10% of headroom to account for memory sources the Go runtime is unaware of. Setting the <code>GOMEMLIMIT</code> option to 90–95% of the workload memory limit might be quite effective.</p>&#13;
&#13;
<p>If we don’t want to <a href="https://oreil.ly/GYTB9">oversubscribe memory on our machines</a>, we can also set <code>GOGC=off</code> to trigger GC only if close to the memory limit, which can save some CPU time.</p>&#13;
</div></aside>&#13;
&#13;
<p>See <a href="https://oreil.ly/3nGzV">a more detailed guide on GC tuning</a> with the interactive visualizations.</p>&#13;
</dd>&#13;
<dt>Triggering GC and freeing OS memory manually</dt>&#13;
<dd>&#13;
<p>In extreme cases, we might want to experiment with manually triggered GC collections using <code>runtime.GC()</code>. For example, we might want to trigger GC manually after an operation that allocated a lot of memory and no longer reference it. Note that a manual GC trigger is usually a strong anti-pattern, especially in libraries as it has global effects.<sup><a data-type="noteref" href="ch11.html#idm45606819295376" id="idm45606819295376-marker">5</a></sup></p>&#13;
</dd>&#13;
<dt>Allocating objects off-heap</dt>&#13;
<dd>&#13;
<p>We mentioned trying to allocate objects on the stack first instead of the heap. But the stack and heap are not our only options. There are ways to allocate memory off-heap, so that it’s outside of the Go runtime’s responsibility to manage.</p>&#13;
&#13;
<p>We can achieve that with <a href="https://oreil.ly/yko2o">the explicit <code>mmap</code> syscall</a> we learned in <a data-type="xref" href="ch05.html#ch-hw-memory-mmap">“mmap Syscall”</a>. Some have even tried <a href="https://oreil.ly/6se5i">calling C functions like <code>jemalloc</code> through the CGO</a>.</p>&#13;
&#13;
<p>While possible, we need to acknowledge that doing this can be compared to reimplementing parts of the Go Allocator from scratch, not to mention dealing with the manual allocations and lack of memory safety. It is the last thing we might want to try for the ultimate high-performance Go implementation!</p>&#13;
&#13;
<p>On the bright side, this space is continuously improving. At the time of writing this book, the Go team approved and implemented an exciting&#13;
<a href="https://oreil.ly/jXgHY">proposal</a> behind the <code>GOEXPERIMENT=arena</code> environment variable. It allows allocating a set of objects from the contiguous region of memory (<code>arena</code>) that lives outside of heap regions managed by GC. As a result, we will be able to isolate, track, and quickly release that memory explicitly when we need it (e.g., when an HTTP request is handled) without waiting or paying for garbage collection cycles. What’s special about <code>arenas</code> is that it’s meant to panic your program when you accidentally use the memory that was unused before assuring a certain level of memory safety. I can’t wait to start playing with it once it is released—it might mean safe and easier-to-use off-heap optimizations.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Benchmarking and measuring all the effects of these optimizations is essential before trying any recycle improvements on our production code. Some of these can be considered tricky to maintain and unsafe if used without extensive tests.<a data-startref="ix_ch11-asciidoc6" data-type="indexterm" id="idm45606819284496"/><a data-startref="ix_ch11-asciidoc5" data-type="indexterm" id="idm45606819283888"/></p>&#13;
&#13;
<p>To sum up, keep the three Rs method in mind, ideally in the same order: reduce, reuse, and recycle. Let’s now dive into some common Go optimizations I have seen in my experience. Some of them might surprise you!<a data-startref="ix_ch11-asciidoc4" data-type="indexterm" id="idm45606819282672"/><a data-startref="ix_ch11-asciidoc3" data-type="indexterm" id="idm45606819282064"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Don’t Leak Resources" data-type="sect1"><div class="sect1" id="ch-basic-leaks">&#13;
<h1>Don’t Leak Resources</h1>&#13;
&#13;
<p><a data-primary="optimization patterns" data-secondary="avoiding resource leak" data-type="indexterm" id="ix_ch11-asciidoc7"/><a data-primary="resource leaks, avoiding" data-type="indexterm" id="ix_ch11-asciidoc8"/>Resource leak is a common problem that reduces the efficiency of our Go programs. The leak occurs when we create some resource or background goroutine, and after using it, we want it to get released or stopped, but it is accidentally left behind. This might not be noticeable on a smaller scale, but sooner or later this can become a large and hard-to-debug issue. I suggest always clearing something you created, even if you expect to exit the program in the next cycle!<sup><a data-type="noteref" href="ch11.html#idm45606819276864" id="idm45606819276864-marker">6</a></sup></p>&#13;
<div data-type="tip"><h1>“This Program Has a Memory Leak!”</h1>&#13;
<p>Not every higher memory utilization behavior can be considered a leak. For example, we could generally “waste” more memory for some operations, resulting in a spike in heap usage, but it gets cleared at some point.</p>&#13;
&#13;
<p><a data-primary="resource leaks, avoiding" data-secondary="definition" data-type="indexterm" id="idm45606819274832"/>Technically a leak is only when, for the same amount of load on the program (e.g., the same amount of HTTP traffic for a long-living service), we use an unbounded amount of resources (e.g., disk space, memory, rows in the database), which eventually run out.</p>&#13;
&#13;
<p>There are cases of unexpected nondeterministic memory usage on the edge of the leak and waste. These are sometimes called pseudomemory leaks, and we will discuss some of them in <a data-type="xref" href="#ch-basic-subslice">“Overusing Memory with Arrays”</a>.</p>&#13;
</div>&#13;
&#13;
<p>Perhaps we might think that memory should be an exception to this rule. The stack memory is automatically removed, and the garbage collection in Go dynamically removes the memory allocated on the heap.<sup><a data-type="noteref" href="ch11.html#idm45606819271728" id="idm45606819271728-marker">7</a></sup> There is no way to trigger the cleanup of a memory block other than stop referencing it and waiting (or triggering) a full GC cycle. However, don’t let that fool you. There are many cases when the Go developer writes code that leaks memory, despite eventual garbage collection!</p>&#13;
&#13;
<p>There are a few reasons our program leaks memory:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Our program constantly creates custom <code>mmap</code> syscalls and never closes them (or closes them slower than creating them). This will typically end with a process or machine OOM.</p>&#13;
</li>&#13;
<li>&#13;
<p>Our program calls too many nested functions, typically infinite or large recursion. Our process will then exit with a stack overflow error.</p>&#13;
</li>&#13;
<li>&#13;
<p>We are referencing a slice with a tiny length, but we forgot that its capacity is very large, as explained in <a data-type="xref" href="#ch-basic-subslice">“Overusing Memory with Arrays”</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Our program constantly creates memory blocks on the heap, which are always referenced by some variables in the execution scope. This typically means we have leaked goroutines or infinitely growing slices or maps.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>It’s easy to fix memory leaks when we know where they are, but it’s not easy to spot them. We often learn about leaks after the fact, when our application has already crashed. Without advanced tools like those in <a data-type="xref" href="ch09.html#ch-obs-cont-profiling">“Continuous Profiling”</a>, we have to hope to reproduce the problem with local tests, which is not always &#13;
<span class="keep-together">possible.</span></p>&#13;
&#13;
<p>Even with the past heap profile, during the leak, we only see memory in the code that allocated memory blocks, not the code that currently references it.<sup><a data-type="noteref" href="ch11.html#idm45606819262800" id="idm45606819262800-marker">8</a></sup> Some of the memory leaks, especially those caused by leaked goroutines, can be narrowed down thanks to the goroutine, but not always.</p>&#13;
&#13;
<p>Fortunately, a few best practices can proactively prevent us from leaking any incompressible resource (e.g., disk space, memory, etc.) and avoid that painful leak analysis. Consider the suggestions in this section as something we always care for and use as reasonable optimizations.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Control the Lifecycle of Your Goroutines" data-type="sect2"><div class="sect2" id="idm45606819260592">&#13;
<h2>Control the Lifecycle of Your Goroutines</h2>&#13;
<blockquote><p>Every time you use the go keyword in your program to launch a goroutine, you must know how, and when, that goroutine will exit. If you don’t know the answer, that’s a potential memory leak.</p>&#13;
&#13;
<p data-type="attribution">Dave Cheney, <a href="https://oreil.ly/eZKzr">“Never Start a goroutine Without Knowing How It Will Stop”</a></p></blockquote>&#13;
&#13;
<p><a data-primary="goroutine" data-secondary="controlling lifecycle of" data-type="indexterm" id="ix_ch11-asciidoc9"/><a data-primary="resource leaks, avoiding" data-secondary="controlling goroutine lifecycle" data-type="indexterm" id="ix_ch11-asciidoc10"/>Goroutines <a data-primary="Cheney, Dave" data-secondary="on goroutines" data-type="indexterm" id="idm45606819254832"/>are an elegant and clean framework for concurrent programming but have some downsides. One is that each goroutine is fully isolated from other goroutines (unless we use an explicit synchronization paradigm). There is no central dispatch in the Go runtime that we could call and, for example, ask to close the goroutines created by the current goroutine (or even check which one it created). This is not a lack of maturity of the framework, but rather a design choice allowing goroutines to be very efficient. As a trade-off, we have to implement potential code that will stop them when the job is done—or, to be specific, the code inside the goroutine to stop itself (the only way!).</p>&#13;
&#13;
<p>The solution is never to create a goroutine and leave it on its own without strict control, even if we think the computation is fast. Instead, when scheduling goroutines, think about two aspects:</p>&#13;
<dl>&#13;
<dt>How to stop them</dt>&#13;
<dd>&#13;
<p>We should always ask ourselves when the goroutine will finish. Will it finish on its own, or do I have to trigger the finish using context, channels, and so on (as in the examples that follow)? Should I be able to abort the goroutine long execution if, e.g., the request was cancelled?</p>&#13;
</dd>&#13;
<dt>Should my function wait for the goroutine to finish?</dt>&#13;
<dd>&#13;
<p>Do I want my code to continue the execution without waiting for my goroutines to finish? Usually, the answer is no, and you should wait for the goroutine to stop, for example, using channels <a href="https://oreil.ly/PQHom"><code>sync.WaitGroup</code></a> (e.g., in <a data-type="xref" href="ch10.html#code-sum-concurrent1">Example 10-10</a>), <a href="https://oreil.ly/G1Aqx"><code>errgroup</code></a>, or the excellent <a href="https://oreil.ly/B1ABL"><code>run.Group</code></a> abstraction.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>There are many cases where it feels safe just to let the goroutines “eventually” stop, but in practice, not waiting for them has dangerous consequences. For example, consider the HTTP server handler that computes some number asynchronously in <a data-type="xref" href="#code-leakhandle1">Example 11-2</a>.</p>&#13;
<div data-type="example" id="code-leakhandle1">&#13;
<h5><span class="label">Example 11-2. </span>Showcase of a common leak in a concurrent function</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">ComplexComputation</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="kt">int</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO2-1" id="co_optimization_patterns_CO2-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
    </code><code class="c1">// Some computation...</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="c1">// Some cleanup...</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="mi">4</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">Handle_VeryWrong</code><code class="p">(</code><code class="nx">w</code><code class="w"> </code><code class="nx">http</code><code class="p">.</code><code class="nx">ResponseWriter</code><code class="p">,</code><code class="w"> </code><code class="nx">r</code><code class="w"> </code><code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Request</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">respCh</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="kd">chan</code><code class="w"> </code><code class="kt">int</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">go</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO2-2" id="co_optimization_patterns_CO2-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
        </code><code class="k">defer</code><code class="w"> </code><code class="nb">close</code><code class="p">(</code><code class="nx">respCh</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO2-3" id="co_optimization_patterns_CO2-3"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
        </code><code class="nx">respCh</code><code class="w"> </code><code class="o">&lt;-</code><code class="w"> </code><code class="nx">ComplexComputation</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">select</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO2-4" id="co_optimization_patterns_CO2-4"><img alt="4" src="assets/4.png"/></a><code class="w">&#13;
    </code><code class="k">case</code><code class="w"> </code><code class="o">&lt;-</code><code class="nx">r</code><code class="p">.</code><code class="nx">Context</code><code class="p">(</code><code class="p">)</code><code class="p">.</code><code class="nx">Done</code><code class="p">(</code><code class="p">)</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO2-5" id="co_optimization_patterns_CO2-5"><img alt="5" src="assets/5.png"/></a><code class="w">&#13;
    </code><code class="k">case</code><code class="w"> </code><code class="nx">resp</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="o">&lt;-</code><code class="nx">respCh</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">_</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">w</code><code class="p">.</code><code class="nx">Write</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="nb">byte</code><code class="p">(</code><code class="nx">strconv</code><code class="p">.</code><code class="nx">Itoa</code><code class="p">(</code><code class="nx">resp</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO2-1" id="callout_optimization_patterns_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Small function simulating longer computation. Imagine it takes around two seconds to complete all.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO2-2" id="callout_optimization_patterns_CO2-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Imagine a handler that schedules asynchronous computation.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO2-3" id="callout_optimization_patterns_CO2-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Our code does not depend on someone closing the channel, but as a good practice, the sender closes it.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO2-4" id="callout_optimization_patterns_CO2-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>If cancellation happens, we return immediately. Otherwise, we wait for the result. At first glance, the above code does not look too bad. It feels like we control the lifecycle of the scheduled goroutine.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO2-5" id="callout_optimization_patterns_CO2-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Unfortunately, the detail is hidden in more information. We control the lifecycle only in a good case (when no cancellation occurs). If our code hits this line, we are doing something bad here. We return without caring about the goroutine lifecycle. We don’t stop it. We don’t wait for it. Even worse, this is a permanent leak, i.e., the goroutine with <code>ComplexCalculation</code> will be starved—as no one reads from the <code>respCh</code> channel.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>While the goroutine looks like it’s controlled, it isn’t in all cases. This leaky code is commonly seen in the Go codebase because it requires a lot of detailed focus to not forget about every little edge case. As a result of these mistakes, we tend to delay using goroutines in our Go, as it’s easy to create leaks like this.</p>&#13;
&#13;
<p>The worst part about leaks is that our Go program might survive long before someone notices the adverse effects of such leaks. For example, running <code>Handle_VeryWrong</code> and cancelling it periodically will eventually OOM this Go program, but if we cancel only from time to time and restart our application periodically, without good observability we might never notice it!</p>&#13;
&#13;
<p>Fortunately, an amazing tool allows us to discover those leaks at the unit test level. Therefore, I suggest using a leak test in every unit (or test file) that uses concurrent code. One of them is called <a href="https://oreil.ly/4N4bb"><code>goleak</code></a> from Uber, and its basic use is presented in <a data-type="xref" href="#code-leakhandletest">Example 11-3</a>.</p>&#13;
<div data-type="example" id="code-leakhandletest">&#13;
<h5><span class="label">Example 11-3. </span>Testing for leaks in <a data-type="xref" href="#code-leakhandle1">Example 11-2</a> code</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">TestHandleCancel</code><code class="p">(</code><code class="nx">t</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">T</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO3-1" id="co_optimization_patterns_CO3-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
    </code><code class="k">defer</code><code class="w"> </code><code class="nx">goleak</code><code class="p">.</code><code class="nx">VerifyNone</code><code class="p">(</code><code class="nx">t</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO3-2" id="co_optimization_patterns_CO3-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
&#13;
    </code><code class="nx">w</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">httptest</code><code class="p">.</code><code class="nx">NewRecorder</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">r</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">httptest</code><code class="p">.</code><code class="nx">NewRequest</code><code class="p">(</code><code class="s">""</code><code class="p">,</code><code class="w"> </code><code class="s">"https://efficientgo.com"</code><code class="p">,</code><code class="w"> </code><code class="kc">nil</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">wg</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">sync</code><code class="p">.</code><code class="nx">WaitGroup</code><code class="p">{</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">wg</code><code class="p">.</code><code class="nx">Add</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">ctx</code><code class="p">,</code><code class="w"> </code><code class="nx">cancel</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">context</code><code class="p">.</code><code class="nx">WithCancel</code><code class="p">(</code><code class="nx">context</code><code class="p">.</code><code class="nx">Background</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">go</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">Handle_VeryWrong</code><code class="p">(</code><code class="nx">w</code><code class="p">,</code><code class="w"> </code><code class="nx">r</code><code class="p">.</code><code class="nx">WithContext</code><code class="p">(</code><code class="nx">ctx</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">wg</code><code class="p">.</code><code class="nx">Done</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">cancel</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">wg</code><code class="p">.</code><code class="nx">Wait</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO3-1" id="callout_optimization_patterns_CO3-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Let’s create tests that verify cancel behavior. This is where the leak is suspected to be triggered.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO3-2" id="callout_optimization_patterns_CO3-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>To verify goroutine leaks, just defer <a href="https://oreil.ly/bgcwF"><code>goleak.VerifyNone</code></a> at the top of our test. It runs at the end of our test and fails if any unexpected goroutine is still running. We can also verify whole package tests using the <a href="https://oreil.ly/zyPjr"><code>goloak.VerifyTestMain</code> method</a>.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>Running such a test causes the test to fail with the output in <a data-type="xref" href="#code-leakhandletest-out">Example 11-4</a>.</p>&#13;
<div data-type="example" id="code-leakhandletest-out">&#13;
<h5><span class="label">Example 11-4. </span>Output of two failed runs of <a data-type="xref" href="#code-leakhandletest">Example 11-3</a></h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="o">==</code><code class="p">=</code><code class="w"> </code><code class="nx">RUN</code><code class="w">   </code><code class="nx">TestHandleCancel</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">leaks</code><code class="p">.</code><code class="k">go</code><code class="p">:</code><code class="mi">78</code><code class="p">:</code><code class="w"> </code><code class="nx">found</code><code class="w"> </code><code class="nx">unexpected</code><code class="w"> </code><code class="nx">goroutines</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">[</code><code class="nx">Goroutine</code><code class="w"> </code><code class="mi">8</code><code class="w"> </code><code class="nx">in</code><code class="w"> </code><code class="nx">state</code><code class="w"> </code><code class="nx">sleep</code><code class="p">,</code><code class="w"> </code><code class="nx">with</code><code class="w"> </code><code class="nx">time</code><code class="p">.</code><code class="nx">Sleep</code><code class="w"> </code><code class="nx">on</code><code class="w"> </code><code class="nx">top</code><code class="w"> </code><code class="nx">of</code><code class="w"> </code><code class="nx">the</code><code class="w"> </code><code class="nx">stack</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">goroutine</code><code class="w"> </code><code class="mi">8</code><code class="w"> </code><code class="p">[</code><code class="nx">sleep</code><code class="p">]</code><code class="p">:</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO4-1" id="co_optimization_patterns_CO4-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
        </code><code class="nx">time</code><code class="p">.</code><code class="nx">Sleep</code><code class="p">(</code><code class="mh">0x3b9aca00</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">           </code><code class="o">/</code><code class="nx">go1</code><code class="mf">.18</code><code class="mf">.3</code><code class="o">/</code><code class="nx">src</code><code class="o">/</code><code class="nx">runtime</code><code class="o">/</code><code class="nx">time</code><code class="p">.</code><code class="k">go</code><code class="p">:</code><code class="mi">194</code><code class="w"> </code><code class="o">+</code><code class="mh">0x12e</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">github</code><code class="p">.</code><code class="nx">com</code><code class="o">/</code><code class="nx">efficientgo</code><code class="o">/</code><code class="nx">examples</code><code class="o">/</code><code class="nx">pkg</code><code class="o">/</code><code class="nx">leak</code><code class="p">.</code><code class="nx">ComplexComputation</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">           </code><code class="o">/</code><code class="nx">examples</code><code class="o">/</code><code class="nx">pkg</code><code class="o">/</code><code class="nx">leak</code><code class="o">/</code><code class="nx">leak_test</code><code class="p">.</code><code class="k">go</code><code class="p">:</code><code class="mi">107</code><code class="w"> </code><code class="o">+</code><code class="mh">0x1e</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">github</code><code class="p">.</code><code class="nx">com</code><code class="o">/</code><code class="nx">efficientgo</code><code class="o">/</code><code class="nx">examples</code><code class="o">/</code><code class="nx">pkg</code><code class="o">/</code><code class="nx">leak</code><code class="p">.</code><code class="nx">Handle_VeryWrong</code><code class="p">.</code><code class="nx">func1</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">           </code><code class="o">/</code><code class="nx">examples</code><code class="o">/</code><code class="nx">pkg</code><code class="o">/</code><code class="nx">leak</code><code class="o">/</code><code class="nx">leak_test</code><code class="p">.</code><code class="k">go</code><code class="p">:</code><code class="mi">117</code><code class="w"> </code><code class="o">+</code><code class="mh">0x5d</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">created</code><code class="w"> </code><code class="nx">by</code><code class="w"> </code><code class="nx">github</code><code class="p">.</code><code class="nx">com</code><code class="o">/</code><code class="nx">efficientgo</code><code class="o">/</code><code class="nx">examples</code><code class="o">/</code><code class="nx">pkg</code><code class="o">/</code><code class="nx">leak</code><code class="p">.</code><code class="nx">Handle_VeryWrong</code><code class="w">&#13;
</code><code class="w">           </code><code class="o">/</code><code class="nx">examples</code><code class="o">/</code><code class="nx">pkg</code><code class="o">/</code><code class="nx">leak</code><code class="o">/</code><code class="nx">leak_test</code><code class="p">.</code><code class="k">go</code><code class="p">:</code><code class="mi">115</code><code class="w"> </code><code class="o">+</code><code class="mh">0x7d</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">]</code><code class="w">&#13;
</code><code class="o">--</code><code class="o">-</code><code class="w"> </code><code class="nx">FAIL</code><code class="p">:</code><code class="w"> </code><code class="nx">TestHandleCancel</code><code class="w"> </code><code class="p">(</code><code class="mf">0.44</code><code class="nx">s</code><code class="p">)</code><code class="w">&#13;
</code><code class="o">==</code><code class="p">=</code><code class="w"> </code><code class="nx">RUN</code><code class="w">   </code><code class="nx">TestHandleCancel</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">leaks</code><code class="p">.</code><code class="k">go</code><code class="p">:</code><code class="mi">78</code><code class="p">:</code><code class="w"> </code><code class="nx">found</code><code class="w"> </code><code class="nx">unexpected</code><code class="w"> </code><code class="nx">goroutines</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">[</code><code class="nx">Goroutine</code><code class="w"> </code><code class="mi">21</code><code class="w"> </code><code class="nx">in</code><code class="w"> </code><code class="nx">state</code><code class="w"> </code><code class="kd">chan</code><code class="w"> </code><code class="nx">send</code><code class="p">,</code><code class="w"> </code><code class="nx">with</code><code class="w"> </code><code class="nx">Handle_VeryWrong</code><code class="p">.</code><code class="nx">func1</code><code class="w"> </code><code class="p">(</code><code class="o">...</code><code class="p">)</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">goroutine</code><code class="w"> </code><code class="mi">21</code><code class="w"> </code><code class="p">[</code><code class="kd">chan</code><code class="w"> </code><code class="nx">send</code><code class="p">]</code><code class="p">:</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO4-2" id="co_optimization_patterns_CO4-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
        </code><code class="nx">github</code><code class="p">.</code><code class="nx">com</code><code class="o">/</code><code class="nx">efficientgo</code><code class="o">/</code><code class="nx">examples</code><code class="o">/</code><code class="nx">pkg</code><code class="o">/</code><code class="nx">leak</code><code class="p">.</code><code class="nx">Handle_VeryWrong</code><code class="p">.</code><code class="nx">func1</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">           </code><code class="o">/</code><code class="nx">examples</code><code class="o">/</code><code class="nx">pkg</code><code class="o">/</code><code class="nx">leak</code><code class="o">/</code><code class="nx">leak_test</code><code class="p">.</code><code class="k">go</code><code class="p">:</code><code class="mi">117</code><code class="w"> </code><code class="o">+</code><code class="mh">0x71</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">created</code><code class="w"> </code><code class="nx">by</code><code class="w"> </code><code class="nx">github</code><code class="p">.</code><code class="nx">com</code><code class="o">/</code><code class="nx">efficientgo</code><code class="o">/</code><code class="nx">examples</code><code class="o">/</code><code class="nx">pkg</code><code class="o">/</code><code class="nx">leak</code><code class="p">.</code><code class="nx">Handle_VeryWrong</code><code class="w">&#13;
</code><code class="w">           </code><code class="o">/</code><code class="nx">examples</code><code class="o">/</code><code class="nx">pkg</code><code class="o">/</code><code class="nx">leak</code><code class="o">/</code><code class="nx">leak_test</code><code class="p">.</code><code class="k">go</code><code class="p">:</code><code class="mi">115</code><code class="w"> </code><code class="o">+</code><code class="mh">0x7d</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">]</code><code class="w">&#13;
</code><code class="o">--</code><code class="o">-</code><code class="w"> </code><code class="nx">FAIL</code><code class="p">:</code><code class="w"> </code><code class="nx">TestHandleCancel</code><code class="w"> </code><code class="p">(</code><code class="mf">3.44</code><code class="nx">s</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO4-1" id="callout_optimization_patterns_CO4-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>We see the goroutines still running at the end of the test and what they were executing.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO4-2" id="callout_optimization_patterns_CO4-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>If we waited a few seconds after cancelling, we could see that the goroutine was still running. However, this time it was waiting on a read from <code>respCh</code>, which would never happen.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>The solution to such an edge case leak is to fix the <a data-type="xref" href="#code-leakhandle1">Example 11-2</a> code. So let’s go through two potential solutions in <a data-type="xref" href="#code-leakhandle2">Example 11-5</a> that seem to fix the problem, but still leak in some way!</p>&#13;
<div data-type="example" id="code-leakhandle2">&#13;
<h5><span class="label">Example 11-5. </span>(Still) leaking handlers. This time the goroutines left behind eventually stop.</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">Handle_Wrong</code><code class="p">(</code><code class="nx">w</code><code class="w"> </code><code class="nx">http</code><code class="p">.</code><code class="nx">ResponseWriter</code><code class="p">,</code><code class="w"> </code><code class="nx">r</code><code class="w"> </code><code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Request</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">respCh</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="kd">chan</code><code class="w"> </code><code class="kt">int</code><code class="p">,</code><code class="w"> </code><code class="mi">1</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO5-1" id="co_optimization_patterns_CO5-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
&#13;
    </code><code class="k">go</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">defer</code><code class="w"> </code><code class="nb">close</code><code class="p">(</code><code class="nx">respCh</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">respCh</code><code class="w"> </code><code class="o">&lt;-</code><code class="w"> </code><code class="nx">ComplexComputation</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">select</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">case</code><code class="w"> </code><code class="o">&lt;-</code><code class="nx">r</code><code class="p">.</code><code class="nx">Context</code><code class="p">(</code><code class="p">)</code><code class="p">.</code><code class="nx">Done</code><code class="p">(</code><code class="p">)</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">case</code><code class="w"> </code><code class="nx">resp</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="o">&lt;-</code><code class="nx">respCh</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">_</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">w</code><code class="p">.</code><code class="nx">Write</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="nb">byte</code><code class="p">(</code><code class="nx">strconv</code><code class="p">.</code><code class="nx">Itoa</code><code class="p">(</code><code class="nx">resp</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">Handle_AlsoWrong</code><code class="p">(</code><code class="nx">w</code><code class="w"> </code><code class="nx">http</code><code class="p">.</code><code class="nx">ResponseWriter</code><code class="p">,</code><code class="w"> </code><code class="nx">r</code><code class="w"> </code><code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Request</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">respCh</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="kd">chan</code><code class="w"> </code><code class="kt">int</code><code class="p">,</code><code class="w"> </code><code class="mi">1</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">go</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">defer</code><code class="w"> </code><code class="nb">close</code><code class="p">(</code><code class="nx">respCh</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">respCh</code><code class="w"> </code><code class="o">&lt;-</code><code class="w"> </code><code class="nx">ComplexComputationWithCtx</code><code class="p">(</code><code class="nx">r</code><code class="p">.</code><code class="nx">Context</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO5-2" id="co_optimization_patterns_CO5-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
    </code><code class="p">}</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">select</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">case</code><code class="w"> </code><code class="o">&lt;-</code><code class="nx">r</code><code class="p">.</code><code class="nx">Context</code><code class="p">(</code><code class="p">)</code><code class="p">.</code><code class="nx">Done</code><code class="p">(</code><code class="p">)</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">case</code><code class="w"> </code><code class="nx">resp</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="o">&lt;-</code><code class="nx">respCh</code><code class="p">:</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">_</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">w</code><code class="p">.</code><code class="nx">Write</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="nb">byte</code><code class="p">(</code><code class="nx">strconv</code><code class="p">.</code><code class="nx">Itoa</code><code class="p">(</code><code class="nx">resp</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">ComplexComputationWithCtx</code><code class="p">(</code><code class="nx">ctx</code><code class="w"> </code><code class="nx">context</code><code class="p">.</code><code class="nx">Context</code><code class="p">)</code><code class="w"> </code><code class="p">(</code><code class="nx">ret</code><code class="w"> </code><code class="kt">int</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="kd">var</code><code class="w"> </code><code class="nx">done</code><code class="w"> </code><code class="kt">bool</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="p">!</code><code class="nx">done</code><code class="w"> </code><code class="o">&amp;&amp;</code><code class="w"> </code><code class="nx">ctx</code><code class="p">.</code><code class="nx">Err</code><code class="w"> </code><code class="o">==</code><code class="w"> </code><code class="kc">nil</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="c1">// Some partial computation...</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="c1">// Some cleanup... </code><a class="co" href="#callout_optimization_patterns_CO5-3" id="co_optimization_patterns_CO5-3"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="nx">ret</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO5-1" id="callout_optimization_patterns_CO5-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The only difference between this code and <code>HandleVeryWrong</code> in <a data-type="xref" href="#code-leakhandle1">Example 11-2</a> is that we create a channel with a buffer for one message. This allows the computation goroutine to push one message to this channel without waiting for someone to read it. If we cancel and wait some time, the “left behind” goroutine will eventually finish.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO5-2" id="callout_optimization_patterns_CO5-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>To make things more efficient, we could even implement a <code>ComplexComputationWithCtx</code> that accepts context, which cancels computation and is no longer needed.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO5-3" id="callout_optimization_patterns_CO5-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Many context-cancelled functions do not finish immediately when the context is cancelled. Perhaps context is checked periodically, or some cleanup might be needed to revert cancelled changes. In our case, we simulate cleanup wait time with sleep.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>The examples in <a data-type="xref" href="#code-leakhandle2">Example 11-5</a> provide some progress, but unfortunately, they still technically leak. In some ways, the leak is only temporary, but it can still cause problems for the following reasons:</p>&#13;
<dl>&#13;
<dt>Unaccounted resource usage.</dt>&#13;
<dd>&#13;
<p>If we used the <code>Handle_AlsoWrong</code> function for request A, then A would cancel. As a result, the <code>ComplexComputation</code> would accidentally allocate a lot of memory after <code>Handle_AlsoWrong</code> finished—it would create a confusing situation. Furthermore, all observability tools would indicate that a spike of memory happened after request A finished, so it would be a false perception that request A is not correlated to the memory problem.</p>&#13;
&#13;
<p>Accounting problems can have big consequences on the future scalability of our program. For example, imagine that a cancelled request usually takes 200 ms to finish. That’s not true—if we accounted for all computations, we would see it’s 200 ms with, e.g., 1 second for <code>ComplexComputation</code> cleanup latency. This calculation is very important when predicting resource usage for certain traffic given certain machine resources.</p>&#13;
</dd>&#13;
<dt>We can run out of resources sooner.</dt>&#13;
<dd>&#13;
<p>Such “left behind” goroutines can still cause OOM as the usage is non-deterministic. Continuous runs and cancels can still give the impression that the server is ready to schedule another request, and keep adding leaked asynchronous jobs, which can eventually starve the program. This situation fits in the leak definition.</p>&#13;
</dd>&#13;
<dt>Are we sure they finished?</dt>&#13;
<dd>&#13;
<p>Furthermore, leaving behind goroutines gives us no visibility on how long they run and if they finished in all edge cases. Perhaps there is a bug that gets them stuck at some point.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>As a result, I would highly suggest never leaving behind goroutines in your code. Fortunately, <a data-type="xref" href="#code-leakhandletest">Example 11-3</a> marks all three functions (<code>Handle_VeryWrong</code>, <code>Handle_Wrong</code>, and <code>Handle_AlsoWrong</code>) as leaking, which is usually what we want. To fix the leak completely, we can, in our case, always wait for the result channel, as presented in <a data-type="xref" href="#code-leakhandle3">Example 11-6</a>.</p>&#13;
<div data-type="example" id="code-leakhandle3">&#13;
<h5><span class="label">Example 11-6. </span>Version of <a data-type="xref" href="#code-leakhandle1">Example 11-2</a> that is not leaking</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">Handle_Better</code><code class="p">(</code><code class="nx">w</code><code class="w"> </code><code class="nx">http</code><code class="p">.</code><code class="nx">ResponseWriter</code><code class="p">,</code><code class="w"> </code><code class="nx">r</code><code class="w"> </code><code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Request</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">respCh</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="kd">chan</code><code class="w"> </code><code class="kt">int</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">go</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">defer</code><code class="w"> </code><code class="nb">close</code><code class="p">(</code><code class="nx">respCh</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">respCh</code><code class="w"> </code><code class="o">&lt;-</code><code class="w"> </code><code class="nx">ComplexComputationWithCtx</code><code class="p">(</code><code class="nx">r</code><code class="p">.</code><code class="nx">Context</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">resp</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="o">&lt;-</code><code class="nx">respCh</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO6-1" id="co_optimization_patterns_CO6-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
    </code><code class="k">if</code><code class="w"> </code><code class="nx">r</code><code class="p">.</code><code class="nx">Context</code><code class="p">(</code><code class="p">)</code><code class="p">.</code><code class="nx">Err</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="kc">nil</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">_</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">w</code><code class="p">.</code><code class="nx">Write</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="nb">byte</code><code class="p">(</code><code class="nx">strconv</code><code class="p">.</code><code class="nx">Itoa</code><code class="p">(</code><code class="nx">resp</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO6-1" id="callout_optimization_patterns_CO6-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Always reading from the channel allows us to wait for the goroutine stop. We also respond to cancel as quickly as possible, thanks to propagating proper context to <code>ComplexComputationWithCtx</code>.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>Last but not least, be careful when you benchmark concurrent code. Always wait in each <code>b.N</code> iteration for what you want to define as “an operation.” A common leak in benchmarking code with the solution is presented in <a data-type="xref" href="#code-leakbenchmark">Example 11-7</a>.</p>&#13;
<div data-type="example" id="code-leakbenchmark">&#13;
<h5><span class="label">Example 11-7. </span>Showcase of a common leak in benchmarking concurrent code</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">BenchmarkComplexComputation_Wrong</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO7-1" id="co_optimization_patterns_CO7-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
    </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">go</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><code class="nx">ComplexComputation</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">}</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">go</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><code class="nx">ComplexComputation</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">}</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">BenchmarkComplexComputation_Better</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO7-2" id="co_optimization_patterns_CO7-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
    </code><code class="k">defer</code><code class="w"> </code><code class="nx">goleak</code><code class="p">.</code><code class="nx">VerifyNone</code><code class="p">(</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">b</code><code class="p">,</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">goleak</code><code class="p">.</code><code class="nx">IgnoreTopFunction</code><code class="p">(</code><code class="s">"testing.(*B).run1"</code><code class="p">)</code><code class="p">,</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">goleak</code><code class="p">.</code><code class="nx">IgnoreTopFunction</code><code class="p">(</code><code class="s">"testing.(*B).doBench"</code><code class="p">)</code><code class="p">,</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO7-3" id="co_optimization_patterns_CO7-3"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
&#13;
    </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">wg</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">sync</code><code class="p">.</code><code class="nx">WaitGroup</code><code class="p">{</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">wg</code><code class="p">.</code><code class="nx">Add</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">go</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="k">defer</code><code class="w"> </code><code class="nx">wg</code><code class="p">.</code><code class="nx">Done</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">            </code><code class="nx">ComplexComputation</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">}</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">go</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="k">defer</code><code class="w"> </code><code class="nx">wg</code><code class="p">.</code><code class="nx">Done</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">            </code><code class="nx">ComplexComputation</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">}</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">wg</code><code class="p">.</code><code class="nx">Wait</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">   </code><code class="p">}</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO7-1" id="callout_optimization_patterns_CO7-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Let’s say we want to benchmark concurrent <code>ComplexComputation</code>. Scheduling two goroutines might find some interesting slowdowns if any resources are shared between those functions. However, these benchmark results are completely wrong. My machine shows <code>1860 ns/op</code>, but if we look carefully, we will see we don’t wait for any of those goroutines to complete. As a result, we only measure the latency needed to schedule two goroutines per operation.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO7-2" id="callout_optimization_patterns_CO7-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>To measure the latency of two concurrent computations, we have to wait for their completion, perhaps with <code>sync.WaitGroup</code>. This benchmark shows a much more realistic <code>2000339135 ns/op</code> (two seconds per operation) result.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO7-3" id="callout_optimization_patterns_CO7-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>We can also use <code>goleak</code> on our benchmarks to verify against leaks! However, we need to have a benchmark-specific filter due to this <a href="https://oreil.ly/VTE9t">issue</a>.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>To sum up, control your goroutine lifecycle for reliable efficiency now and in the future! Ensure the goroutine lifecycle as a reasonable optimization.<a data-startref="ix_ch11-asciidoc10" data-type="indexterm" id="idm45606817623536"/><a data-startref="ix_ch11-asciidoc9" data-type="indexterm" id="idm45606817622832"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Reliably Close Things" data-type="sect2"><div class="sect2" id="idm45606819259680">&#13;
<h2>Reliably Close Things</h2>&#13;
&#13;
<p><a data-primary="resource leaks, avoiding" data-secondary="closing objects" data-type="indexterm" id="ix_ch11-asciidoc11"/>This might be obvious, but if we create some object that is supposed to be closed after use, we should ensure we don’t forget or ignore this. We have to be extra careful if we create an instance of some <code>struct</code> or use a function, and we see some kind of “closer,” for example:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>It returns <code>cancel</code> or <code>close</code> closure, e.g., <a href="https://oreil.ly/lmvQd"><code>context.WithTimeout</code></a> or <a href="https://oreil.ly/aVkMY"><code>context.WithCancel</code></a>.<sup><a data-type="noteref" href="ch11.html#idm45606817523552" id="idm45606817523552-marker">9</a></sup></p>&#13;
</li>&#13;
<li>&#13;
<p>The returned object has a method with closing, cancelling, or &#13;
<span class="keep-together">stopping-like semantics,</span> e.g., <a href="https://oreil.ly/7Lyfs"><code>io.ReaderCloser.Close()</code></a>, <a href="https://oreil.ly/V7ba8"><code>time.Timer.Stop()</code></a>, or TearDown.</p>&#13;
</li>&#13;
<li>&#13;
<p>Some functions do not have a closer method but have a dedicated closing or deleting package-level function, e.g., the corresponding “releasing” function &#13;
<span class="keep-together">for <a href="https://oreil.ly/a2nt4"><code>os.Create</code></a></span> or <a href="https://oreil.ly/klgKo"><code>os.Mkdir</code></a> is <a href="https://oreil.ly/DPNIA"><code>os.Remove</code></a>.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>If we have such a situation, assume the worst: if we don’t call that function at the end of using that object, bad things will happen. Some goroutine will not finish, some memory will be kept referenced, or worse, our data will not bet saved (e.g., in case of <code>os.File.Close()</code>). We should try to be vigilant. When we use a new abstraction, we should check if it has any closers. Unfortunately, there are no linters that would point out if we forgot to call them.<sup><a data-type="noteref" href="ch11.html#idm45606817514192" id="idm45606817514192-marker">10</a></sup></p>&#13;
&#13;
<p>Unfortunately, that isn’t everything. We can’t just defer a call to <code>Close</code>. Typically, it also returns the error, which might mean the close could not happen, and this situation has to be handled. For example, <code>os.Remove</code> failed because of permission issues and the file was not removed. If we cannot exit the application, retry, or handle the error, we should at least be aware of this potential leak.</p>&#13;
&#13;
<p>Does it mean that <code>defer</code> statements are less useful, and we have to have that <code>if err != nil</code> boilerplate for all closers? Not really. This is when I would suggest using the <a href="https://oreil.ly/ucTUB"><code>errcapture</code></a> and <a href="https://oreil.ly/vb2vn"><code>logerrcapture</code></a> packages. See <a data-type="xref" href="#code-deferclose">Example 11-8</a>.</p>&#13;
<div data-type="example" id="code-deferclose">&#13;
<h5><span class="label">Example 11-8. </span>Examples of closing files with <code>defer</code></h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="c1">// import "github.com/efficientgo/core/logerrcapture"</code><code class="w">&#13;
</code><code class="c1">// import "github.com/efficientgo/core/errcapture"</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">doWithFile_Wrong</code><code class="p">(</code><code class="nx">fileName</code><code class="w"> </code><code class="kt">string</code><code class="p">)</code><code class="w"> </code><code class="kt">error</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">f</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">os</code><code class="p">.</code><code class="nx">Open</code><code class="p">(</code><code class="nx">fileName</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">if</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="kc">nil</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w"> </code><code class="nx">err</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">defer</code><code class="w"> </code><code class="nx">f</code><code class="p">.</code><code class="nx">Close</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="c1">// Wrong! </code><a class="co" href="#callout_optimization_patterns_CO8-1" id="co_optimization_patterns_CO8-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="c1">// Use file...</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="kc">nil</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">doWithFile_CaptureCloseErr</code><code class="p">(</code><code class="nx">fileName</code><code class="w"> </code><code class="kt">string</code><code class="p">)</code><code class="w"> </code><code class="p">(</code><code class="nx">err</code><code class="w"> </code><code class="kt">error</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO8-2" id="co_optimization_patterns_CO8-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
    </code><code class="nx">f</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">os</code><code class="p">.</code><code class="nx">Open</code><code class="p">(</code><code class="nx">fileName</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">if</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="kc">nil</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w"> </code><code class="nx">err</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">defer</code><code class="w"> </code><code class="nx">errcapture</code><code class="p">.</code><code class="nx">Do</code><code class="p">(</code><code class="o">&amp;</code><code class="nx">err</code><code class="p">,</code><code class="w"> </code><code class="nx">f</code><code class="p">.</code><code class="nx">Close</code><code class="p">,</code><code class="w"> </code><code class="s">"close file"</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO8-2" id="co_optimization_patterns_CO8-3"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
&#13;
    </code><code class="c1">// Use file...</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="kc">nil</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">doWithFile_LogCloseErr</code><code class="p">(</code><code class="nx">logger</code><code class="w"> </code><code class="nx">log</code><code class="p">.</code><code class="nx">Logger</code><code class="p">,</code><code class="w"> </code><code class="nx">fileName</code><code class="w"> </code><code class="kt">string</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">f</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">os</code><code class="p">.</code><code class="nx">Open</code><code class="p">(</code><code class="nx">fileName</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">if</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="kc">nil</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">level</code><code class="p">.</code><code class="nx">Error</code><code class="p">(</code><code class="nx">logger</code><code class="p">)</code><code class="p">.</code><code class="nx">Log</code><code class="p">(</code><code class="s">"err"</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">defer</code><code class="w"> </code><code class="nx">logerrcapture</code><code class="p">.</code><code class="nx">Do</code><code class="p">(</code><code class="nx">logger</code><code class="p">,</code><code class="w"> </code><code class="nx">f</code><code class="p">.</code><code class="nx">Close</code><code class="p">,</code><code class="w"> </code><code class="s">"close file"</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO8-3" id="co_optimization_patterns_CO8-4"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
&#13;
    </code><code class="c1">// Use file...</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO8-1" id="callout_optimization_patterns_CO8-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Never ignore errors. Especially on a file close, which often flushes some of our writes to disk only on <code>Close</code>, we lose data on an error.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO8-2" id="callout_optimization_patterns_CO8-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Fortunately, we don’t need to give up on the amazing Go <code>defer</code> logic. Using <code>errcapture</code>, we can return an error if <code>f.Close</code> returns an error. If <code>doWithFile_CaptureCloseErr</code> returns an error and we do <code>Close</code>, the potential close error will be appended to the returned one. This is possible thanks to the return argument <code>(err error</code>) of this function. This pattern will not work without it!</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO8-4" id="callout_optimization_patterns_CO8-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>We can also log the close error if we can’t handle it.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>If we see any project I was involved in (and influenced to impact patterns like this), I use <code>errcapture</code> in all functions that return errors, and I can defer them—a clean and reliable way to avoid some leaks.</p>&#13;
&#13;
<p>Another common example of when we forget to close things is error cases. Suppose we have to open a set of files for later use. Making sure we close them is not always trivial, as shown in <a data-type="xref" href="#code-errclose">Example 11-9</a>.</p>&#13;
<div data-type="example" id="code-errclose">&#13;
<h5><span class="label">Example 11-9. </span>Closing files in error cases</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="c1">// import "github.com/efficientgo/core/merrors"</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">openMultiple_Wrong</code><code class="p">(</code><code class="nx">fileNames</code><code class="w"> </code><code class="o">...</code><code class="kt">string</code><code class="p">)</code><code class="w"> </code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="nx">io</code><code class="p">.</code><code class="nx">ReadCloser</code><code class="p">,</code><code class="w"> </code><code class="kt">error</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">files</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="nx">io</code><code class="p">.</code><code class="nx">ReadCloser</code><code class="p">,</code><code class="w"> </code><code class="mi">0</code><code class="p">,</code><code class="w"> </code><code class="nb">len</code><code class="p">(</code><code class="nx">fileNames</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">fn</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="k">range</code><code class="w"> </code><code class="nx">fileNames</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">f</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">os</code><code class="p">.</code><code class="nx">Open</code><code class="p">(</code><code class="nx">fn</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">if</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="kc">nil</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="k">return</code><code class="w"> </code><code class="kc">nil</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="c1">// Leaked files! </code><a class="co" href="#callout_optimization_patterns_CO9-1" id="co_optimization_patterns_CO9-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
</code><code class="w">        </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">files</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nb">append</code><code class="p">(</code><code class="nx">files</code><code class="p">,</code><code class="w"> </code><code class="nx">f</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="nx">files</code><code class="p">,</code><code class="w"> </code><code class="kc">nil</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">openMultiple_Correct</code><code class="p">(</code><code class="nx">fileNames</code><code class="w"> </code><code class="o">...</code><code class="kt">string</code><code class="p">)</code><code class="w"> </code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="nx">io</code><code class="p">.</code><code class="nx">ReadCloser</code><code class="p">,</code><code class="w"> </code><code class="kt">error</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">files</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="nx">io</code><code class="p">.</code><code class="nx">ReadCloser</code><code class="p">,</code><code class="w"> </code><code class="mi">0</code><code class="p">,</code><code class="w"> </code><code class="nb">len</code><code class="p">(</code><code class="nx">fileNames</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">fn</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="k">range</code><code class="w"> </code><code class="nx">fileNames</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">f</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">os</code><code class="p">.</code><code class="nx">Open</code><code class="p">(</code><code class="nx">fn</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">if</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="kc">nil</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="k">return</code><code class="w"> </code><code class="kc">nil</code><code class="p">,</code><code class="w"> </code><code class="nx">merrors</code><code class="p">.</code><code class="nx">New</code><code class="p">(</code><code class="nx">err</code><code class="p">,</code><code class="w"> </code><code class="nx">closeAll</code><code class="p">(</code><code class="nx">files</code><code class="p">)</code><code class="p">)</code><code class="p">.</code><code class="nx">Err</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO9-2" id="co_optimization_patterns_CO9-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
        </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">files</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nb">append</code><code class="p">(</code><code class="nx">files</code><code class="p">,</code><code class="w"> </code><code class="nx">f</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="nx">files</code><code class="p">,</code><code class="w"> </code><code class="kc">nil</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">closeAll</code><code class="p">(</code><code class="nx">closers</code><code class="w"> </code><code class="p">[</code><code class="p">]</code><code class="nx">io</code><code class="p">.</code><code class="nx">ReadCloser</code><code class="p">)</code><code class="w"> </code><code class="kt">error</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">errs</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">merrors</code><code class="p">.</code><code class="nx">New</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">_</code><code class="p">,</code><code class="w"> </code><code class="nx">c</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="k">range</code><code class="w"> </code><code class="nx">closers</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">errs</code><code class="p">.</code><code class="nx">Add</code><code class="p">(</code><code class="nx">c</code><code class="p">.</code><code class="nx">Close</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="nx">errs</code><code class="p">.</code><code class="nx">Err</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO9-1" id="callout_optimization_patterns_CO9-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>This is often difficult to notice, but if we create more resources that have to be closed, or we want to close them in a different function, <code>defer</code> can’t be used. This is normally fine, but if we want to create three files and we have an error when opening the second one, we are leaking resources for the first nonclosed file! We cannot just return the files opened so far from <code>openMultiple_Wrong</code> and an error because the consistent flow is to ignore anything returned if there was an error. We typically have to close the already opened file to avoid leaks and confusion.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO9-2" id="callout_optimization_patterns_CO9-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The solution is typically creating a short helper that will iterate over appended closers and close them. For example, we use the <a href="https://oreil.ly/icRMt"><code>merrors</code></a> package for convenient error append, because we want to know if any new error happened in any <code>Close</code> call.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>To sum up, closing things is very important and considered a good optimization. Of course, no single pattern or linter would prevent us from all mistakes, but we can do a lot to reduce that risk.<a data-startref="ix_ch11-asciidoc11" data-type="indexterm" id="idm45606816809456"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Exhaust Things" data-type="sect2"><div class="sect2" id="idm45606817621904">&#13;
<h2>Exhaust Things</h2>&#13;
&#13;
<p><a data-primary="resource leaks, avoiding" data-secondary="exhausting things" data-type="indexterm" id="ix_ch11-asciidoc12"/>To make things more complex, certain implementations require us to do more work to release all resources fully. For example, an <a href="https://oreil.ly/HR89x"><code>io.Reader</code></a> implementation might not give the <code>Close</code> method, but it might assume that all bytes will be read fully. On the other hand, some implementations might have a <code>Close</code> method, yet still expect us to “exhaust” the reader for efficient use.</p>&#13;
&#13;
<p>One of the most popular implementations that have such behavior are the <a href="https://oreil.ly/3Gq9j"><code>http.Request</code></a> and <a href="https://oreil.ly/3L02L"><code>http.Response</code></a> body <code>io.ReadCloser</code> from the standard library. The problem is shown in <a data-type="xref" href="#code-exhaust">Example 11-10</a>.</p>&#13;
<div data-type="example" id="code-exhaust">&#13;
<h5><span class="label">Example 11-10. </span>An example of the inefficiency of <code>http/net</code> Client caused by a wrongly handled HTTP response</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">handleResp_Wrong</code><code class="p">(</code><code class="nx">resp</code><code class="w"> </code><code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Response</code><code class="p">)</code><code class="w"> </code><code class="kt">error</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO10-1" id="co_optimization_patterns_CO10-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
    </code><code class="k">if</code><code class="w"> </code><code class="nx">resp</code><code class="p">.</code><code class="nx">StatusCode</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="nx">http</code><code class="p">.</code><code class="nx">StatusOK</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w"> </code><code class="nx">errors</code><code class="p">.</code><code class="nx">Newf</code><code class="p">(</code><code class="s">"got non-200 response; code: %v"</code><code class="p">,</code><code class="w"> </code><code class="nx">resp</code><code class="p">.</code><code class="nx">StatusCode</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="kc">nil</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">handleResp_StillWrong</code><code class="p">(</code><code class="nx">resp</code><code class="w"> </code><code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Response</code><code class="p">)</code><code class="w"> </code><code class="kt">error</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">defer</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">_</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">resp</code><code class="p">.</code><code class="nx">Body</code><code class="p">.</code><code class="nx">Close</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO10-2" id="co_optimization_patterns_CO10-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
    </code><code class="p">}</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">if</code><code class="w"> </code><code class="nx">resp</code><code class="p">.</code><code class="nx">StatusCode</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="nx">http</code><code class="p">.</code><code class="nx">StatusOK</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w"> </code><code class="nx">errors</code><code class="p">.</code><code class="nx">Newf</code><code class="p">(</code><code class="s">"got non-200 response; code: %v"</code><code class="p">,</code><code class="w"> </code><code class="nx">resp</code><code class="p">.</code><code class="nx">StatusCode</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="kc">nil</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">handleResp_Better</code><code class="p">(</code><code class="nx">resp</code><code class="w"> </code><code class="o">*</code><code class="nx">http</code><code class="p">.</code><code class="nx">Response</code><code class="p">)</code><code class="w"> </code><code class="p">(</code><code class="nx">err</code><code class="w"> </code><code class="kt">error</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">defer</code><code class="w"> </code><code class="nx">errcapture</code><code class="p">.</code><code class="nx">ExhaustClose</code><code class="p">(</code><code class="o">&amp;</code><code class="nx">err</code><code class="p">,</code><code class="w"> </code><code class="nx">resp</code><code class="p">.</code><code class="nx">Body</code><code class="p">,</code><code class="w"> </code><code class="s">"close"</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO10-3" id="co_optimization_patterns_CO10-3"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
&#13;
    </code><code class="k">if</code><code class="w"> </code><code class="nx">resp</code><code class="p">.</code><code class="nx">StatusCode</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="nx">http</code><code class="p">.</code><code class="nx">StatusOK</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">return</code><code class="w"> </code><code class="nx">errors</code><code class="p">.</code><code class="nx">Newf</code><code class="p">(</code><code class="s">"got non-200 response; code: %v"</code><code class="p">,</code><code class="w"> </code><code class="nx">resp</code><code class="p">.</code><code class="nx">StatusCode</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">return</code><code class="w"> </code><code class="kc">nil</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">BenchmarkClient</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">defer</code><code class="w"> </code><code class="nx">goleak</code><code class="p">.</code><code class="nx">VerifyNone</code><code class="p">(</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">b</code><code class="p">,</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">goleak</code><code class="p">.</code><code class="nx">IgnoreTopFunction</code><code class="p">(</code><code class="s">"testing.(*B).run1"</code><code class="p">)</code><code class="p">,</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">goleak</code><code class="p">.</code><code class="nx">IgnoreTopFunction</code><code class="p">(</code><code class="s">"testing.(*B).doBench"</code><code class="p">)</code><code class="p">,</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">c</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="o">&amp;</code><code class="nx">http</code><code class="p">.</code><code class="nx">Client</code><code class="p">{</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">defer</code><code class="w"> </code><code class="nx">c</code><code class="p">.</code><code class="nx">CloseIdleConnections</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO10-4" id="co_optimization_patterns_CO10-4"><img alt="4" src="assets/4.png"/></a><code class="w">&#13;
&#13;
    </code><code class="nx">b</code><code class="p">.</code><code class="nx">ResetTimer</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">resp</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">c</code><code class="p">.</code><code class="nx">Get</code><code class="p">(</code><code class="s">"http://google.com"</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">testutil</code><code class="p">.</code><code class="nx">Ok</code><code class="p">(</code><code class="nx">b</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">testutil</code><code class="p">.</code><code class="nx">Ok</code><code class="p">(</code><code class="nx">b</code><code class="p">,</code><code class="w"> </code><code class="nx">handleResp_Wrong</code><code class="p">(</code><code class="nx">resp</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO10-1" id="callout_optimization_patterns_CO10-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Imagine we are designing a function that handles an HTTP response from a <a href="https://oreil.ly/uB0Vd"><code>http.Client.Get</code></a> request. <code>Get</code> clearly mentions that the “caller should close resp.Body when done reading from it.” This <code>handle​R⁠esp_Wrong</code> is wrong because it leaks two goroutines:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>One doing <code>net/http.(*persistConn).writeLoop</code></p>&#13;
</li>&#13;
<li>&#13;
<p>The second doing <code>net/http.(*persistConn).readLoop</code>, which is visible when we run <code>BenchmarkClient</code> with the <code>goleak</code></p>&#13;
</li>&#13;
</ul></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO10-2" id="callout_optimization_patterns_CO10-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>The <code>handleResp_StillWrong</code> is better, as we stop the main leak. However, we still don’t read bytes from the body. We might not need them, but the <code>net/http</code> implementations can block the TCP connection if we don’t fully exhaust the body. Unfortunately, this is not well-known information. It is briefly mentioned in the <a href="https://oreil.ly/RegPv"><code>http.Client.Do</code></a> method description: “If the Body is not both read to EOF and closed, the Client’s underlying RoundTripper (typically Transport) may not be able to re-use a persistent TCP connection to the server for a subsequent ‘keep-alive’ request.”</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO10-3" id="callout_optimization_patterns_CO10-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Ideally, we read until the EOF (end of file), representing the end of whatever we are reading. For this reason we created convenient helpers like <code>ExhaustClose</code> from <a href="https://oreil.ly/4LhOs"><code>errcapture</code></a> or <a href="https://oreil.ly/XRxyA"><code>logerrcapture</code></a> that do exactly this.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO10-4" id="callout_optimization_patterns_CO10-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Client runs some goroutines for each TCP connection we want to keep alive and reuse. We can close them using <code>CloseIdleConnection</code> to detect any leaks our code might introduce.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>I wish structures like <code>http.Response.Body</code> were easier to use. The close and exhaust need for the body are important and should be used as a reasonable optimization. <code>handleResp_Wrong</code> fails the <code>BenchmarkClient</code> with a leak error. The &#13;
<span class="keep-together"><code>handleResp_StillWrong</code></span> does not leak any goroutine, so the leak test passes. The “leak” is on a different level, the TCP level, with the TCP connection being unable to reuse, which can cost us extra latency and insufficient file descriptors.</p>&#13;
&#13;
<p>We can see its impact with the results of the <code>BenchmarkClient</code> benchmark in <a data-type="xref" href="#code-exhaust">Example 11-10</a>. On my machine, it takes 265 ms to call <code>http://google.com</code> with &#13;
<span class="keep-together"><code>handleResp_StillWrong</code>.</span> For the version that cleans all resources in &#13;
<span class="keep-together"><code>handleResp_Better</code>,</span> it takes only 188 ms, which is 29% faster!<sup><a data-type="noteref" href="ch11.html#idm45606816330528" id="idm45606816330528-marker">11</a></sup></p>&#13;
&#13;
<p>The need for exhaust is also visible in <code>http.HandlerFunc</code> code. We should always ensure our server implementation exhausts and closes the <code>http.Request</code> body. Otherwise, we will have the same problem as in <a data-type="xref" href="#code-exhaust">Example 11-10</a>. Similarly, this can be true for all sorts of iterators; for example, a <a href="https://oreil.ly/voRFc">Prometheus storage can have a &#13;
<span class="keep-together"><code>ChunkSeriesSet</code></span> iterator</a>. Some implementations can leak or overuse resources if we forget to iterate through all items until <code>Next()</code> equals false.</p>&#13;
&#13;
<p>To sum up, always check the implementation for those nontrivial edge cases. Ideally, we should design our implementations to have obvious efficiency guarantees<a data-startref="ix_ch11-asciidoc12" data-type="indexterm" id="idm45606816326032"/>.<a data-startref="ix_ch11-asciidoc8" data-type="indexterm" id="idm45606816325296"/><a data-startref="ix_ch11-asciidoc7" data-type="indexterm" id="idm45606816324688"/></p>&#13;
&#13;
<p>Let’s now dive into the pre-allocation technique I mentioned in previous chapters.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Pre-Allocate If You Can" data-type="sect1"><div class="sect1" id="ch-basic-prealloc">&#13;
<h1>Pre-Allocate If You Can</h1>&#13;
&#13;
<p><a data-primary="optimization patterns" data-secondary="pre-allocation" data-type="indexterm" id="ix_ch11-asciidoc13"/><a data-primary="pre-allocation" data-type="indexterm" id="ix_ch11-asciidoc14"/>I mentioned pre-allocation in <a data-type="xref" href="ch01.html#ch-eff-s-readable">“Optimized Code Is Not Readable”</a> as a reasonable optimization. I showed how easy it is to pre-allocate a slice with <code>make</code> in <a data-type="xref" href="ch01.html#code-prea2">Example 1-4</a> as an optimization to <code>append</code>. Generally, we want to reduce the amount of work that code has to do to resize or allocate new items if we know the code has to do it eventually.</p>&#13;
&#13;
<p>The <code>append</code> example is important, but there are more examples. It turns out that almost every container implementation that cares about efficiency has some easier pre-allocation methods. See the ones in <a data-type="xref" href="#code-prea3">Example 11-11</a> with explanations.</p>&#13;
<div data-type="example" id="code-prea3">&#13;
<h5><span class="label">Example 11-11. </span>Examples of pre-allocation for some common types</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">const</code><code class="w"> </code><code class="nx">size</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="mf">1e6</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO11-1" id="co_optimization_patterns_CO11-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
&#13;
</code><code class="nx">slice</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="kt">string</code><code class="p">,</code><code class="w"> </code><code class="mi">0</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO11-2" id="co_optimization_patterns_CO11-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
</code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">size</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">slice</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nb">append</code><code class="p">(</code><code class="nx">slice</code><code class="p">,</code><code class="w"> </code><code class="s">"something"</code><code class="p">)</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="nx">slice2</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="kt">string</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO11-3" id="co_optimization_patterns_CO11-3"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
</code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">size</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">slice2</code><code class="p">[</code><code class="nx">i</code><code class="p">]</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="s">"something"</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="nx">m</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="kd">map</code><code class="p">[</code><code class="kt">int</code><code class="p">]</code><code class="kt">string</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO11-4" id="co_optimization_patterns_CO11-4"><img alt="4" src="assets/4.png"/></a><code class="w">&#13;
</code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">size</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">m</code><code class="p">[</code><code class="nx">i</code><code class="p">]</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="s">"something"</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="nx">buf</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">bytes</code><code class="p">.</code><code class="nx">Buffer</code><code class="p">{</code><code class="p">}</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO11-5" id="co_optimization_patterns_CO11-5"><img alt="5" src="assets/5.png"/></a><code class="w">&#13;
</code><code class="nx">buf</code><code class="p">.</code><code class="nx">Grow</code><code class="p">(</code><code class="nx">size</code><code class="p">)</code><code class="w">&#13;
</code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">size</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">_</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">buf</code><code class="p">.</code><code class="nx">WriteByte</code><code class="p">(</code><code class="sc">'a'</code><code class="p">)</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="nx">builder</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">strings</code><code class="p">.</code><code class="nx">Builder</code><code class="p">{</code><code class="p">}</code><code class="w">&#13;
</code><code class="nx">builder</code><code class="p">.</code><code class="nx">Grow</code><code class="p">(</code><code class="nx">size</code><code class="p">)</code><code class="w">&#13;
</code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">size</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">builder</code><code class="p">.</code><code class="nx">WriteByte</code><code class="p">(</code><code class="sc">'a'</code><code class="p">)</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO11-1" id="callout_optimization_patterns_CO11-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Let’s assume we know the size we want to grow the containers up front.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO11-2" id="callout_optimization_patterns_CO11-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p><code>make</code> with slices allows us to grow the capacity of the underlying arrays to the given size. Thanks to the proactive growth of the array with <code>make</code>, the loop with <code>append</code> is much cheaper in CPU time and memory allocation. This is because <code>append</code> does not need to resize the array when it’s too small.</p>&#13;
&#13;
<p>Resizing is quite naive. It simply creates a new, bigger array and copies all elements. A certain heuristic also tells how many new slices are grown. This heuristic was recently <a href="https://oreil.ly/6uIHH">changed</a>, but it will still allocate and copy a few times until it extends to our expected one million elements. In our case, the same logic is 8 times faster with pre-allocation and allocates 16 MB instead of 88 MB of &#13;
<span class="keep-together">memory.</span></p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO11-3" id="callout_optimization_patterns_CO11-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>We can also pre-allocate the slice’s capacity and length. Both <code>slice</code> and <code>slice2</code> will have the same elements. Both ways are almost equally efficient, so we use one that fits more functionally to what we need to do. However, with <code>slice2</code>, we are using all array elements, whereas in <code>slice</code>, we can grow it to be bigger but end up using a smaller number if needed.<sup><a data-type="noteref" href="ch11.html#idm45606816088384" id="idm45606816088384-marker">12</a></sup></p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO11-4" id="callout_optimization_patterns_CO11-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Map can be created using <code>make</code> with an optional number representing its capacity. If we know the size up front, it’s more efficient for Go to create the required internal data structure with up-front sizes. The efficiency results show the difference—on my machine, with pre-allocation, such map initialization takes 87 ms, without 179 ms! The total allocated space with pre-allocation is 57 MB, without 123 MB. However, map insertion can still allocate some memory, just much smaller than pre-allocation.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO11-5" id="callout_optimization_patterns_CO11-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Various buffers and builders offer the <code>Grow</code> function that also pre-allocates.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>The preceding example is actually something I use very often during almost every coding session. Pre-allocation usually takes the extra line of code, but it is a fantastic, more readable pattern. If you are still not convinced that you won’t have a lot of situations when you know the size up front for the slice, let’s talk about <code>io.ReadAll</code>. We use <a href="https://oreil.ly/TN7bt"><code>io.ReadAll</code></a> (previously <a href="https://oreil.ly/nt1oT"><code>ioutil.ReadAll</code></a>) functions in the Go community a lot. Did you know you can optimize it significantly by pre-allocating the internal byte slice if you know the size up front? Unfortunately, <code>io.ReadAll</code> does not have a <code>size</code> or <code>capacity</code> argument, but there is a simple way to optimize it, as presented in <a data-type="xref" href="#code-prea4">Example 11-12</a>.</p>&#13;
<div data-type="example" id="code-prea4">&#13;
<h5><span class="label">Example 11-12. </span>Examples of ReadAll optimizations with the benchmark</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">ReadAll1</code><code class="p">(</code><code class="nx">r</code><code class="w"> </code><code class="nx">io</code><code class="p">.</code><code class="nx">Reader</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="w"> </code><code class="kt">int</code><code class="p">)</code><code class="w"> </code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">,</code><code class="w"> </code><code class="kt">error</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">   </code><code class="nx">buf</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">bytes</code><code class="p">.</code><code class="nx">Buffer</code><code class="p">{</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">   </code><code class="nx">buf</code><code class="p">.</code><code class="nx">Grow</code><code class="p">(</code><code class="nx">size</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">   </code><code class="nx">n</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">io</code><code class="p">.</code><code class="nx">Copy</code><code class="p">(</code><code class="o">&amp;</code><code class="nx">buf</code><code class="p">,</code><code class="w"> </code><code class="nx">r</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO12-1" id="co_optimization_patterns_CO12-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
   </code><code class="k">return</code><code class="w"> </code><code class="nx">buf</code><code class="p">.</code><code class="nx">Bytes</code><code class="p">(</code><code class="p">)</code><code class="p">[</code><code class="p">:</code><code class="nx">n</code><code class="p">]</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">ReadAll2</code><code class="p">(</code><code class="nx">r</code><code class="w"> </code><code class="nx">io</code><code class="p">.</code><code class="nx">Reader</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="w"> </code><code class="kt">int</code><code class="p">)</code><code class="w"> </code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">,</code><code class="w"> </code><code class="kt">error</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">   </code><code class="nx">buf</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">   </code><code class="nx">n</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">io</code><code class="p">.</code><code class="nx">ReadFull</code><code class="p">(</code><code class="nx">r</code><code class="p">,</code><code class="w"> </code><code class="nx">buf</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO12-2" id="co_optimization_patterns_CO12-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
   </code><code class="k">if</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">==</code><code class="w"> </code><code class="nx">io</code><code class="p">.</code><code class="nx">EOF</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">      </code><code class="nx">err</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="kc">nil</code><code class="w">&#13;
</code><code class="w">   </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">   </code><code class="k">return</code><code class="w"> </code><code class="nx">buf</code><code class="p">[</code><code class="p">:</code><code class="nx">n</code><code class="p">]</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">BenchmarkReadAlls</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">   </code><code class="kd">const</code><code class="w"> </code><code class="nx">size</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nb">int</code><code class="p">(</code><code class="mf">1e6</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">   </code><code class="nx">inner</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">   </code><code class="nx">b</code><code class="p">.</code><code class="nx">Run</code><code class="p">(</code><code class="s">"io.ReadAll"</code><code class="p">,</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">      </code><code class="nx">b</code><code class="p">.</code><code class="nx">ReportAllocs</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">      </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">         </code><code class="nx">buf</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">io</code><code class="p">.</code><code class="nx">ReadAll</code><code class="p">(</code><code class="nx">bytes</code><code class="p">.</code><code class="nx">NewReader</code><code class="p">(</code><code class="nx">inner</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">         </code><code class="nx">testutil</code><code class="p">.</code><code class="nx">Ok</code><code class="p">(</code><code class="nx">b</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">         </code><code class="nx">testutil</code><code class="p">.</code><code class="nx">Equals</code><code class="p">(</code><code class="nx">b</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="p">,</code><code class="w"> </code><code class="nb">len</code><code class="p">(</code><code class="nx">buf</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">      </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">   </code><code class="p">}</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">   </code><code class="nx">b</code><code class="p">.</code><code class="nx">Run</code><code class="p">(</code><code class="s">"ReadAll1"</code><code class="p">,</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">      </code><code class="nx">b</code><code class="p">.</code><code class="nx">ReportAllocs</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">      </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">         </code><code class="nx">buf</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">ReadAll1</code><code class="p">(</code><code class="nx">bytes</code><code class="p">.</code><code class="nx">NewReader</code><code class="p">(</code><code class="nx">inner</code><code class="p">)</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">         </code><code class="nx">testutil</code><code class="p">.</code><code class="nx">Ok</code><code class="p">(</code><code class="nx">b</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">         </code><code class="nx">testutil</code><code class="p">.</code><code class="nx">Equals</code><code class="p">(</code><code class="nx">b</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="p">,</code><code class="w"> </code><code class="nb">len</code><code class="p">(</code><code class="nx">buf</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">      </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">   </code><code class="p">}</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">   </code><code class="nx">b</code><code class="p">.</code><code class="nx">Run</code><code class="p">(</code><code class="s">"ReadAll2"</code><code class="p">,</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">      </code><code class="nx">b</code><code class="p">.</code><code class="nx">ReportAllocs</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">      </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">         </code><code class="nx">buf</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">ReadAll2</code><code class="p">(</code><code class="nx">bytes</code><code class="p">.</code><code class="nx">NewReader</code><code class="p">(</code><code class="nx">inner</code><code class="p">)</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">         </code><code class="nx">testutil</code><code class="p">.</code><code class="nx">Ok</code><code class="p">(</code><code class="nx">b</code><code class="p">,</code><code class="w"> </code><code class="nx">err</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">         </code><code class="nx">testutil</code><code class="p">.</code><code class="nx">Equals</code><code class="p">(</code><code class="nx">b</code><code class="p">,</code><code class="w"> </code><code class="nx">size</code><code class="p">,</code><code class="w"> </code><code class="nb">len</code><code class="p">(</code><code class="nx">buf</code><code class="p">)</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">      </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">   </code><code class="p">}</code><code class="p">)</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO12-1" id="callout_optimization_patterns_CO12-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>One way of simulating <code>ReadAll</code> is by creating a pre-allocated buffer and using <code>io.Copy</code> to copy all bytes.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO12-2" id="callout_optimization_patterns_CO12-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Even more efficient is pre-allocating a byte slice and using <code>ReadFull</code>, which is similar. <code>ReadAll</code> does not use the <code>io.EOF</code> error sentinel if everything is read, so we need special handling for it.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>The results, presented in <a data-type="xref" href="#code-prea4-res">Example 11-13</a>, speak for themselves. The <code>ReadAll2</code> using <code>io.ReadFull</code> is over eight times faster and allocates five times less memory for our one million byte slice.</p>&#13;
<div data-type="example" id="code-prea4-res">&#13;
<h5><span class="label">Example 11-13. </span>Results of the benchmark in <a data-type="xref" href="#code-prea4">Example 11-12</a></h5>&#13;
&#13;
<pre data-code-language="text" data-type="programlisting">BenchmarkReadAlls&#13;
BenchmarkReadAlls/io.ReadAll&#13;
BenchmarkReadAlls/io.ReadAll-12  1210   872388 ns/op  5241169 B/op  29 allocs/op&#13;
BenchmarkReadAlls/ReadAll1&#13;
BenchmarkReadAlls/ReadAll1-12    8486   165519 ns/op  1007723 B/op  4 allocs/op&#13;
BenchmarkReadAlls/ReadAll2&#13;
BenchmarkReadAlls/ReadAll2-12    10000  102414 ns/op  1007676 B/op  3 allocs/op&#13;
PASS</pre></div>&#13;
&#13;
<p>The <code>io.ReadAll</code> optimization is very often possible in our Go code. Especially when dealing with HTTP code, the request or response headers often offer a <code>Content-Length</code> header that allows pre-allocations.<sup><a data-type="noteref" href="ch11.html#idm45606815217568" id="idm45606815217568-marker">13</a></sup> The preceding examples represent only a small subset of types and abstractions that allow pre-allocation. Check the documentation and code of the type we use if we can average eager allocations for better &#13;
<span class="keep-together">efficiency.</span></p>&#13;
&#13;
<p>However, there is one more amazing pre-allocation pattern I would like you to know. Consider a simple, singly linked list. If we implement it using pointers, and if we know we will insert millions of new elements on that list, is there a way to pre-allocate things for efficiency? Turns out there might be, as shown in <a data-type="xref" href="#code-prea5">Example 11-14</a>.</p>&#13;
<div data-type="example" id="code-prea5">&#13;
<h5><span class="label">Example 11-14. </span>Basic pre-allocation of linked list elements</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">type</code><code class="w"> </code><code class="nx">Node</code><code class="w"> </code><code class="kd">struct</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">next</code><code class="w"> </code><code class="o">*</code><code class="nx">Node</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">value</code><code class="w"> </code><code class="kt">int</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">type</code><code class="w"> </code><code class="nx">SinglyLinkedList</code><code class="w"> </code><code class="kd">struct</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">head</code><code class="w"> </code><code class="o">*</code><code class="nx">Node</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">pool</code><code class="w">      </code><code class="p">[</code><code class="p">]</code><code class="nx">Node</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO13-1" id="co_optimization_patterns_CO13-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
    </code><code class="nx">poolIndex</code><code class="w"> </code><code class="kt">int</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="p">(</code><code class="nx">l</code><code class="w"> </code><code class="o">*</code><code class="nx">SinglyLinkedList</code><code class="p">)</code><code class="w"> </code><code class="nx">Grow</code><code class="p">(</code><code class="nx">len</code><code class="w"> </code><code class="kt">int</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO13-2" id="co_optimization_patterns_CO13-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
    </code><code class="nx">l</code><code class="p">.</code><code class="nx">pool</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="nx">Node</code><code class="p">,</code><code class="w"> </code><code class="nx">len</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">l</code><code class="p">.</code><code class="nx">poolIndex</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="mi">0</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="p">(</code><code class="nx">l</code><code class="w"> </code><code class="o">*</code><code class="nx">SinglyLinkedList</code><code class="p">)</code><code class="w"> </code><code class="nx">Insert</code><code class="p">(</code><code class="nx">value</code><code class="w"> </code><code class="kt">int</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="kd">var</code><code class="w"> </code><code class="nx">newNode</code><code class="w"> </code><code class="o">*</code><code class="nx">Node</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">if</code><code class="w"> </code><code class="nb">len</code><code class="p">(</code><code class="nx">l</code><code class="p">.</code><code class="nx">pool</code><code class="p">)</code><code class="w"> </code><code class="p">&gt;</code><code class="w"> </code><code class="nx">l</code><code class="p">.</code><code class="nx">poolIndex</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO13-3" id="co_optimization_patterns_CO13-3"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
        </code><code class="nx">newNode</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="o">&amp;</code><code class="nx">l</code><code class="p">.</code><code class="nx">pool</code><code class="p">[</code><code class="nx">l</code><code class="p">.</code><code class="nx">poolIndex</code><code class="p">]</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">l</code><code class="p">.</code><code class="nx">poolIndex</code><code class="o">++</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w"> </code><code class="k">else</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">newNode</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="o">&amp;</code><code class="nx">Node</code><code class="p">{</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">newNode</code><code class="p">.</code><code class="nx">next</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">l</code><code class="p">.</code><code class="nx">head</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">newNode</code><code class="p">.</code><code class="nx">value</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">value</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">l</code><code class="p">.</code><code class="nx">head</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">newNode</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO13-1" id="callout_optimization_patterns_CO13-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>This line makes this linked list a bit special. We maintain a pool of objects in the form of one slice.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO13-2" id="callout_optimization_patterns_CO13-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Thanks to the pool, we can implement our own <code>Grow</code> method, which will allocate a pool of many <code>Node</code> objects within one allocation. Generally, it’s way faster to allocate one large <code>[]Node</code> than millions of <code>*Node</code>.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO13-3" id="callout_optimization_patterns_CO13-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>During the insert, we can check if we have room in our pool and take one element from it instead of allocating an individual <code>Node</code>. This implementation can be expanded to be more robust, e.g., for subsequent growth, if we hit the capacity limit.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>If we benchmarked the insertion of one million elements using the preceding linked list, we would see that the insertion takes four times less time with one eager allocation and the same space with just one allocation instead of one million.</p>&#13;
&#13;
<p>The simple pre-allocation with slices and maps presented in <a data-type="xref" href="#code-prea3">Example 11-11</a> have almost no downsides, so they can be treated as reasonable optimizations. The pre-allocation presented in <a data-type="xref" href="#code-prea5">Example 11-14</a>, on the other hand, should be done with care, deliberately, and with benchmarks as it’s not without trade-offs.</p>&#13;
&#13;
<p>First, the problem is that potential deletion logic or allowing the <code>Grow</code> call multiple times is not trivial to implement. The second issue is that a single <code>Node</code> element is now connected to a very large single memory block. Let’s dive into this problem in the next section.<a data-startref="ix_ch11-asciidoc14" data-type="indexterm" id="idm45606815566752"/><a data-startref="ix_ch11-asciidoc13" data-type="indexterm" id="idm45606815383696"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Overusing Memory with Arrays" data-type="sect1"><div class="sect1" id="ch-basic-subslice">&#13;
<h1>Overusing Memory with Arrays</h1>&#13;
&#13;
<p><a data-primary="arrays" data-secondary="overusing memory with" data-type="indexterm" id="ix_ch11-asciidoc15"/><a data-primary="memory leak" data-type="indexterm" id="ix_ch11-asciidoc16"/><a data-primary="memory resource" data-secondary="overusing with arrays" data-type="indexterm" id="ix_ch11-asciidoc17"/><a data-primary="optimization patterns" data-secondary="overusing memory with arrays" data-type="indexterm" id="ix_ch11-asciidoc18"/>As you probably know, slices are very powerful in Go. They offer <a href="https://oreil.ly/YhOdH">robust flexibility for using arrays</a> that is used daily in the Go community. But with power and flexibility comes responsibility. There are many cases where we might end up overusing memory, which some might call a “memory leak.” The main problem is that those cases will never appear in <a data-type="xref" href="ch08.html#ch-obs-micro-go">“Go Benchmarks”</a>, because it’s related to garbage collection and will not release memory we thought could be released. Let’s explore this problem in <a data-type="xref" href="#code-overuse-mem">Example 11-15</a>, which tests potential deletion in <code>SinglyLinkedList</code> introduced in <a data-type="xref" href="#code-prea5">Example 11-14</a>.</p>&#13;
<div data-type="example" id="code-overuse-mem">&#13;
<h5><span class="label">Example 11-15. </span>Reproducing memory overuse for a linked list that used pre-allocation in <a data-type="xref" href="#code-prea5">Example 11-14</a></h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="p">(</code><code class="nx">l</code><code class="w"> </code><code class="o">*</code><code class="nx">SinglyLinkedList</code><code class="p">)</code><code class="w"> </code><code class="nx">Delete</code><code class="p">(</code><code class="nx">n</code><code class="w"> </code><code class="o">*</code><code class="nx">Node</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><code class="cm">/* ... */</code><code class="w"> </code><code class="p">}</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO14-1" id="co_optimization_patterns_CO14-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">TestSinglyLinkedList_Delete</code><code class="p">(</code><code class="nx">t</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">T</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO14-2" id="co_optimization_patterns_CO14-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
    </code><code class="nx">l</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="o">&amp;</code><code class="nx">SinglyLinkedList</code><code class="p">{</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">l</code><code class="p">.</code><code class="nx">Grow</code><code class="p">(</code><code class="nx">size</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">k</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">k</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">size</code><code class="p">;</code><code class="w"> </code><code class="nx">k</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">l</code><code class="p">.</code><code class="nx">Insert</code><code class="p">(</code><code class="nx">k</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">l</code><code class="p">.</code><code class="nx">pool</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="kc">nil</code><code class="w"> </code><code class="c1">// Dispose pool. </code><a class="co" href="#callout_optimization_patterns_CO14-3" id="co_optimization_patterns_CO14-3"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
</code><code class="w">    </code><code class="nx">_printHeapUsage</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO14-4" id="co_optimization_patterns_CO14-4"><img alt="4" src="assets/4.png"/></a><code class="w">&#13;
&#13;
    </code><code class="c1">// Remove all but last.</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">curr</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">l</code><code class="p">.</code><code class="nx">head</code><code class="p">;</code><code class="w"> </code><code class="nx">curr</code><code class="p">.</code><code class="nx">next</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="kc">nil</code><code class="p">;</code><code class="w"> </code><code class="nx">curr</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">curr</code><code class="p">.</code><code class="nx">next</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO14-5" id="co_optimization_patterns_CO14-5"><img alt="5" src="assets/5.png"/></a><code class="w">&#13;
        </code><code class="nx">l</code><code class="p">.</code><code class="nx">Delete</code><code class="p">(</code><code class="nx">curr</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">_printHeapUsage</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO14-6" id="co_optimization_patterns_CO14-6"><img alt="6" src="assets/6.png"/></a><code class="w">&#13;
&#13;
    </code><code class="nx">l</code><code class="p">.</code><code class="nx">Delete</code><code class="p">(</code><code class="nx">l</code><code class="p">.</code><code class="nx">head</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">_printHeapUsage</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO14-7" id="co_optimization_patterns_CO14-7"><img alt="7" src="assets/7.png"/></a><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">_printHeapUsage</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">m</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">runtime</code><code class="p">.</code><code class="nx">MemStats</code><code class="p">{</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">runtime</code><code class="p">.</code><code class="nx">GC</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">runtime</code><code class="p">.</code><code class="nx">ReadMemStats</code><code class="p">(</code><code class="o">&amp;</code><code class="nx">m</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">fmt</code><code class="p">.</code><code class="nx">Println</code><code class="p">(</code><code class="nb">float64</code><code class="p">(</code><code class="nx">m</code><code class="p">.</code><code class="nx">HeapAlloc</code><code class="p">)</code><code class="o">/</code><code class="mf">1024.0</code><code class="p">,</code><code class="w"> </code><code class="s">"KB"</code><code class="p">)</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO14-1" id="callout_optimization_patterns_CO14-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Let’s add deletion logic to the linked list, which removes the given element.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO14-2" id="callout_optimization_patterns_CO14-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Using a microbenchmark to assess the efficiency of <code>Delete</code> would show us that when <code>Grow</code> was used, the deletion was only marginally faster. However, to showcase the memory overuse problem, we would need the macrobenchmarks test (see <a data-type="xref" href="ch08.html#ch-obs-macro">“Macrobenchmarks”</a>). Alternatively, we can write a brittle interactive test as we did here.<sup><a data-type="noteref" href="ch11.html#idm45606814784544" id="idm45606814784544-marker">14</a></sup></p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO14-3" id="callout_optimization_patterns_CO14-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Notice we are trying our best for the GC to remove the deleted node. However, we <code>nil</code> the <code>pool</code> variable, so the slice we used to create all nodes in the list is not referenced anywhere.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO14-4" id="callout_optimization_patterns_CO14-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>We use a manual trigger for the GC and print of the heap, which is not very reliable generally as it contains allocations from background runtime work. However, it’s good enough here to show us the problem. The pre-allocated list showed 15,818.5 KB in one of the runs, and 15,813.0 KB for the run without <code>Grow</code>. Don’t look at the difference between those, but how this value changed for pre-allocated.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO14-5" id="callout_optimization_patterns_CO14-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Let’s remove all but one element.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO14-6" id="callout_optimization_patterns_CO14-6"><img alt="6" src="assets/6.png"/></a></dt>&#13;
<dd><p>In a perfect world, we would expect to hold only memory for one <code>Node</code>, right? This is the case for the non-pre-allocated list—189.85 KB on the heap. On the other hand, for the pre-allocated list, we can observe a certain problem: the heap is still big, with 15,831.2 KB on it!</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO14-7" id="callout_optimization_patterns_CO14-7"><img alt="7" src="assets/7.png"/></a></dt>&#13;
<dd><p>Only after all the elements do we see a small heap size for both cases (around 190 KB for both).</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>This problem is important to understand, and we have it every time we work with structs with arrays. The representation of what happens when all but one element is deleted in both cases is shown in <a data-type="xref" href="#img-opt-overuse-mem">Figure 11-1</a>.</p>&#13;
&#13;
<figure><div class="figure" id="img-opt-overuse-mem">&#13;
<img alt="efgo 1101" src="assets/efgo_1101.png"/>&#13;
<h6><span class="label">Figure 11-1. </span>The heap’s state with references with one node in the list. On the left, created without a pool, on the right with it.</h6>&#13;
</div></figure>&#13;
&#13;
<p>When we allocate an individual object, we see that it receives its own memory block that can be managed in isolation. If we use pooling or subslicing (e.g., <code>buf[1:2]</code>) from a bigger slice, the GC will see that the big memory block for continuous memory used by the array is referenced. It’s not smart enough to see that only 1% of it is used and could be “clipped.”</p>&#13;
&#13;
<p>The solution is to avoid pooling or come up with a more advanced pool that can be grown or shrunk (maybe even automatically). For example, if half of the objects are deleted, we can “clip” the array behind our linked list nodes. Alternatively, we can add the on-demand <code>ClipMemory</code> method, as presented in <a data-type="xref" href="#code-overuse-mem2">Example 11-16</a>.</p>&#13;
<div data-type="example" id="code-overuse-mem2">&#13;
<h5><span class="label">Example 11-16. </span>Example implementation of clipping too-big memory block</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="p">(</code><code class="nx">l</code><code class="w"> </code><code class="o">*</code><code class="nx">SinglyLinkedList</code><code class="p">)</code><code class="w"> </code><code class="nx">ClipMemory</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="kd">var</code><code class="w"> </code><code class="nx">objs</code><code class="w"> </code><code class="kt">int</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">curr</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">l</code><code class="p">.</code><code class="nx">head</code><code class="p">;</code><code class="w"> </code><code class="nx">curr</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="kc">nil</code><code class="p">;</code><code class="w"> </code><code class="nx">curr</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">curr</code><code class="p">.</code><code class="nx">next</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">objs</code><code class="o">++</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">l</code><code class="p">.</code><code class="nx">pool</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="nx">Node</code><code class="p">,</code><code class="w"> </code><code class="nx">objs</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO15-1" id="co_optimization_patterns_CO15-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
    </code><code class="nx">l</code><code class="p">.</code><code class="nx">poolIndex</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="mi">0</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">curr</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">l</code><code class="p">.</code><code class="nx">head</code><code class="p">;</code><code class="w"> </code><code class="nx">curr</code><code class="w"> </code><code class="o">!=</code><code class="w"> </code><code class="kc">nil</code><code class="p">;</code><code class="w"> </code><code class="nx">curr</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">curr</code><code class="p">.</code><code class="nx">next</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">oldCurr</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">curr</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">curr</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="o">&amp;</code><code class="nx">l</code><code class="p">.</code><code class="nx">pool</code><code class="p">[</code><code class="nx">l</code><code class="p">.</code><code class="nx">poolIndex</code><code class="p">]</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">l</code><code class="p">.</code><code class="nx">poolIndex</code><code class="o">++</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">curr</code><code class="p">.</code><code class="nx">next</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">oldCurr</code><code class="p">.</code><code class="nx">next</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO15-2" id="co_optimization_patterns_CO15-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
        </code><code class="nx">curr</code><code class="p">.</code><code class="nx">value</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">oldCurr</code><code class="p">.</code><code class="nx">value</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">if</code><code class="w"> </code><code class="nx">oldCurr</code><code class="w"> </code><code class="o">==</code><code class="w"> </code><code class="nx">l</code><code class="p">.</code><code class="nx">head</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="nx">l</code><code class="p">.</code><code class="nx">head</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">curr</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO15-3" id="co_optimization_patterns_CO15-3"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
        </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO15-1" id="callout_optimization_patterns_CO15-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>At this moment, we get rid of the reference to the old <code>[]Node</code> slice and create a smaller one.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO15-2" id="callout_optimization_patterns_CO15-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>As we saw in <a data-type="xref" href="#img-opt-overuse-mem">Figure 11-1</a>, there are still other references to bigger memory blocks from each element in the list. So we need to perform a copy using a new pool of objects to ensure the GC can remove that old bigger pool.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO15-3" id="callout_optimization_patterns_CO15-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Let’s not forget about the last pointer, <code>l.head</code>, which would otherwise still point to the old memory block.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>We can now use the <code>ClipMemory</code> when we delete some items to resize the underlying memory block.</p>&#13;
&#13;
<p class="less_space pagebreak-before">As presented in <a data-type="xref" href="#code-overuse-mem">Example 11-15</a>, the overuse of memory is more common than we might think. However, we don’t need such specific pooling to experience it. Subslicing and using clever zero copy functions like in <a data-type="xref" href="ch10.html#code-sum3">Example 10-4</a> (<code>zeroCopyToString</code>) are very much prone to this problem.<sup><a data-type="noteref" href="ch11.html#idm45606814531920" id="idm45606814531920-marker">15</a></sup></p>&#13;
<div data-type="tip">&#13;
<p>This section is not to demotivate you from pre-allocating things, subslicing, or experimenting with reusing byte slices. Rather it’s a reminder to always keep in mind how Go manages memory (as discussed in <a data-type="xref" href="ch05.html#ch-hw-go-mem">“Go Memory Management”</a>) when we attempt to do more advanced things with slices and underlying arrays.</p>&#13;
&#13;
<p>Remember that Go benchmarking does not cover memory usage characteristics, as mentioned in <a data-type="xref" href="ch08.html#ch-obs-micro-mem">“Microbenchmarks Versus Memory Management”</a>. Move to the <a data-type="xref" href="ch08.html#ch-obs-macro">“Macrobenchmarks”</a> level to verify all efficiency aspects if you suspect you are affected by this problem.</p>&#13;
</div>&#13;
&#13;
<p>Since we mentioned pooling, let’s dive into the last section. What are the other ways to reuse and pool memory in Go? It turns out that sometimes not pooling anything might be better!<a data-startref="ix_ch11-asciidoc18" data-type="indexterm" id="idm45606814439712"/><a data-startref="ix_ch11-asciidoc17" data-type="indexterm" id="idm45606814439104"/><a data-startref="ix_ch11-asciidoc16" data-type="indexterm" id="idm45606814438496"/><a data-startref="ix_ch11-asciidoc15" data-type="indexterm" id="idm45606814437888"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Memory Reuse and Pooling" data-type="sect1"><div class="sect1" id="ch-basic-pool">&#13;
<h1>Memory Reuse and Pooling</h1>&#13;
&#13;
<p><a data-primary="optimization patterns" data-secondary="memory reuse/pooling" data-type="indexterm" id="ix_ch11-asciidoc19"/>Memory <a data-primary="memory reuse" data-type="indexterm" id="ix_ch11-asciidoc20"/>reuse allows using the same memory blocks for subsequent operations. If the operation we perform requires a bigger <code>struct</code> or <code>slice</code> and we perform a lot of them in a quick sequence, it’s wasteful to allocate a new memory block every time because:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Allocation of memory with guaranteed zero-ing of the memory block takes CPU time.</p>&#13;
</li>&#13;
<li>&#13;
<p>We put more work into the GC, so more CPU cycles are used.</p>&#13;
</li>&#13;
<li>&#13;
<p>The GC is eventual, so our maximum heap size can grow uncontrollably.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>I already presented some memory reuse techniques in <a data-type="xref" href="ch10.html#code-sum6">Example 10-8</a>, using a small buffer to process files chunk by chunk. Then, in <a data-type="xref" href="#code-prea5">Example 11-14</a>, I showed how we could allocate one bigger memory block at once and use that as our pool of objects.</p>&#13;
&#13;
<p>The logic of reusing objects, especially byte slices, is often enabled by many popular implementations, such as <code>io.CopyBuffer</code> or <code>io.ReadFull</code>. Even our <code>Sum6Reader​(r ⁠io.Reader, buf []byte)</code> from <a data-type="xref" href="ch10.html#code-sum6">Example 10-8</a> allows further reuse of the buffer. However, memory reuse is not always so easy. Consider the following example of byte slice reuse in <a data-type="xref" href="#code-reuse1">Example 11-17</a>.</p>&#13;
<div data-type="example" id="code-reuse1">&#13;
<h5><span class="label">Example 11-17. </span>Simple buffering or byte slice</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">processUsingBuffer</code><code class="p">(</code><code class="nx">buf</code><code class="w"> </code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">buf</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">buf</code><code class="p">[</code><code class="p">:</code><code class="mi">0</code><code class="p">]</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO16-1" id="co_optimization_patterns_CO16-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
&#13;
    </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="mf">1e6</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">buf</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nb">append</code><code class="p">(</code><code class="nx">buf</code><code class="p">,</code><code class="w"> </code><code class="sc">'a'</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="c1">// Use buffer...</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">BenchmarkProcess</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">b</code><code class="p">.</code><code class="nx">Run</code><code class="p">(</code><code class="s">"alloc"</code><code class="p">,</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="nx">processUsingBuffer</code><code class="p">(</code><code class="kc">nil</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO16-2" id="co_optimization_patterns_CO16-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
        </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">b</code><code class="p">.</code><code class="nx">Run</code><code class="p">(</code><code class="s">"buffer"</code><code class="p">,</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">buf</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">,</code><code class="w"> </code><code class="mf">1e6</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">b</code><code class="p">.</code><code class="nx">ResetTimer</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="nx">processUsingBuffer</code><code class="p">(</code><code class="nx">buf</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO16-3" id="co_optimization_patterns_CO16-3"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
        </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="p">)</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO16-1" id="callout_optimization_patterns_CO16-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Because our logic uses <code>append</code>, we need to zero the length of the slice while reusing the same underlying array for efficiency.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO16-2" id="callout_optimization_patterns_CO16-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>We can simulate no buffer by simply passing <code>nil</code>. Fortunately, Go handles nil slices in the operations like <code>buf[:0]</code> or <code>append([]byte(nil), 'a')</code>.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO16-3" id="callout_optimization_patterns_CO16-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Reusing the buffer is better in this case. On my machine, benchmarks show that each operation with reused buffer is almost two times faster and allocates zero bytes.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>The preceding example looks excellent, but the real code contains complications and edge cases. Two main problems sometimes block us from implementing such naive memory reuse, as in <a data-type="xref" href="#code-reuse1">Example 11-17</a>:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>We know the buffer size will be similar for most operations, but we don’t know the exact number. This can be easily fixed by passing an empty buffer and reusing the grown underlying array from the first operation.</p>&#13;
</li>&#13;
<li>&#13;
<p>We might run the <code>processUsingBuffer</code> code concurrently at some point. Sometimes with four workers, sometimes with one thousand, sometimes with one. In this case, we could implement this by maintaining a static number of buffers. The number could be the maximum goroutines we want to run concurrently or less with some locking. This obviously can have a lot of waste if the number of goroutines is dynamically changing and is sometimes zero.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><a data-primary="memory pooling" data-type="indexterm" id="ix_ch11-asciidoc21"/><a data-primary="sync.Pool structure" data-type="indexterm" id="idm45606814142560"/>For those reasons, the Go team came up with the <a href="https://oreil.ly/BAQwU"><code>sync.Pool</code></a> structure that performs a particular form of memory pooling. It’s important to understand that memory pooling is not the same as typical caching<a data-primary="Honnef, Dominik, on sync.Pool" data-type="indexterm" id="idm45606814140912"/>.</p>&#13;
<blockquote><p>The type that Brad Fitzpatrick requested [<code>sync.Pool</code>] is actually a pool: A set of interchangeable values where it doesn’t matter which concrete value you get out, because they’re all identical. You wouldn’t even notice when, instead of getting a value from the pool, you get a newly created one. Caches, on the other hand, map keys to concrete values.</p>&#13;
&#13;
<p data-type="attribution">Dominik Honnef, <a href="https://oreil.ly/z6AUf">“What’s Happening in Go Tip”</a></p></blockquote>&#13;
&#13;
<p>The <code>sync.Pool</code> from the standard library is implemented purely as a very short, temporary cache for the same type of free memory blocks that last until more or less the next GC invocation. It uses quite smart logic that makes it thread-safe yet avoids locking as much as possible for efficient access. The main idea behind <code>sync.Pool</code> is to reuse memory that the GC did not yet release. Since we keep those memory blocks around until eventual GC, why not make them accessible and useful? The example of using <code>sync.Pool</code> in <a data-type="xref" href="#code-reuse1">Example 11-17</a> is presented in <a data-type="xref" href="#code-reuse2">Example 11-18</a>.</p>&#13;
<div data-type="example" id="code-reuse2">&#13;
<h5><span class="label">Example 11-18. </span>Simple buffering using <code>sync.Pool</code></h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">processUsingPool</code><code class="p">(</code><code class="nx">p</code><code class="w"> </code><code class="o">*</code><code class="nx">sync</code><code class="p">.</code><code class="nx">Pool</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">buf</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">p</code><code class="p">.</code><code class="nx">Get</code><code class="p">(</code><code class="p">)</code><code class="p">.</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO17-1" id="co_optimization_patterns_CO17-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
    </code><code class="nx">buf</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">buf</code><code class="p">[</code><code class="p">:</code><code class="mi">0</code><code class="p">]</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="mf">1e6</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">buf</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nb">append</code><code class="p">(</code><code class="nx">buf</code><code class="p">,</code><code class="w"> </code><code class="sc">'a'</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">defer</code><code class="w"> </code><code class="nx">p</code><code class="p">.</code><code class="nx">Put</code><code class="p">(</code><code class="nx">buf</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO17-2" id="co_optimization_patterns_CO17-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
&#13;
    </code><code class="c1">// Use buffer...</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">BenchmarkProcess</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">b</code><code class="p">.</code><code class="nx">ReportAllocs</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">p</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">sync</code><code class="p">.</code><code class="nx">Pool</code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">New</code><code class="p">:</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="kt">any</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><code class="k">return</code><code class="w"> </code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">{</code><code class="p">}</code><code class="w"> </code><code class="p">}</code><code class="p">,</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO17-3" id="co_optimization_patterns_CO17-3"><img alt="3" src="assets/3.png"/></a><code class="w">&#13;
    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">b</code><code class="p">.</code><code class="nx">ResetTimer</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">processUsingPool</code><code class="p">(</code><code class="o">&amp;</code><code class="nx">p</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO17-4" id="co_optimization_patterns_CO17-4"><img alt="4" src="assets/4.png"/></a><code class="w">&#13;
    </code><code class="p">}</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO17-1" id="callout_optimization_patterns_CO17-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p><code>sync.Pool</code> pools an object of the given type, so we must cast it to the type we put or create. When <code>Get</code> is involved, we either allocate a new object or use one of the pooled ones.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO17-2" id="callout_optimization_patterns_CO17-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>To use the pool effectively, we need to put back the object to reuse. Remember to never put back the object you are still using to avoid races!</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO17-3" id="callout_optimization_patterns_CO17-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>The <code>New</code> closure specifies how a new object will be created.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO17-4" id="callout_optimization_patterns_CO17-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>For our example, the implementation with <code>sync.Pool</code> is very efficient. It’s over 2 times faster than without reuse, with an average of 2 KB of space allocated versus 5 MB allocated per operation from code that does not reuse the buffer.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>While results look very promising, pooling using <code>sync.Pool</code> is a more advanced optimization that can bring more efficiency bottlenecks than optimizations if wrongly used. The first problem is that, as with any other complex structure that works with slices, using it is prone to errors. Consider the code with benchmark in <a data-type="xref" href="#code-reuse3">Example 11-19</a>.</p>&#13;
<div data-type="example" id="code-reuse3">&#13;
<h5><span class="label">Example 11-19. </span>Common, hard-to-spot bug while using <code>sync.Pool</code> and <code>defer</code></h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">processUsingPool_Wrong</code><code class="p">(</code><code class="nx">p</code><code class="w"> </code><code class="o">*</code><code class="nx">sync</code><code class="p">.</code><code class="nx">Pool</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">buf</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">p</code><code class="p">.</code><code class="nx">Get</code><code class="p">(</code><code class="p">)</code><code class="p">.</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">buf</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nx">buf</code><code class="p">[</code><code class="p">:</code><code class="mi">0</code><code class="p">]</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">defer</code><code class="w"> </code><code class="nx">p</code><code class="p">.</code><code class="nx">Put</code><code class="p">(</code><code class="nx">buf</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO18-1" id="co_optimization_patterns_CO18-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
&#13;
    </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="mf">1e6</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">buf</code><code class="w"> </code><code class="p">=</code><code class="w"> </code><code class="nb">append</code><code class="p">(</code><code class="nx">buf</code><code class="p">,</code><code class="w"> </code><code class="sc">'a'</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="c1">// Use buffer...</code><code class="w">&#13;
</code><code class="p">}</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="kd">func</code><code class="w"> </code><code class="nx">BenchmarkProcess</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">p</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">sync</code><code class="p">.</code><code class="nx">Pool</code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">New</code><code class="p">:</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="kt">any</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><code class="k">return</code><code class="w"> </code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">{</code><code class="p">}</code><code class="w"> </code><code class="p">}</code><code class="p">,</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">b</code><code class="p">.</code><code class="nx">ResetTimer</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">    </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">processUsingPool_Wrong</code><code class="p">(</code><code class="o">&amp;</code><code class="nx">p</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO18-2" id="co_optimization_patterns_CO18-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
    </code><code class="p">}</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO18-1" id="callout_optimization_patterns_CO18-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>There is a bug in this function that defies the point of using <code>sync.Pool</code>—<code>Get</code> will always allocate an object in our case. Can you spot it?</p>&#13;
&#13;
<p>The problem is that the <code>Put</code> might be deferred to the correct time, but its argument is evaluated at the moment of the <code>defer</code> schedule. As a result, the <code>buf</code> variable we are putting might point to a different slice if <code>append</code> will have to grow it.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO18-2" id="callout_optimization_patterns_CO18-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>As a result, the benchmark will show that this <code>processUsingPool_Wrong</code> operation is twice as slow as the <code>alloc</code> case in <a data-type="xref" href="#code-reuse1">Example 11-17</a> that always allocates. Using <code>sync.Pool</code> to only <code>Get</code> and never <code>Put</code> is slower than straight allocation (<code>make([]byte)</code> in our case).</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>However, the real difficulty comes from the specific <code>sync.Pool</code> characteristic: it only pools objects for a short duration, which is not reflected by our typical &#13;
<span class="keep-together">microbenchmark</span> like in <a data-type="xref" href="#code-reuse2">Example 11-18</a>. We can see the difference if we trigger GC manually in our benchmark, done for demonstration in <a data-type="xref" href="#code-reuse3-gc">Example 11-20</a>.</p>&#13;
<div data-type="example" id="code-reuse3-gc">&#13;
<h5><span class="label">Example 11-20. </span>Common, hard-to-spot bug while using <code>sync.Pool</code> and <code>defer</code>, triggering GC manually</h5>&#13;
&#13;
<pre data-code-language="go" data-type="programlisting"><code class="kd">func</code><code class="w"> </code><code class="nx">BenchmarkProcess</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">b</code><code class="p">.</code><code class="nx">Run</code><code class="p">(</code><code class="s">"buffer-GC"</code><code class="p">,</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">buf</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nb">make</code><code class="p">(</code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">,</code><code class="w"> </code><code class="mf">1e6</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">b</code><code class="p">.</code><code class="nx">ResetTimer</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">      </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="nx">processUsingBuffer</code><code class="p">(</code><code class="nx">buf</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO19-1" id="co_optimization_patterns_CO19-1"><img alt="1" src="assets/1.png"/></a><code class="w">&#13;
            </code><code class="nx">runtime</code><code class="p">.</code><code class="nx">GC</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">            </code><code class="nx">runtime</code><code class="p">.</code><code class="nx">GC</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">&#13;
</code><code class="w">    </code><code class="nx">b</code><code class="p">.</code><code class="nx">Run</code><code class="p">(</code><code class="s">"pool-GC"</code><code class="p">,</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="nx">b</code><code class="w"> </code><code class="o">*</code><code class="nx">testing</code><code class="p">.</code><code class="nx">B</code><code class="p">)</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">p</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="nx">sync</code><code class="p">.</code><code class="nx">Pool</code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="nx">New</code><code class="p">:</code><code class="w"> </code><code class="kd">func</code><code class="p">(</code><code class="p">)</code><code class="w"> </code><code class="kt">any</code><code class="w"> </code><code class="p">{</code><code class="w"> </code><code class="k">return</code><code class="w"> </code><code class="p">[</code><code class="p">]</code><code class="kt">byte</code><code class="p">{</code><code class="p">}</code><code class="w"> </code><code class="p">}</code><code class="p">,</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">        </code><code class="nx">b</code><code class="p">.</code><code class="nx">ResetTimer</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="k">for</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="o">:=</code><code class="w"> </code><code class="mi">0</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="w"> </code><code class="p">&lt;</code><code class="w"> </code><code class="nx">b</code><code class="p">.</code><code class="nx">N</code><code class="p">;</code><code class="w"> </code><code class="nx">i</code><code class="o">++</code><code class="w"> </code><code class="p">{</code><code class="w">&#13;
</code><code class="w">            </code><code class="nx">processUsingPool</code><code class="p">(</code><code class="o">&amp;</code><code class="nx">p</code><code class="p">)</code><code class="w"> </code><a class="co" href="#callout_optimization_patterns_CO19-2" id="co_optimization_patterns_CO19-2"><img alt="2" src="assets/2.png"/></a><code class="w">&#13;
            </code><code class="nx">runtime</code><code class="p">.</code><code class="nx">GC</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">            </code><code class="nx">runtime</code><code class="p">.</code><code class="nx">GC</code><code class="p">(</code><code class="p">)</code><code class="w">&#13;
</code><code class="w">        </code><code class="p">}</code><code class="w">&#13;
</code><code class="w">    </code><code class="p">}</code><code class="p">)</code><code class="w">&#13;
</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO19-1" id="callout_optimization_patterns_CO19-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The second surprise comes from the fact that in our initial benchmarks, the &#13;
<span class="keep-together"><code>process*</code></span> operations are performed quickly, one after another. However, on a macro level that might not be true. This is fine for <code>processUsingBuffer</code>. If the GC runs once or twice in the meantime for our simple buffered solution, the allocation and latency (adjusted with GC latency) stay the same because we keep the memory references in our <code>buf</code> variable. The next <code>processUsingBuffer</code> will be as fast as always.</p></dd>&#13;
<dt><a class="co" href="#co_optimization_patterns_CO19-2" id="callout_optimization_patterns_CO19-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>This is not the case for the standard pool. After two GC runs, the <code>sync.Pool</code> is, by design, fully cleaned from all objects,<sup><a data-type="noteref" href="ch11.html#idm45606813445248" id="idm45606813445248-marker">16</a></sup> which results in performance worse than <code>alloc</code> in <a data-type="xref" href="#code-reuse1">Example 11-17</a>.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p>As you can see, it’s fairly easy to make mistakes using <code>sync.Pool</code>. The fact that it does not preserve the pool after garbage collection might be beneficial in cases where we don’t want to keep pooled objects for a longer duration. However, in my experience, it makes it very hard to work with due to nondeterministic behavior caused by the combination of nontrivial <code>sync.Pool</code> implementation with an even more complex GC schedule.</p>&#13;
&#13;
<p>To show the potential damage when <code>sync.Pool</code> is applied to the wrong workloads, let’s try to optimize the memory use of the <code>labeler</code> service from <a data-type="xref" href="ch08.html#ch-obs-macro-example">“Go e2e Framework”</a> using optimized buffered code from <a data-type="xref" href="ch10.html#code-sum6">Example 10-8</a> and four different buffering techniques:</p>&#13;
<dl>&#13;
<dt><code>no-buffering</code></dt>&#13;
<dd>&#13;
<p><code>Sum6Reader</code> without buffering—always allocates a new buffer.</p>&#13;
</dd>&#13;
<dt><code>sync-pool</code></dt>&#13;
<dd>&#13;
<p>With <code>sync.Pool</code>.</p>&#13;
</dd>&#13;
</dl>&#13;
<dl class="less_space pagebreak-before">&#13;
<dt><code>gobwas-pool</code></dt>&#13;
<dd>&#13;
<p>With <a href="https://oreil.ly/VZjYW"><code>gobwas/pool</code></a> that maintains multiple buckets of <code>sync.Pool</code>. In theory, it should work well for byte slices that might require different buffer sizes.</p>&#13;
</dd>&#13;
<dt><code>static-buffers</code></dt>&#13;
<dd>&#13;
<p>With four static buffers that offer a buffer for a maximum of four goroutines.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>The main problem is that the <a data-type="xref" href="ch10.html#code-sum6">Example 10-8</a> workload might not look immediately like a wrong fit. The small allocation of <code>make([]byte, 8*1024)</code> per operation is the only one we make during the computation, so pooling to save the total memory usage might feel like a valid choice. The microbenchmark also shows amazing results. The benchmarks perform sequential <code>Sum6</code> operations on two different files (50% of the time, we use files with 10 million numbers, 50% with 100 million). The results are shown in <a data-type="xref" href="#code-labeler2-micro">Example 11-21</a>.</p>&#13;
<div data-type="example" id="code-labeler2-micro">&#13;
<h5><span class="label">Example 11-21. </span>The microbenchmark results with one hundred iterations that compare labeler <code>labelObject</code> logic using <a data-type="xref" href="ch10.html#code-sum6">Example 10-8</a> and four different buffering versions</h5>&#13;
&#13;
<pre data-type="programlisting">name                  time/op&#13;
Labeler/no-buffering   430ms ± 0%&#13;
Labeler/sync-pool      435ms ± 0%&#13;
Labeler/gobwas-pool    438ms ± 0%&#13;
Labeler/static-buffers 434ms ± 0%&#13;
&#13;
name                  alloc/op&#13;
Labeler/no-buffering   3.10MB ± 0%&#13;
Labeler/sync-pool      62.0kB ± 0%&#13;
Labeler/gobwas-pool    94.5kB ± 0% <a class="co" href="#callout_optimization_patterns_CO20-1" id="co_optimization_patterns_CO20-1"><img alt="1" src="assets/1.png"/></a>&#13;
Labeler/static-buffers 62.0kB ± 0%&#13;
&#13;
name                  allocs/op&#13;
Labeler/no-buffering    3.00 ± 0%&#13;
Labeler/sync-pool       3.00 ± 0%&#13;
Labeler/gobwas-pool     3.00 ± 0%&#13;
Labeler/static-buffers  2.00 ± 0%</pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_optimization_patterns_CO20-1" id="callout_optimization_patterns_CO20-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>The bucketed pool is slightly more memory intensive, but this is expected, as two separate pools are maintained. However, ideally, we expect to see larger benefits from that split on a larger scale.</p></dd>&#13;
</dl></div>&#13;
&#13;
<p class="less_space pagebreak-before">We see that the <code>sync.Pool</code> version and static buffer are winning in terms of memory allocations. The latency is more or less similar, given most of <a data-type="xref" href="ch10.html#code-sum6">Example 10-8</a> is spent on integer parsing, not allocating the buffer.</p>&#13;
&#13;
<p>Unfortunately, on the macro level, for a 5-minute test per version with 2 virtual users in <code>k6s</code> performing a sum on 10 million lines and then 100 million line files, we see that the reality is different than what <a data-type="xref" href="#code-labeler2-micro">Example 11-21</a> showed. What’s good is that the <code>labeler</code> without buffering allocates significantly more (3.3 GB in total) during that load than other versions (500 MB on average), as visible in <a data-type="xref" href="#img-labeler2-alloc">Figure 11-2</a>.</p>&#13;
&#13;
<figure><div class="figure" id="img-labeler2-alloc">&#13;
<img alt="efgo 1102" src="assets/efgo_1102.png"/>&#13;
<h6><span class="label">Figure 11-2. </span>The Parca Graph for the total memory allocated during macrobenchmark from heap profiles. Four lines indicate runs of four different versions in order: <code>no-buffering</code>, <code>sync-pool</code>, <code>gobwas-pool</code>, and <code>static-buffers</code>.</h6>&#13;
</div></figure>&#13;
&#13;
<p>However, it seems that such allocations are not a huge problem for the GC, as the simplest, no buffering solution <code>labelObject1</code> has similar average latency to others (same CPU usage as well), but also the lowest maximum heap usage, as visible in <a data-type="xref" href="#img-labeler2-use">Figure 11-3</a>.</p>&#13;
&#13;
<figure><div class="figure" id="img-labeler2-use">&#13;
<img alt="efgo 1103" src="assets/efgo_1103.png"/>&#13;
<h6><span class="label">Figure 11-3. </span>The Prometheus Graph for the heap size during the macrobenchmark. Four lines indicate runs of four different versions in order: <code>no-buffering</code>, <code>sync-pool</code>, <code>gobwas-pool</code>, and <code>static-buffers</code>.</h6>&#13;
</div></figure>&#13;
&#13;
<p>You can reproduce the whole experiment thanks to <a href="https://oreil.ly/9vDNZ">the <code>e2e</code> framework code in the example repo</a>. The results were not satisfying, but the experiment can give us a lot of lessons:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Reducing allocations might be the easiest way to improve latency and memory efficiency, but not always! Clearly, in this case, higher allocations were better than pooling. One reason is that the <code>Sum6</code> in <a data-type="xref" href="ch10.html#code-sum6">Example 10-8</a> was already heavily optimized. The CPU profile of <code>Sum6</code> in <a data-type="xref" href="ch10.html#code-sum6">Example 10-8</a> clearly shows that allocation is not a latency bottleneck. Secondly, the slower allocation pace caused the GC to kick in less often, allowing generally higher maximum memory usage. Additional <code>GOGC</code> tuning might have helped here.</p>&#13;
</li>&#13;
<li>&#13;
<p>The microbenchmarking does not always show the full picture. So always assess efficiency on multiple levels to be sure.</p>&#13;
</li>&#13;
<li>&#13;
<p>The <code>sync.Pool</code> helps the most with allocation latency, not with maximum memory usage, as our goal here.</p>&#13;
</li>&#13;
</ul>&#13;
<div class="fix_tracking" data-type="tip"><h1>The Optimization Journey Can Be a Roller Coaster!</h1>&#13;
<p>Sometimes we achieve improvement, and sometimes we spend a few days on change that can’t be merged. We all learn every day, try things, and sometimes fail. What’s most important is to fail early, so the less efficient version is not accidentally released to our users!</p>&#13;
</div>&#13;
&#13;
<p>The main issue of this experiment is that the <code>sync.Pool</code> is not designed for the type of workload that <code>labeler</code> represents. The <code>sync.Pool</code> have very specific use cases. Use it when:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>You want to reuse large or extreme amounts of objects to reduce the latency of those allocations.</p>&#13;
</li>&#13;
<li>&#13;
<p>You don’t care about the object content, just its memory blocks.</p>&#13;
</li>&#13;
<li>&#13;
<p>You want to reuse those objects from multiple goroutines, which can vary in number.</p>&#13;
</li>&#13;
<li>&#13;
<p>You want to reuse objects between quick computations that frequently happen (maximum one GC cycle away).</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>For example, <code>sync.Pool</code> works great when we want to pool objects for an <a href="https://oreil.ly/9mvAE">extremely fast pseudorandom generator</a>. The HTTP servers use <a href="https://oreil.ly/TpzMN">many different pools of bytes</a> to reuse bytes for reading from the network.</p>&#13;
&#13;
<p>Unfortunately, in my experience, the <code>sync.Pool</code> is overused. The perception is that the <code>sync.Pool</code> is in the standard library, so it must be handy, but that isn’t always true. The <code>sync.Pool</code> has a very narrow use case, and there are high chances it’s not what we want.</p>&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm45606813306848">&#13;
<h5>Why Can’t We Always Have Nice Things in the Standard Library?</h5>&#13;
<p>The community and Go team always debate for a long time until something is merged into the standard library. In most cases, features are rejected.</p>&#13;
&#13;
<p>There is a good reason for that, and <code>sync.Pool</code> is a good example. It becomes the official standard whenever something is merged in the <a href="https://oreil.ly/f2q36">Go repository</a>. However, in the case of <code>sync.Pool</code>, I think it created a wrong perception that it is useful for more cases. Perhaps to the point where it should be used more often than simple static buffers, as in <a data-type="xref" href="#code-reuse1">Example 11-17</a>. Otherwise, we would have an official structure like <code>sync.Reusable</code> or <code>sync.Cache</code>, right?<sup><a data-type="noteref" href="ch11.html#idm45606813301392" id="idm45606813301392-marker">17</a></sup></p>&#13;
&#13;
<p>This is misleading. We don’t have something for static reusable buffers because it’s easy to write your own, not because it’s a less beneficial pattern!</p>&#13;
</div></aside>&#13;
&#13;
<p>To sum up, I prefer simple optimization first. The more clever the optimization is, the more vigilant we should be and the more benchmarking effort we should make. The <code>sync.Pool</code> structure is one of the more complex solutions. I would recommend looking at easier solutions first, e.g., a simple static reusable buffer of memory, as in <a data-type="xref" href="#code-reuse1">Example 11-17</a>. My recommendation is to avoid <code>sync.Pool</code> until you are sure your workloads match the use cases mentioned previously. In most cases, after reduced work and allocations, adding <code>sync.Pool</code> will only make your code less efficient, brittle, and harder to assess its<a data-startref="ix_ch11-asciidoc21" data-type="indexterm" id="idm45606813296512"/><a data-startref="ix_ch11-asciidoc20" data-type="indexterm" id="idm45606813295808"/> efficiency<a data-startref="ix_ch11-asciidoc19" data-type="indexterm" id="idm45606813295008"/>.<a data-startref="ix_ch11-asciidoc0" data-type="indexterm" id="idm45606813294176"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="idm45606814436368">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>That’s it. You made it to the end of this book, congratulations! I hope it was a fantastic and valuable journey. I know it was for me!</p>&#13;
&#13;
<p>Perhaps, if you have made it this far, the world of pragmatic, efficient software is much more accessible for you than it was before opening this book. Or perhaps you see how all the details on how we write our code and design our algorithms can impact the software efficiency, which can translate to real cost in the long run.</p>&#13;
&#13;
<p>In some ways, this is extremely exciting. With one deliberate change and the right observability tools to assess it, we can sometimes save millions of dollars for our employer, or enable use cases or customers that were not possible before. But, on the other hand, it is quite scary how easy it is to waste that money on silly mistakes like leaking a few goroutines or not pre-allocating some slices on critical paths.</p>&#13;
&#13;
<p>My advice for you, if you are more on the “scared” side, is…​to relax! Remember that nothing in the world is perfect, and our code can’t be perfect either. It’s good to know in what direction to turn to for perfection, but as the saying goes, <a href="https://oreil.ly/OogZF">“Perfect is the enemy of good”</a>, and there has to be a moment when the software is “good enough.” In my opinion, this is the key difference between the professional, pragmatic, everyday efficiency practices I wanted to teach you here and Donald Knuth’s “premature optimization is the root of all evil” world. This is also why my book is called <em>Efficient Go</em> and not <em>Ultra-Performance, Super Fast Go</em>.</p>&#13;
&#13;
<p>I think the pragmatic car mechanic profession could be a good comparison to the pragmatic efficiency-aware software developer (sorry for my car analogies!). Imagine a passionate and experienced mechanical engineer with huge experience in building F1 cars—one of the fastest racing automobiles in the world. Imagine they work at the auto workshop, and a customer goes there with some standard saloon car that has an oil leak. Even with the greatest knowledge about making the car extremely fast, the pragmatic mechanic would fix the oil leak, double-check the whole car if there was anything wrong with it, and that’s it. However, if the mechanic starts to tune the customer’s car for faster acceleration, better air efficiency, and braking performance, you can imagine the customer would not be satisfied. Better car performance would probably make the customer happy, but this always comes with an extreme bill for work hours, expensive parts, and delayed time to repair.</p>&#13;
&#13;
<p>Follow the same rules as you would expect from your mechanic. Do what’s needed to be done to satisfy functional and efficiency goals. This is not being lazy; it’s being pragmatic and professional. No optimization is premature if we do this within the premise of requirements.</p>&#13;
&#13;
<p>That’s why my second piece of advice is to always set some goals. Look how (in some sense) “easy” it was to assess if the <code>Sum</code> optimizations in <a data-type="xref" href="ch10.html#ch-opt">Chapter 10</a> were acceptable or not. One of the biggest mistakes I made in most of my software projects was to ignore or procrastinate on setting clear, ideally written, data-driven goals for the project’s expected efficiency. Even if it’s obvious, note, “I expect this functionality to finish in one minute.” You can iterate on better requirements later on! Without clear goals, every optimization is potentially premature.</p>&#13;
&#13;
<p>Finally, my third bit of advice is to invest in good observability tools. I was lucky that during my daily job for the last few years, the teams I worked with delivered observability software. Furthermore, those observability tools are <em>free</em> in open source, and every reader of this book can install them right now. I can’t imagine not having the tools mentioned in <a data-type="xref" href="ch06.html#ch-observability">Chapter 6</a>.</p>&#13;
&#13;
<p>On the other hand, I also see, as a tech leader of <a href="https://oreil.ly/yJKg4">the CNCF interest group observability</a>, and speaker and attendee of technical conferences, how many developers and organizations don’t use observability tools. They either don’t observe their software or don’t use those tools correctly! That is why it’s very hard for those individuals or organizations to pragmatically improve the efficiency of their programs.</p>&#13;
&#13;
<p>Don’t get distracted by overhyped solutions and vendors who promise shiny observability solutions for a high price.<sup><a data-type="noteref" href="ch11.html#idm45606813281824" id="idm45606813281824-marker">18</a></sup> Instead, I would recommend starting small with open source monitoring and observability solutions like <a href="https://oreil.ly/2Sa3P">Prometheus</a>, <a href="https://oreil.ly/Fw9I3">Loki</a>, <a href="https://oreil.ly/RohpZ">OpenSearch</a>, <a href="https://oreil.ly/eZ2Gy">Tempo</a>, or <a href="https://oreil.ly/q5O8u">Jaeger</a>!</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="Next Steps" data-type="sect1"><div class="sect1" id="idm45606813277632">&#13;
<h1>Next Steps</h1>&#13;
&#13;
<p>Throughout this book, we went through all the elements required to become effective with the efficiency development of Go if required. Particularly:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>We discussed motivation for efficient programs and introduction in <a data-type="xref" href="ch01.html#ch-efficiency-matters">Chapter 1</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>We walked through the foundational aspects of Go in <a data-type="xref" href="ch02.html#ch-go">Chapter 2</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>We discussed challenges, optimizations, RAER, and TFBO in <a data-type="xref" href="ch03.html#ch-efficiency">Chapter 3</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>I explained the two most important resources we optimize for: the CPU in <a data-type="xref" href="ch04.html#ch-hardware">Chapter 4</a> and memory in <a data-type="xref" href="ch05.html#ch-hardware2">Chapter 5</a>. I also mentioned latency.</p>&#13;
</li>&#13;
<li>&#13;
<p>We discussed observability and common instrumentation in <a data-type="xref" href="ch06.html#ch-observability">Chapter 6</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>We walked through data-driven efficiency analysis, complexities, and reliability of experiments in <a data-type="xref" href="ch07.html#ch-observability2">Chapter 7</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>We discussed benchmarking in <a data-type="xref" href="ch08.html#ch-benchmarking">Chapter 8</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>I introduced the topic of profiling, which helps with bottleneck analysis in &#13;
<span class="keep-together"><a data-type="xref" href="ch09.html#ch-observability3">Chapter 9</a>.</span></p>&#13;
</li>&#13;
<li>&#13;
<p>Finally, we optimized various code examples in <a data-type="xref" href="ch10.html#ch-opt">Chapter 10</a> and summarized common patterns in <a data-type="xref" href="#ch-opt2">Chapter 11</a>.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>However, as with everything, there is always more to learn if you are interested!</p>&#13;
&#13;
<p>First, I skipped some aspects of the Go language that were not strictly related to the efficiency topic. To learn more about those, I would recommend reading <a href="https://oreil.ly/VnFms">“Practical Go Lessons”</a> authored by Maximilien Andile and…​practicing writing Go programs for realistic goals for work or as a fun side project.<sup><a data-type="noteref" href="ch11.html#idm45606813255952" id="idm45606813255952-marker">19</a></sup></p>&#13;
&#13;
<p>Secondly, hopefully, I enabled you to understand the underlying mechanisms of the resources you are optimizing for. One of the next steps to becoming better at software efficiency is to learn more about other resources we commonly optimize for, for example:</p>&#13;
<dl>&#13;
<dt>Disk</dt>&#13;
<dd>&#13;
<p>We use disk storage every day in our Go programs. The way OS handles reads or writes to it can be similarly complex, as you saw in <a data-type="xref" href="ch05.html#ch-hw-memory-os">“OS Memory Management”</a>. Understanding disk storage better (e.g., the <a href="https://oreil.ly/3mjc6">SSD</a> characteristics) &#13;
<span class="keep-together">will make</span> you a better developer. If you are curious &#13;
<span class="keep-together">about the</span> alternative optimizations to disk access, I would also recommend &#13;
<span class="keep-together">reading</span> about the <a href="https://oreil.ly/Sxagc"><code>io_uring</code> interface that comes with the new Linux kernels</a>. It might allow you to build even better concurrency for your Go programs using a lot of disk access.</p>&#13;
</dd>&#13;
<dt>Network</dt>&#13;
<dd>&#13;
<p>Reading more about the network constraints like latency, bandwidth, and different protocols will make you more aware of how to optimize your Go code that is constrained by network limitations.</p>&#13;
</dd>&#13;
<dt>GPUs and FPGA</dt>&#13;
<dd>&#13;
<p>For more on offloading some computations to external devices like <a href="https://oreil.ly/yEi43">GPUs</a> or <a href="https://oreil.ly/1dPXO">programmable hardware</a>, I would recommend <a href="https://oreil.ly/T8q9A">cu</a>, which uses the popular <a href="https://oreil.ly/PXZhH">CUDA API</a> for the NVIDIA GPUs, or this <a href="https://oreil.ly/v3dty">guide</a> to run Go on Apple M1 GPUs.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>Thirdly, while I might add more optimization examples in the next editions of this book, the list will never be complete. This is because some developers might want to try many more or less extreme optimizations for some specific part of their programs. For example:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Something I wanted to talk about but could not fit into this book is the importance of error path and <a href="https://oreil.ly/2IoAP">instrumentation efficiency</a>. Choosing efficient interfaces for your metrics, logging, tracing, and profiling instrumentations can be important.</p>&#13;
</li>&#13;
<li>&#13;
<p>Memory alignment and <a href="https://oreil.ly/r1aJn">struct padding optimizations</a> with tools like <a href="https://oreil.ly/IuWGN"><code>structslop</code></a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Using more efficient <a href="https://oreil.ly/ALPOm">string encodings</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Partial encoding and decoding of common formats like <a href="https://oreil.ly/gzswU">protobuf</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Removal of bound checks (BCE), e.g., from <a href="https://oreil.ly/uOHmo">arrays</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Branchless Go coding, optimizing for <a href="https://oreil.ly/v9eNk">the CPU branch predictions</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p><a href="https://oreil.ly/SxPUA">Array of structs versus structs of arrays and loop fusion and fission</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Finally, try to run different languages from Go to offload some performance-sensitive logic, for example, running <a href="https://oreil.ly/vp5V3">Rust from Go</a>, or in the future, <a href="https://oreil.ly/ZO3Zn">Carbon</a> from Go! Let’s not forget about something much more common: running <a href="https://oreil.ly/eLZKW">Assembly from Go</a> for efficiency reasons.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Finally, all examples in this book are available at the <a class="bare" href="https://github.com/efficientgo/examples"><em class="hyperlink">https://github.com/efficientgo/examples</em></a> open source repository. Give feedback, contribute, and learn together with others.</p>&#13;
&#13;
<p>Everybody learns differently, so try what helps you the most. However, I strongly recommend practicing the software of your choice using the practices you learned in this book. Try to set reasonable efficiency goals and try to optimize them.<sup><a data-type="noteref" href="ch11.html#idm45606813221312" id="idm45606813221312-marker">20</a></sup></p>&#13;
&#13;
<p>You are also welcome to use and contribute to other Go tools I maintain in the open source: <a class="bare" href="https://github.com/efficientgo/core"><em class="hyperlink">https://github.com/efficientgo/core</em></a>, <a class="bare" href="https://github.com/efficientgo/e2e"><em class="hyperlink">https://github.com/efficientgo/e2e</em></a>, <a class="bare" href="https://github.com/prometheus/prometheus"><em class="hyperlink">https://github.com/prometheus/prometheus</em></a>, and more!<sup><a data-type="noteref" href="ch11.html#idm45606813214720" id="idm45606813214720-marker">21</a></sup></p>&#13;
&#13;
<p>Join our <a href="https://oreil.ly/cNnt2">“Efficient Go” Discord Community</a>, and feel free to give feedback on the book, ask additional questions, or find new friends!</p>&#13;
&#13;
<p>Massive thanks to all (see <a data-type="xref" href="preface01.html#thanks">“Acknowledgments”</a>) who directly or indirectly helped to create this book. Thanks to those who mentored me to where I am now!</p>&#13;
&#13;
<p>Thank you for buying and reading my book. See you in the open source! :)</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45606819377840"><sup><a href="ch11.html#idm45606819377840-marker">1</a></sup> I spoke about this problem at the <a href="https://oreil.ly/z6YHe">GitHub Global Maintainers Summit</a>.</p><p data-type="footnote" id="idm45606819373392"><sup><a href="ch11.html#idm45606819373392-marker">2</a></sup> This list was inspired by Chapter 4 in <em>Writing Efficient Programs</em> by Jon Louis Bentley.</p><p data-type="footnote" id="idm45606819974288"><sup><a href="ch11.html#idm45606819974288-marker">3</a></sup> There’s a reason some people call caches <a href="https://oreil.ly/KNQP3">“a memory leak you don’t know about yet”</a>.</p><p data-type="footnote" id="idm45606819332528"><sup><a href="ch11.html#idm45606819332528-marker">4</a></sup> See a nice blog post about those <a href="https://oreil.ly/KrVnG">here</a>.</p><p data-type="footnote" id="idm45606819295376"><sup><a href="ch11.html#idm45606819295376-marker">5</a></sup> For example, in <a href="https://oreil.ly/WFbrk">the Prometheus project we removed</a> the manual GC trigger when code conditions changed a little. That decision was based on micro- and macrobenchmarks discussed in <a data-type="xref" href="ch07.html#ch-observability2">Chapter 7</a>.</p><p data-type="footnote" id="idm45606819276864"><sup><a href="ch11.html#idm45606819276864-marker">6</a></sup> The reason is that we might reuse the same code in a more long-living scenario, where a leak might have much bigger consequences.</p><p data-type="footnote" id="idm45606819271728"><sup><a href="ch11.html#idm45606819271728-marker">7</a></sup> Unless we disabled it using the <code>GOGC=off</code> environment variable.</p><p data-type="footnote" id="idm45606819262800"><sup><a href="ch11.html#idm45606819262800-marker">8</a></sup> For that, we could use tools that <a href="https://oreil.ly/iTXhz">analyze the dumped core</a>, but they aren’t very accessible at the moment, so I would not recommend them.</p><p data-type="footnote" id="idm45606817523552"><sup><a href="ch11.html#idm45606817523552-marker">9</a></sup> Yes! If we don’t invoke the returned <code>context.CancelContext</code> function, it will keep a goroutine running forever (when <code>WithContext</code> was used) or until the timeout (<code>WithTimeout</code>).</p><p data-type="footnote" id="idm45606817514192"><sup><a href="ch11.html#idm45606817514192-marker">10</a></sup> I have only seen linters that check some basic things like if the code closed <a href="https://oreil.ly/DpSLY">request body</a>, or <a href="https://oreil.ly/EVB8M">sql statements</a>. There is room to contribute more of those, e.g., <a href="https://oreil.ly/WfmyC">in the <code>semgrep-go</code> project</a>.</p><p data-type="footnote" id="idm45606816330528"><sup><a href="ch11.html#idm45606816330528-marker">11</a></sup> Which is quite interesting, considering we do more work in our code. We read through all bytes of the HTML returned by Google. Yet, it’s faster as we create fewer TCP connections.</p><p data-type="footnote" id="idm45606816088384"><sup><a href="ch11.html#idm45606816088384-marker">12</a></sup> This is often used when we know only the worst-case <code>size</code>. Sometimes it’s worth growing it to the worst case, even if we use less in the end. See <a data-type="xref" href="#ch-basic-subslice">“Overusing Memory with Arrays”</a>.</p><p data-type="footnote" id="idm45606815217568"><sup><a href="ch11.html#idm45606815217568-marker">13</a></sup> For example, this is what we did in <a href="https://oreil.ly/8nWCH">Thanos</a> some time ago.</p><p data-type="footnote" id="idm45606814784544"><sup><a href="ch11.html#idm45606814784544-marker">14</a></sup> This is great as a quick showcase, but does not work well as a reliable efficiency assessment.</p><p data-type="footnote" id="idm45606814531920"><sup><a href="ch11.html#idm45606814531920-marker">15</a></sup> In the Prometheus project ecosystem, we experienced such a problem many times. For example, chunk pooling caused us to keep arrays that were way bigger than required, so we introduced <a href="https://oreil.ly/ORx1C">the <code>Compact</code> method</a>. In Thanos, I introduced a (probably too) clever <a href="https://oreil.ly/Z3Q8n"><code>ZLabel</code> construct</a> that avoided expensive copy of strings for metric labels. It turned out to be beneficial for cases when we were not keeping the label strings for longer. For example, it was better to perform when we did <a href="https://oreil.ly/5o6sH">a lazy copy</a>.</p><p data-type="footnote" id="idm45606813445248"><sup><a href="ch11.html#idm45606813445248-marker">16</a></sup> If you are interested in the specific implementation details, check out <a href="https://oreil.ly/oMh6I">this amazing blog post</a>.</p><p data-type="footnote" id="idm45606813301392"><sup><a href="ch11.html#idm45606813301392-marker">17</a></sup> Interestingly enough, <code>sync.Pool</code> was proposed to be named <code>sync.Cache</code> initially and have cache semantics.</p><p data-type="footnote" id="idm45606813281824"><sup><a href="ch11.html#idm45606813281824-marker">18</a></sup> And be vigilant when someone offers shiny observability for a low price. It is often less cheap in practice, given how much data we usually have to pass through those systems.</p><p data-type="footnote" id="idm45606813255952"><sup><a href="ch11.html#idm45606813255952-marker">19</a></sup> My recommendation is to <a href="https://oreil.ly/5YDe6">avoid following only tutorials</a>. If you are out of your comfort zone and have to think on your own, you learn.</p><p data-type="footnote" id="idm45606813221312"><sup><a href="ch11.html#idm45606813221312-marker">20</a></sup> If you are interested, I would like to invite you to our yearly <a href="https://oreil.ly/OPPXh">efficiency-coding-advent</a>, where we try to solve <a href="https://oreil.ly/10gGv">coding challenges around Christmas time</a> with an efficient approach.</p><p data-type="footnote" id="idm45606813214720"><sup><a href="ch11.html#idm45606813214720-marker">21</a></sup> You can find all the projects I maintain (or used to maintain) on <a href="https://oreil.ly/0af14">my website</a>.</p></div></div></section></body></html>