<html><head></head><body><section data-pdf-bookmark="Appendix A. Latencies for Napkin Math Calculations" data-type="appendix" epub:type="appendix"><div class="appendix" id="appendix-napkin-math">&#13;
<h1><span class="label">Appendix A. </span>Latencies for Napkin Math Calculations</h1>&#13;
&#13;
&#13;
<p><a data-primary="latency" data-secondary="napkin math calculations" data-type="indexterm" id="idm45606813209024"/><a data-primary="napkin math" data-type="indexterm" id="idm45606813208080"/>For designing and assessing optimizations on a different level, it’s useful to be able to approximate and ballpark latency numbers for basic operations we see in interactions with the computer.</p>&#13;
&#13;
<p>It’s good to remember some of those numbers, but if you don’t, I prepared a small table with the approximate, rounded, average latencies in <a data-type="xref" href="#table-napkin-math">Table A-1</a>. It is heavily inspired by <a href="https://oreil.ly/yXLnn">Simon Eskildsen’s napkin-math repository</a>, with a few modifications.</p>&#13;
&#13;
<p>The repository was created in 2021. For CPU-based operations, those numbers are based on the server x86 CPU from the Xeon family. Note that things are still improving every year, however, most of the numbers are stable since 2005, due to limitations explained in <a data-type="xref" href="ch01.html#ch-eff-s-hardware">“Hardware Is Getting Faster and Cheaper”</a>. CPU-related latencies might be also different across various CPU architectures (e.g. ARM).</p>&#13;
<table id="table-napkin-math">&#13;
<caption><span class="label">Table A-1. </span>CPU-related latencies</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Operation</th>&#13;
<th>Latency</th>&#13;
<th>Throughput</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>3 Ghz CPU clock cycle</p></td>&#13;
<td><p>0.3 ns</p></td>&#13;
<td><p>N/A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>CPU register access</p></td>&#13;
<td><p>0.3 ns (1 cycle)</p></td>&#13;
<td><p>N/A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>CPU L1 cache access</p></td>&#13;
<td><p>0.9 ns (3 cycles)</p></td>&#13;
<td><p>N/A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>CPU L2 cache access</p></td>&#13;
<td><p>3ns</p></td>&#13;
<td><p>N/A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Sequential memory R/W (64 bytes)</p></td>&#13;
<td><p>5 ns</p></td>&#13;
<td><p>10 GBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>CPU L3 cache access</p></td>&#13;
<td><p>20 ns</p></td>&#13;
<td><p>N/A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Hashing, not crypto-safe (64 bytes)</p></td>&#13;
<td><p>25 ns</p></td>&#13;
<td><p>2 GBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Random memory R/W (64 bytes)</p></td>&#13;
<td><p>50 ns</p></td>&#13;
<td><p>1 GBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Mutex lock/unlock</p></td>&#13;
<td><p>17 ns</p></td>&#13;
<td><p>N/A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>System call</p></td>&#13;
<td><p>500 ns</p></td>&#13;
<td><p>N/A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Hashing, crypto-safe (64 bytes)</p></td>&#13;
<td><p>500 ns</p></td>&#13;
<td><p>200 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Sequential SSD read (8 KB)</p></td>&#13;
<td><p>1 μs</p></td>&#13;
<td><p>4 GBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Context switch</p></td>&#13;
<td><p>10 μs</p></td>&#13;
<td><p>N/A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Sequential SSD write, -fsync (8KB)</p></td>&#13;
<td><p>10 μs</p></td>&#13;
<td><p>1 GBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>TCP echo server (32 KiB)</p></td>&#13;
<td><p>10 μs</p></td>&#13;
<td><p>4 GBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Sequential SSD write, +fsync (8KB)</p></td>&#13;
<td><p>1 ms</p></td>&#13;
<td><p>10 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Sorting (64-bit integers)</p></td>&#13;
<td><p>N/A</p></td>&#13;
<td><p>200 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Random SSD seek (8 KiB)</p></td>&#13;
<td><p>100 μs</p></td>&#13;
<td><p>70 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Compression</p></td>&#13;
<td><p>N/A</p></td>&#13;
<td><p>100 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Decompression</p></td>&#13;
<td><p>N/A</p></td>&#13;
<td><p>200 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Proxy: Envoy/ProxySQL/NGINX/HAProxy</p></td>&#13;
<td><p>50 μs</p></td>&#13;
<td><p>?</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Network within same region</p></td>&#13;
<td><p>250 μs</p></td>&#13;
<td><p>100 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>MySQL, memcached, Redis query</p></td>&#13;
<td><p>500 μs</p></td>&#13;
<td><p>?</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Random HDD Seek (8 KB)</p></td>&#13;
<td><p>10 ms</p></td>&#13;
<td><p>0.7 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Network NA East ↔ West</p></td>&#13;
<td><p>60 ms</p></td>&#13;
<td><p>25 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Network EU West ↔ NA East</p></td>&#13;
<td><p>80 ms</p></td>&#13;
<td><p>25 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Network NA West ↔ Singapore</p></td>&#13;
<td><p>180 ms</p></td>&#13;
<td><p>25 MBps</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Network EU West ↔ Singapore</p></td>&#13;
<td><p>160 ms</p></td>&#13;
<td><p>25 MBps</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div></section></body></html>